{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 1s 747us/step - loss: 0.5006 - accuracy: 0.8792\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 1s 763us/step - loss: 0.2304 - accuracy: 0.9347\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 2s 830us/step - loss: 0.1788 - accuracy: 0.9495\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 2s 823us/step - loss: 0.1488 - accuracy: 0.9578\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 1s 750us/step - loss: 0.1274 - accuracy: 0.9637\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 1s 767us/step - loss: 0.1117 - accuracy: 0.9683\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 1s 756us/step - loss: 0.0997 - accuracy: 0.9719\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 1s 775us/step - loss: 0.0891 - accuracy: 0.9750\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 2s 810us/step - loss: 0.0809 - accuracy: 0.9777\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 2s 813us/step - loss: 0.0734 - accuracy: 0.9793\n",
      "313/313 - 0s - loss: 0.1051 - accuracy: 0.9687\n",
      "test_loss: 0.10505840927362442 \n",
      "test_accuracy: 0.9686999917030334\n"
     ]
    }
   ],
   "source": [
    "# Conv2D 모델을 쓰지 않고 다층 퍼셉트론으로 분류하기\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MNIST 데이터를 로드. 다운로드하지 않았다면 다운로드까지 자동으로 진행됩니다. \n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()   \n",
    "\n",
    "# 모델에 맞게 데이터 가공\n",
    "x_train_norm, x_test_norm = x_train / 255.0, x_test / 255.0\n",
    "x_train_reshaped = x_train_norm.reshape(-1, x_train_norm.shape[1]*x_train_norm.shape[2])\n",
    "x_test_reshaped = x_test_norm.reshape(-1, x_test_norm.shape[1]*x_test_norm.shape[2])\n",
    "\n",
    "# 딥러닝 모델 구성 - 2 Layer Perceptron\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(50, activation='sigmoid', input_shape=(784,)))  # 입력층 d=784, 은닉층 레이어 H=50\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))   # 출력층 레이어 K=10\n",
    "model.summary()\n",
    "\n",
    "# 모델 구성과 학습\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "model.fit(x_train_reshaped, y_train, epochs=10)\n",
    "\n",
    "# 모델 테스트 결과\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 퍼셉트론   \n",
    "입력층(d + 1), 은닉층(H + 1), 출력층(K)   \n",
    "bias에 관한 참고자료(https://funnypr.tistory.com/entry/The-Basic-Artificial-Neuron-Bias-neuron)   \n",
    "은닉층은 여러 층일 수 있다.   \n",
    "Fully-Connected Neural Network = MLP(Multi layer perceptron)   \n",
    "서로 다른 층에 위치한 노드 간에는 연결 관계가 존재하지 않으며,   \n",
    "인접한 층에 위치한 노드들 간의 연결만 존재한다는 의미 내포   \n",
    "인접한 레이어 사이의 관계식 : y = W * X + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(5, 784)\n"
     ]
    }
   ],
   "source": [
    "# 입력층 데이터의 모양(shape)\n",
    "print(x_train_reshaped.shape)\n",
    "\n",
    "# 테스트를 위해 x_train_reshaped의 앞 5개의 데이터를 가져온다.\n",
    "X = x_train_reshaped[:5]\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(5, 50)\n"
     ]
    }
   ],
   "source": [
    "# 입력층과 은닉층\n",
    "weight_init_std = 0.1\n",
    "input_size = 784\n",
    "hidden_size=50\n",
    "\n",
    "# 인접 레이어간 관계를 나타내는 파라미터 W를 생성하고 random 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)  \n",
    "# 바이어스 파라미터 b를 생성하고 Zero로 초기화\n",
    "b1 = np.zeros(hidden_size)\n",
    "\n",
    "a1 = np.dot(X, W1) + b1   # 은닉층 출력\n",
    "\n",
    "print(W1.shape)\n",
    "print(b1.shape)\n",
    "print(a1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27517754, -1.18694462,  1.23981076,  0.20130697,  0.72761433,\n",
       "        0.66312384,  0.99966084, -0.43152154, -0.30988435, -0.92857059,\n",
       "        0.41885779,  1.18449627, -0.07710131, -0.09030765, -1.71642415,\n",
       "       -0.03451691, -0.48135733, -0.14329307,  1.64443371,  0.05142941,\n",
       "       -0.35665453,  0.85075461,  0.07170502,  0.54733239,  0.03578679,\n",
       "       -1.93314025,  0.2358194 ,  0.93640113,  0.15555796,  0.14962901,\n",
       "        0.6105892 , -0.16246689,  2.29654455, -0.21212953, -0.2382227 ,\n",
       "       -0.61273688,  0.49816242,  1.56840108, -1.45784063, -0.7001867 ,\n",
       "        0.34207614, -0.8703566 ,  0.52411792,  0.83190402, -1.59451899,\n",
       "       -0.34637837,  0.82071989,  1.01896903,  0.98708716,  0.37884972])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫번째 데이터의 은닉층 출력을 확인해 봅시다.  50dim의 벡터가 나오나요?\n",
    "a1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.43163646 0.23380583 0.77553107 0.55015747 0.67428153 0.65996177\n",
      " 0.73099189 0.39376306 0.42314297 0.2832148  0.6032099  0.76575528\n",
      " 0.48073421 0.47743842 0.15233233 0.49137163 0.38193166 0.4642379\n",
      " 0.83813733 0.51285452 0.41176965 0.70072541 0.51791858 0.63351646\n",
      " 0.50894574 0.12640341 0.55868315 0.71837213 0.53881126 0.53733762\n",
      " 0.64807519 0.45947238 0.90859046 0.44716559 0.44072439 0.35143513\n",
      " 0.6220274  0.82755555 0.18879782 0.33177084 0.58469475 0.29518011\n",
      " 0.62811017 0.69675737 0.16874906 0.41426093 0.69438913 0.73477173\n",
      " 0.7285122  0.59359564]\n"
     ]
    }
   ],
   "source": [
    "# 활성화함수\n",
    "# 1. sigmoid\n",
    "\n",
    "# 위 수식의 sigmoid 함수를 구현해 봅니다.\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "\n",
    "\n",
    "z1 = sigmoid(a1)\n",
    "print(z1[0])  # sigmoid의 출력은 모든 엘리먼트가 0에서 1사이\n",
    "\n",
    "# Gradient Vanishing 현상발생\n",
    "# exp함수는 비용이 크다\n",
    "# Vanishing Gradient Problem(https://brunch.co.kr/@chris-song/39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Tanh\n",
    "# 함수의 중심값을 0으로 이동시켜 sigmoid의 최적화 과정이 느려지는 문제 해결\n",
    "# 여전히 gradient vanishing 문제 존재.\n",
    "\n",
    "# 3. ReLU f(x) = max(0, x)\n",
    "# sigmoid, tanh함수에 비해 학습이 빠름.\n",
    "# 연산 비용이 크지 않으며, 구현이 매우 간단하다.\n",
    "\n",
    "# 활성화함수란(https://reniew.github.io/12/)\n",
    "# (https://pozalabs.github.io/Activation_Function/)\n",
    "# https://wikidocs.net/60683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.16364738  0.04132123  0.26639753  0.11348436 -0.21090399  0.21570556\n",
      "  0.11796838 -0.15118493 -0.38317365  0.06403835]\n"
     ]
    }
   ],
   "source": [
    "# 단일 레이어 구현 함수\n",
    "def affine_layer_forward(X, W, b):\n",
    "    y = np.dot(X, W) + b\n",
    "    cache = (X, W, b)\n",
    "    return y, cache\n",
    "\n",
    "input_size = 784\n",
    "hidden_size = 50\n",
    "output_size = 10\n",
    "\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)    # z1이 다시 두번째 레이어의 입력이 됩니다. \n",
    "\n",
    "print(a2[0])  # 최종 출력이 output_size만큼의 벡터가 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11293793, 0.09993423, 0.12515945, 0.10741237, 0.07765586,\n",
       "       0.118973  , 0.10789509, 0.08243467, 0.06536699, 0.10223043])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    if x.ndim == 2:\n",
    "        x = x.T\n",
    "        x = x - np.max(x, axis=0)\n",
    "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "        return y.T \n",
    "\n",
    "    x = x - np.max(x) # 오버플로 대책\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "\n",
    "y_hat = softmax(a2)\n",
    "y_hat[0]  # 10개의 숫자 중 하나일 확률이 되었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수(Loss Functions)\n",
    "# 비선형 활성화 함수를 가진 여러 개의 은닉층을 거친 다음 출력층으로 전달된다.\n",
    "# 출력층으로 전달된 정보와 실제 정보의 차이를 계산하고 다시 파라미터들을 조정한다.\n",
    "# 이 차이를 계산하는 함수가 손실함수 또는 비용함수라 한다.\n",
    "# 평균제곱오차(MSE: Mean Square Error)\n",
    "# 교차 엔트로피(Cross entropy): 두 확률분포 사이의 유사도가 클수록 작아지는 값\n",
    "# http://www.gisdeveloper.co.kr/?p=7631"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답 라벨을 One-hot 인코딩하는 함수\n",
    "def _change_ont_hot_label(X, num_category):\n",
    "    T = np.zeros((X.size, num_category))\n",
    "    for idx, row in enumerate(T):\n",
    "        row[X[idx]] = 1\n",
    "        \n",
    "    return T\n",
    "\n",
    "Y_digit = y_train[:5]\n",
    "t = _change_ont_hot_label(Y_digit, 10)\n",
    "t     # 정답 라벨의 One-hot 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11293793 0.09993423 0.12515945 0.10741237 0.07765586 0.118973\n",
      " 0.10789509 0.08243467 0.06536699 0.10223043]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# softmax(a2)와 정답의 분포가 유사해지도록 조정한다.\n",
    "print(y_hat[0])\n",
    "print(t[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2507463168227604"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.reshape(1, y.size)\n",
    "        \n",
    "    # 훈련 데이터가 원-핫 벡터라면 정답 레이블의 인덱스로 반환\n",
    "    if t.size == y.size:\n",
    "        t = t.argmax(axis=1)\n",
    "             \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size\n",
    "\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02258759,  0.01998685,  0.02503189,  0.02148247,  0.01553117,\n",
       "        -0.1762054 ,  0.02157902,  0.01648693,  0.0130734 ,  0.02044609],\n",
       "       [-0.17753916,  0.02276278,  0.02087973,  0.02027468,  0.0145348 ,\n",
       "         0.02144336,  0.02545552,  0.02016897,  0.01356644,  0.01845288],\n",
       "       [ 0.02189238,  0.01876948,  0.02245927,  0.01643507, -0.18238376,\n",
       "         0.02154149,  0.02855053,  0.02127925,  0.01454446,  0.01691181],\n",
       "       [ 0.0218434 , -0.1770194 ,  0.02034438,  0.01980182,  0.01657345,\n",
       "         0.02089372,  0.02648314,  0.02078063,  0.01322814,  0.01707072],\n",
       "       [ 0.02173064,  0.01850479,  0.02386584,  0.0190787 ,  0.0168967 ,\n",
       "         0.02100747,  0.02713797,  0.01891353,  0.0136981 , -0.18083374]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learning rate, overfitting(https://aileen93.tistory.com/71)\n",
    "# 가중치 초기화(https://reniew.github.io/13/)\n",
    "# learning rate는 오차 조절량을 제어하는 역할을 한다.\n",
    "batch_num = y_hat.shape[0]\n",
    "dy = (y_hat - t) / batch_num\n",
    "dy    # softmax값의 출력으로 Loss를 미분한 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02000157, -0.03681739,  0.05042109,  0.04233693, -0.12677483,\n",
       "        -0.02836469,  0.05912252,  0.04469822,  0.03098562, -0.01560589],\n",
       "       [-0.0108912 , -0.0428971 ,  0.0712097 ,  0.05950626, -0.13251144,\n",
       "        -0.02315824,  0.08307951,  0.06204028,  0.04326498, -0.10964274],\n",
       "       [-0.07466411, -0.07492254,  0.05972919,  0.05270195, -0.03476986,\n",
       "        -0.05351318,  0.06858678,  0.05229787,  0.03627981, -0.03172591],\n",
       "       [-0.01853447, -0.0159273 ,  0.05351696,  0.04484748, -0.09225287,\n",
       "        -0.04143497,  0.06130006,  0.0458841 ,  0.03224661, -0.0696456 ],\n",
       "       [-0.03358303, -0.03225441,  0.0509029 ,  0.04299359, -0.10949132,\n",
       "        -0.02258083,  0.05965255,  0.04503491,  0.03123615, -0.03191051],\n",
       "       [-0.03033944, -0.05136092,  0.0425265 ,  0.03643461, -0.0754271 ,\n",
       "        -0.00534674,  0.05050458,  0.03820995,  0.02626903, -0.03147047],\n",
       "       [-0.04504446, -0.04270813,  0.04018564,  0.0346088 , -0.0774731 ,\n",
       "        -0.0081464 ,  0.04775304,  0.03633182,  0.02494145, -0.01044867],\n",
       "       [-0.02389729, -0.02031682,  0.02659355,  0.02292697, -0.02690508,\n",
       "        -0.01949824,  0.03055489,  0.02306526,  0.01609416, -0.0286174 ],\n",
       "       [-0.06430069, -0.06052374,  0.05979497,  0.05193808, -0.0550457 ,\n",
       "        -0.02647124,  0.06957214,  0.05262408,  0.03646448, -0.06405237],\n",
       "       [ 0.01939404, -0.11432583,  0.06011018,  0.05170824, -0.08623065,\n",
       "        -0.06867001,  0.06912219,  0.05244471,  0.03638586, -0.01993872],\n",
       "       [-0.05233645,  0.0039795 ,  0.05767615,  0.04896003, -0.05678119,\n",
       "        -0.05739043,  0.06489781,  0.0485751 ,  0.03440332, -0.09198384],\n",
       "       [-0.07244659, -0.06430186,  0.06244311,  0.054415  , -0.06648056,\n",
       "        -0.04376671,  0.07229185,  0.05496634,  0.03810091, -0.03522149],\n",
       "       [-0.08401177, -0.09906321,  0.08747185,  0.07650983, -0.06579077,\n",
       "        -0.09408534,  0.0997158 ,  0.07584376,  0.05285674, -0.0494469 ],\n",
       "       [-0.05056761, -0.01044106,  0.02709944,  0.02405998,  0.00436418,\n",
       "        -0.04087455,  0.02997813,  0.0228296 ,  0.01612603, -0.02257412],\n",
       "       [-0.01141626, -0.01532862,  0.03530468,  0.02964992, -0.04994486,\n",
       "        -0.01534428,  0.04076832,  0.03038288,  0.02129315, -0.06536492],\n",
       "       [-0.06749297, -0.08692164,  0.06410265,  0.05641788, -0.0460836 ,\n",
       "        -0.06264287,  0.07356063,  0.05611309,  0.03892499, -0.02597817],\n",
       "       [-0.0479048 , -0.0180914 ,  0.05156297,  0.04385672, -0.09836585,\n",
       "        -0.0524449 ,  0.05907751,  0.04479983,  0.03133529, -0.01382537],\n",
       "       [-0.07140807, -0.04965715,  0.05248498,  0.0454297 , -0.08817751,\n",
       "        -0.01182424,  0.06213605,  0.04729006,  0.03251125, -0.01878506],\n",
       "       [-0.10821295, -0.06384445,  0.07477303,  0.0654803 , -0.03930396,\n",
       "        -0.03437176,  0.08654989,  0.06549936,  0.04547358, -0.09204304],\n",
       "       [-0.09290314, -0.03318704,  0.07302921,  0.06309086, -0.0625506 ,\n",
       "        -0.04727116,  0.08380583,  0.06321137,  0.0441819 , -0.09140723],\n",
       "       [-0.07571877, -0.00393185,  0.0543713 ,  0.04677219, -0.05867725,\n",
       "        -0.05552731,  0.06156904,  0.04654633,  0.03274526, -0.04814893],\n",
       "       [-0.0466614 , -0.05153761,  0.05937901,  0.0517202 , -0.03507649,\n",
       "        -0.09081691,  0.06624704,  0.05027618,  0.03540895, -0.03893897],\n",
       "       [-0.08987235, -0.04237863,  0.04787484,  0.04205982, -0.05368318,\n",
       "        -0.01205012,  0.05639713,  0.04303875,  0.02960183, -0.0209881 ],\n",
       "       [-0.05686797, -0.0728832 ,  0.07215825,  0.06235235, -0.05707426,\n",
       "        -0.03238264,  0.0836173 ,  0.06293496,  0.04375105, -0.10560583],\n",
       "       [-0.06476031, -0.07879102,  0.06705532,  0.05751832, -0.10870793,\n",
       "         0.02956169,  0.08091536,  0.0609828 ,  0.04170677, -0.085481  ],\n",
       "       [-0.09906131, -0.06664883,  0.08224724,  0.07181514, -0.03861856,\n",
       "        -0.06456026,  0.09396371,  0.07104297,  0.04961041, -0.09979051],\n",
       "       [-0.04857313, -0.05684446,  0.04979655,  0.04337077, -0.03306178,\n",
       "        -0.02172835,  0.0578245 ,  0.04366683,  0.03027381, -0.06472473],\n",
       "       [-0.04657912, -0.02902991,  0.0548326 ,  0.04671268, -0.08604322,\n",
       "        -0.03435923,  0.06342031,  0.04783338,  0.03335211, -0.0501396 ],\n",
       "       [-0.05045332, -0.09074375,  0.04879637,  0.043206  , -0.00220786,\n",
       "         0.00853016,  0.05787388,  0.04367348,  0.02991929, -0.08859427],\n",
       "       [-0.0479422 ,  0.01701876,  0.04968071,  0.04177428, -0.0636582 ,\n",
       "        -0.03743246,  0.05633354,  0.04202934,  0.02974953, -0.0875533 ],\n",
       "       [-0.04250349, -0.05868547,  0.06107473,  0.05301517, -0.05079813,\n",
       "        -0.08330994,  0.06876206,  0.05217927,  0.03661179, -0.03634599],\n",
       "       [-0.03296495, -0.06337144,  0.05004241,  0.04341758, -0.02673734,\n",
       "        -0.01773378,  0.05812412,  0.04368961,  0.03031688, -0.08478308],\n",
       "       [-0.07554896,  0.00615017,  0.05343175,  0.04529485, -0.08153761,\n",
       "        -0.0110146 ,  0.06222088,  0.04668415,  0.03259498, -0.0782756 ],\n",
       "       [-0.06331451, -0.05524002,  0.08045696,  0.06893614, -0.11067255,\n",
       "        -0.06877688,  0.09235623,  0.06981142,  0.04874823, -0.06230503],\n",
       "       [-0.06188809, -0.06744704,  0.06156076,  0.053293  , -0.07757647,\n",
       "        -0.02195707,  0.07217655,  0.05468222,  0.03775842, -0.05060228],\n",
       "       [-0.02622664, -0.01724837,  0.05568288,  0.04754369, -0.04435963,\n",
       "        -0.0906459 ,  0.06141888,  0.04616489,  0.03286678, -0.06519657],\n",
       "       [-0.01862836, -0.118545  ,  0.05393515,  0.04714732, -0.04714224,\n",
       "        -0.00150071,  0.06424973,  0.0486195 ,  0.0332176 , -0.06135298],\n",
       "       [-0.03940066, -0.09650381,  0.06562529,  0.05703937, -0.07025433,\n",
       "        -0.04735336,  0.07611002,  0.05776119,  0.03997184, -0.04299554],\n",
       "       [-0.03434351, -0.06363614,  0.05822843,  0.05016518, -0.07239046,\n",
       "        -0.04888996,  0.06706063,  0.05076285,  0.03532056, -0.04227756],\n",
       "       [ 0.00851291, -0.05251736,  0.03096084,  0.02625469, -0.06387153,\n",
       "        -0.016157  ,  0.03646897,  0.02755706,  0.0189915 , -0.01620008],\n",
       "       [-0.02131441, -0.06808221,  0.04587172,  0.03969127, -0.05108524,\n",
       "        -0.02541057,  0.0534547 ,  0.04043812,  0.02796149, -0.04152487],\n",
       "       [-0.04501335,  0.00027182,  0.06438534,  0.05403769, -0.1275835 ,\n",
       "        -0.06796163,  0.07323256,  0.05514345,  0.0388426 , -0.04535497],\n",
       "       [-0.09341838, -0.06135265,  0.08514353,  0.07434636, -0.02900232,\n",
       "        -0.09843164,  0.09579513,  0.072452  ,  0.05091906, -0.09645108],\n",
       "       [-0.02913396, -0.0640172 ,  0.03744671,  0.03249447, -0.0512212 ,\n",
       "         0.00815055,  0.04503459,  0.03410067,  0.02326209, -0.0361167 ],\n",
       "       [-0.02920475, -0.02423426,  0.03725602,  0.03175605, -0.04929021,\n",
       "        -0.01165867,  0.0434162 ,  0.03260104,  0.0226781 , -0.05331951],\n",
       "       [-0.02026706, -0.07920434,  0.0472596 ,  0.04076365, -0.05563498,\n",
       "         0.00617805,  0.05638576,  0.0424556 ,  0.02910665, -0.06704292],\n",
       "       [-0.07355743, -0.04944976,  0.05809258,  0.05050006, -0.05572543,\n",
       "        -0.02859147,  0.06746141,  0.05109845,  0.03544074, -0.05526915],\n",
       "       [-0.10354767, -0.05679382,  0.06697144,  0.05913637, -0.01499556,\n",
       "        -0.0601668 ,  0.07624226,  0.05792282,  0.04041648, -0.06518553],\n",
       "       [-0.07442106, -0.04466172,  0.04850996,  0.04222033, -0.07205866,\n",
       "        -0.01429349,  0.05722296,  0.04361346,  0.03000652, -0.01613831],\n",
       "       [-0.08130959,  0.00216436,  0.04114032,  0.03592765, -0.04461089,\n",
       "        -0.06576657,  0.04588329,  0.03514816,  0.02477692,  0.00664634]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dW2 = np.dot(z1.T, dy)    \n",
    "dW2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dW2 = np.dot(z1.T, dy)\n",
    "db2 = np.sum(dy, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_grad(x):\n",
    "    return (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "\n",
    "dz1 = np.dot(dy, W2.T)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dW1 = np.dot(X.T, da1)\n",
    "db1 = np.sum(dz1, axis=0)\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "def update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수를 통해 오차를 구하여 입력층에 기울기를 적용시킨다.\n",
    "# 이 과정을 오차역전파법이라 한다.\n",
    "# 오차값을 각 레이어들을 지나 역전파해가며 각 노드가 가지고 있는 변수들을 갱신한다.\n",
    "\n",
    "# 해당 레이어의 backprogation함수\n",
    "def affine_layer_backward(dy, cache):\n",
    "    X, W, b = cache\n",
    "    dX = np.dot(dy, W.T)\n",
    "    dW = np.dot(X.T, dy)\n",
    "    db = np.sum(dy, axis=0)\n",
    "    return dX, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04939162 0.05734545 0.15371397 0.05566295 0.14706605 0.06852143\n",
      "  0.10377914 0.095726   0.10272379 0.1660696 ]\n",
      " [0.05898099 0.07509652 0.1470277  0.05914956 0.15275834 0.06779289\n",
      "  0.10505894 0.09505447 0.10247455 0.13660605]\n",
      " [0.05937491 0.05602917 0.14276522 0.0545178  0.11394332 0.05675313\n",
      "  0.11592725 0.10611544 0.12475436 0.16981941]\n",
      " [0.0614667  0.06868427 0.14032856 0.06147123 0.09528766 0.07733602\n",
      "  0.12014203 0.09519312 0.11092718 0.16916322]\n",
      " [0.05766159 0.05534325 0.14621546 0.06751288 0.11841122 0.06563081\n",
      "  0.10528701 0.08885056 0.10993283 0.1851544 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.409600632245753\n"
     ]
    }
   ],
   "source": [
    "# forward propagation과 backwordpropagation이 진행 과정을 정리하면 다음과 같다.\n",
    "# 파라미터 초기화\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "# Forward Propagation\n",
    "a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "z1 = sigmoid(a1)\n",
    "a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "\n",
    "# 추론과 오차(Loss) 계산\n",
    "y_hat = softmax(a2)\n",
    "t = _change_ont_hot_label(Y_digit, 10)   # 정답 One-hot 인코딩\n",
    "Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "print(y_hat)\n",
    "print(t)\n",
    "print('Loss: ', Loss)\n",
    "        \n",
    "dy = (y_hat - t) / X.shape[0]\n",
    "dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "da1 = sigmoid_grad(a1) * dz1\n",
    "dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "\n",
    "# 경사하강법을 통한 파라미터 업데이트    \n",
    "learning_rate = 0.1\n",
    "W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업데이트가 되는지, 오차가 줄어드는지 확인해보자. 5번 실행\n",
    "W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "b1 = np.zeros(hidden_size)\n",
    "W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "b2 = np.zeros(output_size)\n",
    "\n",
    "def train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=False):\n",
    "    a1, cache1 = affine_layer_forward(X, W1, b1)\n",
    "    z1 = sigmoid(a1)\n",
    "    a2, cache2 = affine_layer_forward(z1, W2, b2)\n",
    "    y_hat = softmax(a2)\n",
    "    t = _change_ont_hot_label(Y, 10)\n",
    "    Loss = cross_entropy_error(y_hat, t)\n",
    "\n",
    "    if verbose:\n",
    "        print('---------')\n",
    "        print(y_hat)\n",
    "        print(t)\n",
    "        print('Loss: ', Loss)\n",
    "        \n",
    "    dy = (y_hat - t) / X.shape[0]\n",
    "    dz1, dW2, db2 = affine_layer_backward(dy, cache2)\n",
    "    da1 = sigmoid_grad(a1) * dz1\n",
    "    dX, dW1, db1 = affine_layer_backward(da1, cache1)\n",
    "    \n",
    "    W1, b1, W2, b2 = update_params(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate)\n",
    "    \n",
    "    return W1, b1, W2, b2, Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "[[0.0985465  0.13063865 0.07819409 0.11775272 0.10303449 0.09714935\n",
      "  0.05628883 0.13772296 0.07096615 0.10970627]\n",
      " [0.10701036 0.12521054 0.06620749 0.11992773 0.09053762 0.10106276\n",
      "  0.06345293 0.15212705 0.06499075 0.10947277]\n",
      " [0.09405254 0.1132635  0.09699056 0.13013406 0.0888859  0.10478239\n",
      "  0.08306635 0.11146161 0.0747961  0.10256699]\n",
      " [0.10142991 0.12839478 0.094127   0.10032228 0.1137637  0.1077652\n",
      "  0.06204121 0.10305896 0.08646453 0.10263244]\n",
      " [0.08171157 0.11914325 0.08470472 0.12448074 0.09862124 0.10893603\n",
      "  0.06778457 0.12263219 0.08155389 0.1104318 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.248547993116281\n",
      "---------\n",
      "[[0.11391919 0.14147792 0.06810922 0.0986399  0.11544425 0.11378899\n",
      "  0.05046283 0.11199709 0.06265598 0.12350464]\n",
      " [0.12823683 0.13436665 0.05757591 0.10073772 0.10182386 0.11539136\n",
      "  0.05686358 0.12520101 0.05704353 0.12275955]\n",
      " [0.10715893 0.12223027 0.08600856 0.11042853 0.10435375 0.1179992\n",
      "  0.07545749 0.09339481 0.06706298 0.11590549]\n",
      " [0.11319478 0.14378912 0.08255988 0.08418098 0.12507459 0.12028011\n",
      "  0.05553974 0.08497808 0.07646997 0.11393277]\n",
      " [0.09377496 0.12943553 0.07437343 0.10423384 0.11149706 0.12359152\n",
      "  0.06060181 0.1010842  0.07216164 0.12924602]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  2.094539953999226\n",
      "---------\n",
      "[[0.12710782 0.14877509 0.05934125 0.08365505 0.12519749 0.12871435\n",
      "  0.0449789  0.09273803 0.05518374 0.13430829]\n",
      " [0.14830823 0.13993378 0.05003671 0.08557875 0.11072568 0.12717534\n",
      "  0.05061096 0.10484558 0.04988829 0.13289667]\n",
      " [0.11818731 0.12839931 0.07630444 0.0948455  0.11885465 0.12871541\n",
      "  0.06824393 0.07957342 0.06002583 0.1268502 ]\n",
      " [0.12269166 0.15712982 0.07263311 0.07162032 0.13387275 0.13045669\n",
      "  0.04960724 0.07139954 0.0676875  0.12290138]\n",
      " [0.10390633 0.13653241 0.06527391 0.08832469 0.1219982  0.13548193\n",
      "  0.05385794 0.08480352 0.06368036 0.1461407 ]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.9724689074262038\n",
      "---------\n",
      "[[0.13823672 0.15361293 0.05195399 0.07185101 0.13274616 0.14209192\n",
      "  0.04010459 0.0780546  0.0487433  0.14260477]\n",
      " [0.16715767 0.14300938 0.04365674 0.07355608 0.11760352 0.13672043\n",
      "  0.04501732 0.08917978 0.04371032 0.14038875]\n",
      " [0.12723545 0.13255686 0.06797915 0.08243391 0.1324668  0.13722329\n",
      "  0.06175462 0.06879298 0.05386287 0.13569408]\n",
      " [0.13015729 0.16907411 0.06429072 0.06174025 0.14061047 0.13864531\n",
      "  0.04440412 0.06096922 0.06018424 0.12992427]\n",
      " [0.11221171 0.14134501 0.05751886 0.07575112 0.13045586 0.14495322\n",
      "  0.0478572  0.07226621 0.05632894 0.16131187]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.8726711851801725\n",
      "---------\n",
      "[[0.14750936 0.15682044 0.04579914 0.06246157 0.13852336 0.15416217\n",
      "  0.03588162 0.06665913 0.04328858 0.14889463]\n",
      " [0.18483017 0.14442859 0.03831944 0.06393402 0.12282013 0.14438541\n",
      "  0.04014483 0.07691316 0.03846938 0.14575487]\n",
      " [0.13448465 0.13532492 0.06091673 0.07244409 0.14533087 0.14386824\n",
      "  0.05605674 0.06023567 0.04855337 0.14278473]\n",
      " [0.13585068 0.18016201 0.0573183  0.05386335 0.1456917  0.14519361\n",
      "  0.03991575 0.05279172 0.0538367  0.13537619]\n",
      " [0.11886949 0.14459378 0.05099257 0.06571425 0.13722094 0.15240298\n",
      "  0.04264659 0.0624389  0.05006638 0.17505413]]\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Loss:  1.7886738303348462\n"
     ]
    }
   ],
   "source": [
    "X = x_train_reshaped[:5]\n",
    "Y = y_train[:5]\n",
    "\n",
    "# train_step을 다섯 번 반복 돌립니다.\n",
    "for i in range(5):\n",
    "    W1, b1, W2, b2, _ = train_step(X, Y, W1, b1, W2, b2, learning_rate=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15515236, 0.15896903, 0.04067735, 0.05490438, 0.14289375,\n",
       "       0.16517098, 0.03226012, 0.05766489, 0.03869318, 0.15361396])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(W1, b1, W2, b2, X):\n",
    "    a1 = np.dot(X, W1) + b1\n",
    "    z1 = sigmoid(a1)\n",
    "    a2 = np.dot(z1, W2) + b2\n",
    "    y = softmax(a2)\n",
    "\n",
    "    return y\n",
    "\n",
    "# X = x_train[:100] 에 대해 모델 추론을 시도합니다. \n",
    "\n",
    "X = x_train_reshaped[:100]\n",
    "Y = y_test[:100]\n",
    "result = predict(W1, b1, W2, b2, X)\n",
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15515236 0.15896903 0.04067735 0.05490438 0.14289375 0.16517098\n",
      " 0.03226012 0.05766489 0.03869318 0.15361396]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "0.09\n"
     ]
    }
   ],
   "source": [
    "# 정확도?\n",
    "def accuracy(W1, b1, W2, b2, x, y):\n",
    "    y_hat = predict(W1, b1, W2, b2, x)\n",
    "    y_hat = np.argmax(y_hat, axis=1)\n",
    "   # t = np.argmax(t, axis=1)\n",
    "\n",
    "    accuracy = np.sum(y_hat == y) / float(x.shape[0])\n",
    "    return accuracy\n",
    "\n",
    "acc = accuracy(W1, b1, W2, b2, X, Y)\n",
    "\n",
    "t = _change_ont_hot_label(Y, 10)\n",
    "print(result[0])\n",
    "print(t[0])\n",
    "print(acc)\n",
    "\n",
    "# 5번 업데이트 결과(9%의 정확도)로는 아직 부족하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 50)\n",
      "(50,)\n",
      "(50, 10)\n",
      "(10,)\n",
      "Loss:  2.303244163741123\n",
      "train acc, test acc | 0.09915, 0.1009\n",
      "Loss:  0.801135338263419\n",
      "train acc, test acc | 0.78995, 0.7941\n",
      "Loss:  0.39574376541149875\n",
      "train acc, test acc | 0.8772666666666666, 0.8814\n",
      "Loss:  0.3588200414900465\n",
      "train acc, test acc | 0.89955, 0.9012\n",
      "Loss:  0.3489193654390701\n",
      "train acc, test acc | 0.90905, 0.9124\n",
      "Loss:  0.3055275626445065\n",
      "train acc, test acc | 0.9144333333333333, 0.9158\n",
      "Loss:  0.3462628514196568\n",
      "train acc, test acc | 0.9198833333333334, 0.9219\n",
      "Loss:  0.19463889644846122\n",
      "train acc, test acc | 0.9240333333333334, 0.9254\n",
      "Loss:  0.25163090795510057\n",
      "train acc, test acc | 0.9275333333333333, 0.9296\n",
      "Loss:  0.18666463224973698\n",
      "train acc, test acc | 0.9302166666666667, 0.9328\n",
      "Loss:  0.2519576460481283\n",
      "train acc, test acc | 0.9334166666666667, 0.9362\n",
      "Loss:  0.17119298524391738\n",
      "train acc, test acc | 0.9363166666666667, 0.9361\n",
      "Loss:  0.2570291948913646\n",
      "train acc, test acc | 0.9385666666666667, 0.9387\n",
      "Loss:  0.22355015089312213\n",
      "train acc, test acc | 0.9410333333333334, 0.9411\n",
      "Loss:  0.2372414388371265\n",
      "train acc, test acc | 0.9425, 0.9419\n",
      "Loss:  0.3317681740628363\n",
      "train acc, test acc | 0.9447333333333333, 0.9441\n",
      "Loss:  0.2687362748977222\n",
      "train acc, test acc | 0.9469833333333333, 0.9443\n",
      "Loss:  0.28344729779745687\n",
      "train acc, test acc | 0.9478333333333333, 0.9456\n",
      "Loss:  0.1787667173491446\n",
      "train acc, test acc | 0.9492666666666667, 0.9465\n",
      "Loss:  0.20903917047412257\n",
      "train acc, test acc | 0.9506666666666667, 0.9466\n",
      "Loss:  0.15795593358991392\n",
      "train acc, test acc | 0.9519, 0.9466\n",
      "Loss:  0.09293710028266507\n",
      "train acc, test acc | 0.9531833333333334, 0.9491\n",
      "Loss:  0.22233796077855683\n",
      "train acc, test acc | 0.9544333333333334, 0.9506\n",
      "Loss:  0.13744662213800413\n",
      "train acc, test acc | 0.95585, 0.951\n",
      "Loss:  0.08405462053779184\n",
      "train acc, test acc | 0.9563166666666667, 0.9513\n",
      "Loss:  0.10249553822659195\n",
      "train acc, test acc | 0.9571333333333333, 0.9527\n",
      "Loss:  0.25125990922450986\n",
      "train acc, test acc | 0.9587333333333333, 0.9524\n",
      "Loss:  0.14800206894845722\n",
      "train acc, test acc | 0.9594666666666667, 0.9545\n",
      "Loss:  0.07967244882392746\n",
      "train acc, test acc | 0.9603, 0.9545\n",
      "Loss:  0.19078783321503298\n",
      "train acc, test acc | 0.9617166666666667, 0.9553\n",
      "Loss:  0.15321500196716642\n",
      "train acc, test acc | 0.9622833333333334, 0.9566\n",
      "Loss:  0.1659750868093269\n",
      "train acc, test acc | 0.96335, 0.9565\n",
      "Loss:  0.14530178939770635\n",
      "train acc, test acc | 0.9643333333333334, 0.9576\n",
      "Loss:  0.17246022300706482\n",
      "train acc, test acc | 0.96455, 0.9581\n",
      "Loss:  0.16056142631576242\n",
      "train acc, test acc | 0.96515, 0.9577\n",
      "Loss:  0.07551549948025559\n",
      "train acc, test acc | 0.9658, 0.959\n",
      "Loss:  0.08651637443110641\n",
      "train acc, test acc | 0.96685, 0.9599\n",
      "Loss:  0.09126167159447895\n",
      "train acc, test acc | 0.9677333333333333, 0.9606\n",
      "Loss:  0.12524843944113367\n",
      "train acc, test acc | 0.9682666666666667, 0.96\n",
      "Loss:  0.05819587950201306\n",
      "train acc, test acc | 0.9687833333333333, 0.9599\n",
      "Loss:  0.07773391946842541\n",
      "train acc, test acc | 0.9691666666666666, 0.9606\n",
      "Loss:  0.09822341879680035\n",
      "train acc, test acc | 0.9697666666666667, 0.9609\n",
      "Loss:  0.07892967853129818\n",
      "train acc, test acc | 0.9702166666666666, 0.9616\n",
      "Loss:  0.12161528246707773\n",
      "train acc, test acc | 0.9710333333333333, 0.9616\n",
      "Loss:  0.06380748541559282\n",
      "train acc, test acc | 0.9709166666666667, 0.962\n",
      "Loss:  0.05204507191548468\n",
      "train acc, test acc | 0.9718833333333333, 0.9619\n",
      "Loss:  0.13968467296291343\n",
      "train acc, test acc | 0.9720166666666666, 0.9624\n",
      "Loss:  0.14116198401639998\n",
      "train acc, test acc | 0.9727, 0.9623\n",
      "Loss:  0.04748335177532853\n",
      "train acc, test acc | 0.9729333333333333, 0.963\n",
      "Loss:  0.11026297992107949\n",
      "train acc, test acc | 0.9738333333333333, 0.9638\n",
      "Loss:  0.043237130902492316\n",
      "train acc, test acc | 0.97455, 0.9637\n",
      "Loss:  0.1430772433340698\n",
      "train acc, test acc | 0.9746166666666667, 0.9647\n",
      "Loss:  0.045411544543664556\n",
      "train acc, test acc | 0.97455, 0.9643\n",
      "Loss:  0.09466555293939585\n",
      "train acc, test acc | 0.9755166666666667, 0.9653\n",
      "Loss:  0.1479992474762869\n",
      "train acc, test acc | 0.9752833333333333, 0.9646\n",
      "Loss:  0.05124466265392501\n",
      "train acc, test acc | 0.9761333333333333, 0.9663\n",
      "Loss:  0.06956272487055687\n",
      "train acc, test acc | 0.9767333333333333, 0.9663\n",
      "Loss:  0.031798349047010774\n",
      "train acc, test acc | 0.9773333333333334, 0.9665\n",
      "Loss:  0.07335583811806054\n",
      "train acc, test acc | 0.9773833333333334, 0.967\n",
      "Loss:  0.04229564946681618\n",
      "train acc, test acc | 0.9775833333333334, 0.9673\n",
      "Loss:  0.10150659376880151\n",
      "train acc, test acc | 0.9775833333333334, 0.9668\n",
      "Loss:  0.02011644820729823\n",
      "train acc, test acc | 0.9781833333333333, 0.968\n",
      "Loss:  0.08057204676931054\n",
      "train acc, test acc | 0.9778666666666667, 0.9668\n",
      "Loss:  0.04939219203519704\n",
      "train acc, test acc | 0.9787166666666667, 0.9669\n",
      "Loss:  0.07763269199189997\n",
      "train acc, test acc | 0.9787166666666667, 0.9672\n",
      "Loss:  0.1738955576846356\n",
      "train acc, test acc | 0.9795166666666667, 0.9677\n",
      "Loss:  0.0856526020507329\n",
      "train acc, test acc | 0.9796, 0.9665\n",
      "Loss:  0.020000521023722448\n",
      "train acc, test acc | 0.9800666666666666, 0.9673\n",
      "Loss:  0.06246251207249938\n",
      "train acc, test acc | 0.9801166666666666, 0.9672\n",
      "Loss:  0.0808902735416863\n",
      "train acc, test acc | 0.98025, 0.9683\n",
      "Loss:  0.07788271485713516\n",
      "train acc, test acc | 0.98075, 0.9684\n",
      "Loss:  0.05486217365578058\n",
      "train acc, test acc | 0.9808166666666667, 0.9682\n",
      "Loss:  0.07251942230851569\n",
      "train acc, test acc | 0.981, 0.9686\n",
      "Loss:  0.03465498252313034\n",
      "train acc, test acc | 0.9812333333333333, 0.9689\n",
      "Loss:  0.09211271768682533\n",
      "train acc, test acc | 0.9817833333333333, 0.9683\n",
      "Loss:  0.12072749789788569\n",
      "train acc, test acc | 0.98185, 0.9693\n",
      "Loss:  0.09688547606432234\n",
      "train acc, test acc | 0.9820833333333333, 0.969\n",
      "Loss:  0.05915876221495511\n",
      "train acc, test acc | 0.9822333333333333, 0.9684\n",
      "Loss:  0.024085631410575337\n",
      "train acc, test acc | 0.9822, 0.9695\n",
      "Loss:  0.10343710442495507\n",
      "train acc, test acc | 0.98235, 0.97\n",
      "Loss:  0.06803797469649756\n",
      "train acc, test acc | 0.9828666666666667, 0.9696\n",
      "Loss:  0.08172211630277165\n",
      "train acc, test acc | 0.9828666666666667, 0.9704\n",
      "Loss:  0.05687494457645565\n",
      "train acc, test acc | 0.9830666666666666, 0.9706\n",
      "Loss:  0.046042171275278265\n",
      "train acc, test acc | 0.9831, 0.9712\n"
     ]
    }
   ],
   "source": [
    "# 전체 학습\n",
    "def init_params(input_size, hidden_size, output_size, weight_init_std=0.01):\n",
    "\n",
    "    W1 = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "    b1 = np.zeros(hidden_size)\n",
    "    W2 = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "    b2 = np.zeros(output_size)\n",
    "\n",
    "    print(W1.shape)\n",
    "    print(b1.shape)\n",
    "    print(W2.shape)\n",
    "    print(b2.shape)\n",
    "    \n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# 하이퍼파라미터\n",
    "iters_num = 50000  # 반복 횟수를 적절히 설정한다.\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "W1, b1, W2, b2 = init_params(784, 50, 10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치 획득\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train_reshaped[batch_mask]\n",
    "    y_batch = y_train[batch_mask]\n",
    "    \n",
    "    W1, b1, W2, b2, Loss = train_step(x_batch, y_batch, W1, b1, W2, b2, learning_rate=0.1, verbose=False)\n",
    "\n",
    "    # 학습 경과 기록\n",
    "    train_loss_list.append(Loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        print('Loss: ', Loss)\n",
    "        train_acc = accuracy(W1, b1, W2, b2, x_train_reshaped, y_train)\n",
    "        test_acc = accuracy(W1, b1, W2, b2, x_test_reshaped, y_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "        \n",
    "# numpy는 GPU 지원하지 않음.\n",
    "# numpy만으로도 딥러닝이 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 12, 6 \n",
    "\n",
    "# Accuracy 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss 그래프 그리기\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim(0, 3.0)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
