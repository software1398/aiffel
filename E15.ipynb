{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E15 - 단어 수준의 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154982</th>\n",
       "      <td>They have been reading an interesting book.</td>\n",
       "      <td>Ils ont lu un livre intéressant.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159222</th>\n",
       "      <td>A tuft of hair showed from underneath her cap.</td>\n",
       "      <td>Une touffe de cheveux apparaissait du dessous ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31006</th>\n",
       "      <td>It's still in limbo.</td>\n",
       "      <td>C'est toujours dans les limbes.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162695</th>\n",
       "      <td>How long did it take you to translate this book?</td>\n",
       "      <td>Combien de temps avez-vous mis pour traduire c...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88058</th>\n",
       "      <td>What are you so happy about?</td>\n",
       "      <td>Pourquoi es-tu si heureux ?</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     eng  \\\n",
       "154982       They have been reading an interesting book.   \n",
       "159222    A tuft of hair showed from underneath her cap.   \n",
       "31006                               It's still in limbo.   \n",
       "162695  How long did it take you to translate this book?   \n",
       "88058                       What are you so happy about?   \n",
       "\n",
       "                                                      fra  \\\n",
       "154982                   Ils ont lu un livre intéressant.   \n",
       "159222  Une touffe de cheveux apparaissait du dessous ...   \n",
       "31006                     C'est toujours dans les limbes.   \n",
       "162695  Combien de temps avez-vous mis pour traduire c...   \n",
       "88058                         Pourquoi es-tu si heureux ?   \n",
       "\n",
       "                                                       cc  \n",
       "154982  CC-BY 2.0 (France) Attribution: tatoeba.org #7...  \n",
       "159222  CC-BY 2.0 (France) Attribution: tatoeba.org #1...  \n",
       "31006   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "162695  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "88058   CC-BY 2.0 (France) Attribution: tatoeba.org #7...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25642</th>\n",
       "      <td>Love is not enough.</td>\n",
       "      <td>L'amour ne suffit pas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48639</th>\n",
       "      <td>I know it's not a joke.</td>\n",
       "      <td>Je sais que ce n'est pas une blague.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21193</th>\n",
       "      <td>The rumor is true.</td>\n",
       "      <td>La rumeur est vraie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21099</th>\n",
       "      <td>The bar is closed.</td>\n",
       "      <td>Le bar est fermé.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21771</th>\n",
       "      <td>Was that too hard?</td>\n",
       "      <td>Était-ce trop difficile ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng                                   fra\n",
       "25642      Love is not enough.                L'amour ne suffit pas.\n",
       "48639  I know it's not a joke.  Je sais que ce n'est pas une blague.\n",
       "21193       The rumor is true.                  La rumeur est vraie.\n",
       "21099       The bar is closed.                     Le bar est fermé.\n",
       "21771       Was that too hard?             Était-ce trop difficile ?"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][20000:53000] # 3만3천개의 샘플 사용, 세 번째 열은 제외\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 구현\n",
    "import re\n",
    "\n",
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess(cols, sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,¿'-])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"[-]\", r\" \", sentence)\n",
    "    sentence = re.sub(r\"\\s+\", r\" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    if cols == 'fra':\n",
    "        sentence = sos_token + sentence + eos_token\n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52795</th>\n",
       "      <td>you can use my bicycle .</td>\n",
       "      <td>&lt;start&gt; tu peux utiliser mon vélo . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28512</th>\n",
       "      <td>do you go out a lot ?</td>\n",
       "      <td>&lt;start&gt; est ce que tu sors souvent ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22760</th>\n",
       "      <td>you ' re the oldest .</td>\n",
       "      <td>&lt;start&gt; c ' est toi le doyen . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29605</th>\n",
       "      <td>i don ' t take bribes .</td>\n",
       "      <td>&lt;start&gt; je ne prends pas les pots de vin . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45492</th>\n",
       "      <td>we ' re completely lost .</td>\n",
       "      <td>&lt;start&gt; nous sommes complètement égarées . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47031</th>\n",
       "      <td>do what you have to do .</td>\n",
       "      <td>&lt;start&gt; faites ce que vous avez à faire . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48875</th>\n",
       "      <td>i remember saying that .</td>\n",
       "      <td>&lt;start&gt; je me rappelle avoir dit ça . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48892</th>\n",
       "      <td>i sat down next to him .</td>\n",
       "      <td>&lt;start&gt; je me suis assise auprès de lui . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20603</th>\n",
       "      <td>no one can escape .</td>\n",
       "      <td>&lt;start&gt; personne ne peut s ' échapper . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40104</th>\n",
       "      <td>all we can do is wait .</td>\n",
       "      <td>&lt;start&gt; tout ce que nous pouvons faire , c ' e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             eng  \\\n",
       "52795   you can use my bicycle .   \n",
       "28512      do you go out a lot ?   \n",
       "22760      you ' re the oldest .   \n",
       "29605    i don ' t take bribes .   \n",
       "45492  we ' re completely lost .   \n",
       "47031   do what you have to do .   \n",
       "48875   i remember saying that .   \n",
       "48892   i sat down next to him .   \n",
       "20603        no one can escape .   \n",
       "40104    all we can do is wait .   \n",
       "\n",
       "                                                     fra  \n",
       "52795          <start> tu peux utiliser mon vélo . <end>  \n",
       "28512         <start> est ce que tu sors souvent ? <end>  \n",
       "22760               <start> c ' est toi le doyen . <end>  \n",
       "29605   <start> je ne prends pas les pots de vin . <end>  \n",
       "45492   <start> nous sommes complètement égarées . <end>  \n",
       "47031    <start> faites ce que vous avez à faire . <end>  \n",
       "48875        <start> je me rappelle avoir dit ça . <end>  \n",
       "48892    <start> je me suis assise auprès de lui . <end>  \n",
       "20603      <start> personne ne peut s ' échapper . <end>  \n",
       "40104  <start> tout ce que nous pouvons faire , c ' e...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng = lines.eng.apply(lambda x: preprocess('eng', x))\n",
    "lines.fra = lines.fra.apply(lambda x: preprocess('fra', x))\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 단어장을 만들기, 영어와 프랑스어별로\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(filters=' ')            # 단어 단위로 Tokenizer를 생성합니다.\n",
    "    tokenizer.fit_on_texts(corpus)                # 33000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "    tensor = tokenizer.texts_to_sequences(corpus) # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 22, 70, 30, 174, 1],\n",
       " [3, 2, 22, 70, 30, 174, 1],\n",
       " [3, 2, 22, 70, 508, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text, eng_tokenizer = tokenize(lines.eng)\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 5, 19, 4, 28, 30, 201, 9, 317, 3, 2],\n",
       " [1, 5, 19, 4, 28, 30, 201, 9, 633, 3, 2],\n",
       " [1, 5, 12, 129, 20, 435, 3, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text, fra_tokenizer = tokenize(lines.fra)\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 5210\n",
      "프랑스어 단어장의 크기 : 9020\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 11\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)\n",
    "# 패딩처리하기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5210\n",
      "프랑스어 단어장의 크기 : 9020\n",
      "영어 시퀀스의 최대 길이 11\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [x[:-1] for x in target_text]\n",
    "# 시작 토큰 제거\n",
    "decoder_target = [x[1:] for x in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 5, 19, 4, 28, 30, 201, 9, 317, 3], [1, 5, 19, 4, 28, 30, 201, 9, 633, 3], [1, 5, 12, 129, 20, 435, 3]]\n",
      "[[5, 19, 4, 28, 30, 201, 9, 317, 3, 2], [5, 19, 4, 28, 30, 201, 9, 633, 3, 2], [5, 12, 129, 20, 435, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in decoder_target:\n",
    "#     print(' '.join(list(map(lambda x: fra_tokenizer.index_word[x], sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 11)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 처리하기\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (30000, 11)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (30000, 20)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (30000, 20)\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터와 검증데이터 분리하기\n",
    "\n",
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input_train))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_train))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "embedding_size = 4096\n",
    "hidden_size = 512\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "# 출력층\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 4096)   21340160    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 4096)   36945920    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 4096)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 4096)   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 512), (None, 9439232     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  9439232     masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9020)   4627260     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 81,791,804\n",
      "Trainable params: 81,791,804\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 37s 315ms/step - loss: 1.7669 - val_loss: 1.4550\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 36s 306ms/step - loss: 1.1048 - val_loss: 1.1968\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 36s 308ms/step - loss: 0.8855 - val_loss: 1.0559\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 36s 308ms/step - loss: 0.7287 - val_loss: 0.9752\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.6073 - val_loss: 0.9165\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.5101 - val_loss: 0.8668\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.4295 - val_loss: 0.8165\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 36s 308ms/step - loss: 0.3629 - val_loss: 0.8096\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.3079 - val_loss: 0.8018\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.2634 - val_loss: 0.7843\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 36s 308ms/step - loss: 0.2268 - val_loss: 0.7866\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.1986 - val_loss: 0.7727\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.1754 - val_loss: 0.7887\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.1562 - val_loss: 0.8000\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.1411 - val_loss: 0.7893\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 37s 310ms/step - loss: 0.1287 - val_loss: 0.7918\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 37s 310ms/step - loss: 0.1184 - val_loss: 0.7943\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 37s 310ms/step - loss: 0.1101 - val_loss: 0.7954\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.1033 - val_loss: 0.7986\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 36s 309ms/step - loss: 0.0974 - val_loss: 0.8043\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='traingin loss', color='red')\n",
    "plt.plot(epochs, val_loss, 'b', label='validation loss', color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 4096)        21340160  \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 4096)        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 512), (None, 512) 9439232   \n",
      "=================================================================\n",
      "Total params: 30,779,392\n",
      "Trainable params: 30,779,392\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 테스트하기\n",
    "\n",
    "# 인코더 정의\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 4096)   36945920    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  9439232     embedding_2[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9020)   4627260     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 51,012,412\n",
      "Trainable params: 51,012,412\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 정의\n",
    "\n",
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2 =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수->단어, 단어->정수\n",
    "\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_sequence(): 입력 인자는 번역하고자 하는 문장의 정수 시퀀스\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: the rain made me late .\n",
      "정답 문장: la pluie m ' a mis en retard .\n",
      "번역기가 번역한 문장: la l l par . . . . \n",
      "-----------------------------------\n",
      "입력 문장: what is its purpose ?\n",
      "정답 문장: quel est son but ?\n",
      "번역기가 번역한 문장: quel est son ? ? ? \n",
      "-----------------------------------\n",
      "입력 문장: he does speak well .\n",
      "정답 문장: il s ' exprime bien .\n",
      "번역기가 번역한 문장: il parle bien . . . \n",
      "-----------------------------------\n",
      "입력 문장: i can ' t talk to tom .\n",
      "정답 문장: je ne peux pas parler à tom .\n",
      "번역기가 번역한 문장: je ne parler tom to\n",
      "-----------------------------------\n",
      "입력 문장: was i polite enough ?\n",
      "정답 문장: ai je été assez polie ?\n",
      "번역기가 번역한 문장: ai assez assez des de\n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "sel_lst = [rd.randint(1, 30000) for _ in range(5)]\n",
    "\n",
    "for seq_index in sel_lst:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index + 20000])\n",
    "    print('정답 문장:', lines.fra[seq_index + 20000][8:-6])\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
