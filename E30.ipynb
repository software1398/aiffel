{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E30 다양한 조건의 음악 생성하기\n",
    "### STEP 1 : MAESTRO 데이터셋을 전처리하여 훈련용 데이터셋 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import concurrent.futures\n",
    "\n",
    "import mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IntervalDim = 100\n",
    "\n",
    "VelocityDim = 32\n",
    "VelocityOffset = IntervalDim\n",
    "\n",
    "NoteOnDim = NoteOffDim = 128\n",
    "NoteOnOffset = IntervalDim + VelocityDim\n",
    "NoteOffOffset = IntervalDim + VelocityDim + NoteOnDim\n",
    "\n",
    "CCDim = 2\n",
    "CCOffset = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim\n",
    "\n",
    "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim + CCDim # 390\n",
    "\n",
    "def get_data(data, length):    \n",
    "    # time augmentation\n",
    "    data[:, 0] *= np.random.uniform(0.80, 1.20)\n",
    "    \n",
    "    # absolute time to relative interval\n",
    "    data[1:, 0] = data[1:, 0] - data[:-1, 0]\n",
    "    data[0, 0] = 0\n",
    "    \n",
    "    # discretize interval into IntervalDim\n",
    "    data[:, 0] = np.clip(np.round(data[:, 0] * IntervalDim), 0, IntervalDim - 1)\n",
    "    \n",
    "    # Note augmentation\n",
    "    data[:, 2] += np.random.randint(-6, 6)\n",
    "    data[:, 2] = np.clip(data[:, 2], 0, NoteOnDim - 1)\n",
    "    \n",
    "    eventlist = []\n",
    "    for d in data:\n",
    "        # append interval\n",
    "        interval = d[0]\n",
    "        eventlist.append(interval)\n",
    "    \n",
    "        # note on case\n",
    "        if d[1] == 1:\n",
    "            velocity = (d[3] / 128) * VelocityDim + VelocityOffset\n",
    "            note = d[2] + NoteOnOffset\n",
    "            eventlist.append(velocity)\n",
    "            eventlist.append(note)\n",
    "            \n",
    "        # note off case\n",
    "        elif d[1] == 0:\n",
    "            note = d[2] + NoteOffOffset\n",
    "            eventlist.append(note)\n",
    "        # CC\n",
    "        elif d[1] == 2:\n",
    "            event = CCOffset + d[3]\n",
    "            eventlist.append(event)\n",
    "            \n",
    "    eventlist = np.array(eventlist).astype(np.int)\n",
    "    \n",
    "    if len(eventlist) > (length+1):\n",
    "        start_index = np.random.randint(0, len(eventlist) - (length+1))\n",
    "        eventlist = eventlist[start_index:start_index+(length+1)]\n",
    "        \n",
    "    # pad zeros\n",
    "    if len(eventlist) < (length+1):\n",
    "        pad = (length+1) - len(eventlist)\n",
    "        eventlist = np.pad(eventlist, (pad, 0), 'constant')\n",
    "        \n",
    "    x = eventlist[:length]\n",
    "    y = eventlist[1:length+1]\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1282,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = os.getenv('HOME') + '/aiffel/music_transformer/data/midi_test.npy'\n",
    "\n",
    "get_midi = np.load(data_path, allow_pickle=True)\n",
    "get_midi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 256\n",
    "train = []\n",
    "labels = []\n",
    "\n",
    "for midi_list in get_midi:\n",
    "    cut_list = [midi_list[i:i+length] for i in range(0, len(midi_list), length)]\n",
    "    for sublist in cut_list:\n",
    "        x, y = get_data(np.array(sublist), length)\n",
    "        train.append(x)\n",
    "        labels.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59268, 256) (59268, 256)\n"
     ]
    }
   ],
   "source": [
    "train = np.array(train)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(train.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pad = pad_sequences(train,\n",
    "                               maxlen=length,\n",
    "                               padding='post',\n",
    "                               value=0)\n",
    "train_label_pad = pad_sequences(labels,\n",
    "                                maxlen=length,\n",
    "                                padding='post',\n",
    "                                value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_casting(train, label):\n",
    "    train = tf.cast(train, tf.int64)\n",
    "    label = tf.cast(label, tf.int64)\n",
    "\n",
    "    return train, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_pad, train_label_pad))\n",
    "train_dataset = train_dataset.map(tensor_casting)\n",
    "train_dataset = train_dataset.shuffle(10000).batch(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[  0 322   8 ...   0 107 189]\n",
      " [209   6 325 ...   0 122 176]\n",
      " [109 190   0 ...   1 114 207]\n",
      " ...\n",
      " [  0   0   0 ...  10 285  99]\n",
      " [344   1 116 ... 108 231   0]\n",
      " [315   2 329 ... 178   3 334]], shape=(64, 256), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[322   8 116 ... 107 189   2]\n",
      " [  6 325   3 ... 122 176   0]\n",
      " [190   0 108 ... 114 207   3]\n",
      " ...\n",
      " [  0   0   0 ... 285  99 361]\n",
      " [  1 116 227 ... 231   0 359]\n",
      " [  2 329  10 ...   3 334   5]], shape=(64, 256), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for t,l in train_dataset.take(1):\n",
    "    print(t)\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : Music Transformer 모델을 구현하여 학습 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 1), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "\n",
    "def create_look_ahead_mask(size):\n",
    "    mask = tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)\n",
    "\n",
    "\n",
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "        tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RelativeGlobalAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(RelativeGlobalAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        self.headDim = d_model // num_heads\n",
    "        self.contextDim = int(self.headDim * self.num_heads)\n",
    "        self.eventDim = 390\n",
    "        self.E = self.add_weight('E', shape=[self.num_heads, length, self.headDim])\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(self.headDim)\n",
    "        self.wk = tf.keras.layers.Dense(self.headDim)\n",
    "        self.wv = tf.keras.layers.Dense(self.headDim)\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        # [Heads, Batch, Time, HeadDim]\n",
    "        q = tf.stack([self.wq(q) for _ in range(self.num_heads)])\n",
    "        k = tf.stack([self.wk(k) for _ in range(self.num_heads)])\n",
    "        v = tf.stack([self.wv(v) for _ in range(self.num_heads)])\n",
    "\n",
    "        self.batch_size = q.shape[1]\n",
    "        self.max_len = q.shape[2]\n",
    "        \n",
    "        #skewing\n",
    "        # E = Heads, Time, HeadDim\n",
    "        # [Heads, Batch * Time, HeadDim]\n",
    "        Q_ = tf.reshape(q, [self.num_heads, self.batch_size * self.max_len, self.headDim])\n",
    "        # [Heads, Batch * Time, Time]\n",
    "        S = tf.matmul(Q_, self.E, transpose_b=True)\n",
    "        # [Heads, Batch, Time, Time]\n",
    "        S = tf.reshape(S, [self.num_heads, self.batch_size, self.max_len, self.max_len])\n",
    "        # [Heads, Batch, Time, Time+1]\n",
    "        S = tf.pad(S, ((0, 0), (0, 0), (0, 0), (1, 0)))\n",
    "        # [Heads, Batch, Time+1, Time]\n",
    "        S = tf.reshape(S, [self.num_heads, self.batch_size, self.max_len + 1, self.max_len])   \n",
    "        # [Heads, Batch, Time, Time]\n",
    "        S = S[:, :, 1:]\n",
    "        # [Heads, Batch, Time, Time]\n",
    "        attention = (tf.matmul(q, k, transpose_b=True) + S) / np.sqrt(self.headDim)\n",
    "        # mask tf 2.0 == tf.linalg.band_part\n",
    "        get_mask = tf.linalg.band_part(tf.ones([self.max_len, self.max_len]), -1, 0)\n",
    "        attention = attention * get_mask - tf.cast(1e10, attention.dtype) * (1-get_mask)\n",
    "        score = tf.nn.softmax(attention, axis=3)\n",
    "\n",
    "        # [Heads, Batch, Time, HeadDim]\n",
    "        context = tf.matmul(score, v)\n",
    "        # [Batch, Time, Heads, HeadDim]\n",
    "        context = tf.transpose(context, [1, 2, 0, 3])\n",
    "        # [Batch, Time, ContextDim]\n",
    "        context = tf.reshape(context, [self.batch_size, self.max_len, self.d_model])\n",
    "        # [Batch, Time, ContextDim]\n",
    "        logits = tf.keras.layers.Dense(self.d_model)(context)\n",
    "\n",
    "        return logits, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.rga = RelativeGlobalAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        attn_output, _ = self.rga(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.rga1 = RelativeGlobalAttention(d_model, num_heads)\n",
    "        self.rga2 = RelativeGlobalAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.rga1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.rga2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        attention_weights = {}\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                   look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicTransformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, rate=0.1):\n",
    "        super(MusicTransformer, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(input_vocab_size)\n",
    "\n",
    "    def call(self, inp, training, enc_padding_mask, \n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "        embed = self.embedding(inp)\n",
    "        embed *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "\n",
    "        enc_output = self.encoder(embed, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            embed, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = 390   # MIDI가 낼 수 있는 소리의 종류\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 선언\n",
    "music_transformer = MusicTransformer(num_layers, d_model, num_heads, dff,\n",
    "                                     input_vocab_size, rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.getenv('HOME')+'/aiffel/music_transformer/models/'\n",
    "\n",
    "ckpt = tf.train.Checkpoint(music_transformer=music_transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 6.3145\n",
      "Epoch 1 Batch 100 Loss 6.1384\n",
      "Epoch 1 Batch 200 Loss 5.9641\n",
      "Epoch 1 Batch 300 Loss 5.7084\n",
      "Epoch 1 Batch 400 Loss 5.4855\n",
      "Epoch 1 Batch 500 Loss 5.3310\n",
      "Epoch 1 Batch 600 Loss 5.1511\n",
      "Epoch 1 Batch 700 Loss 4.9484\n",
      "Epoch 1 Batch 800 Loss 4.7864\n",
      "Epoch 1 Batch 900 Loss 4.6573\n",
      "Epoch 1 Loss 4.6283\n",
      "Time taken for 1 epoch: 623.6348176002502 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 3.6787\n",
      "Epoch 2 Batch 100 Loss 3.6393\n",
      "Epoch 2 Batch 200 Loss 3.6346\n",
      "Epoch 2 Batch 300 Loss 3.6259\n",
      "Epoch 2 Batch 400 Loss 3.6192\n",
      "Epoch 2 Batch 500 Loss 3.6142\n",
      "Epoch 2 Batch 600 Loss 3.6070\n",
      "Epoch 2 Batch 700 Loss 3.6017\n",
      "Epoch 2 Batch 800 Loss 3.5961\n",
      "Epoch 2 Batch 900 Loss 3.5912\n",
      "Saving checkpoint for epoch 2 at /home/ubuntu/aiffel/music_transformer/models/ckpt-1\n",
      "Epoch 2 Loss 3.5905\n",
      "Time taken for 1 epoch: 620.9059829711914 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 3.5879\n",
      "Epoch 3 Batch 100 Loss 3.5696\n",
      "Epoch 3 Batch 200 Loss 3.5646\n",
      "Epoch 3 Batch 300 Loss 3.5606\n",
      "Epoch 3 Batch 400 Loss 3.5577\n",
      "Epoch 3 Batch 500 Loss 3.5545\n",
      "Epoch 3 Batch 600 Loss 3.5518\n",
      "Epoch 3 Batch 700 Loss 3.5505\n",
      "Epoch 3 Batch 800 Loss 3.5493\n",
      "Epoch 3 Batch 900 Loss 3.5469\n",
      "Epoch 3 Loss 3.5464\n",
      "Time taken for 1 epoch: 626.0475707054138 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 3.5700\n",
      "Epoch 4 Batch 100 Loss 3.5644\n",
      "Epoch 4 Batch 200 Loss 3.5547\n",
      "Epoch 4 Batch 300 Loss 3.5465\n",
      "Epoch 4 Batch 400 Loss 3.5359\n",
      "Epoch 4 Batch 500 Loss 3.5325\n",
      "Epoch 4 Batch 600 Loss 3.5300\n",
      "Epoch 4 Batch 700 Loss 3.5280\n",
      "Epoch 4 Batch 800 Loss 3.5241\n",
      "Epoch 4 Batch 900 Loss 3.5225\n",
      "Saving checkpoint for epoch 4 at /home/ubuntu/aiffel/music_transformer/models/ckpt-2\n",
      "Epoch 4 Loss 3.5224\n",
      "Time taken for 1 epoch: 620.5189921855927 secs\n",
      "\n",
      "Epoch 5 Batch 0 Loss 3.5659\n",
      "Epoch 5 Batch 100 Loss 3.5155\n",
      "Epoch 5 Batch 200 Loss 3.5115\n",
      "Epoch 5 Batch 300 Loss 3.5104\n",
      "Epoch 5 Batch 400 Loss 3.5075\n",
      "Epoch 5 Batch 500 Loss 3.5056\n",
      "Epoch 5 Batch 600 Loss 3.5046\n",
      "Epoch 5 Batch 700 Loss 3.5061\n",
      "Epoch 5 Batch 800 Loss 3.5048\n",
      "Epoch 5 Batch 900 Loss 3.5020\n",
      "Epoch 5 Loss 3.5014\n",
      "Time taken for 1 epoch: 623.5283222198486 secs\n",
      "\n",
      "Epoch 6 Batch 0 Loss 3.5442\n",
      "Epoch 6 Batch 100 Loss 3.5000\n",
      "Epoch 6 Batch 200 Loss 3.4947\n",
      "Epoch 6 Batch 300 Loss 3.4911\n",
      "Epoch 6 Batch 400 Loss 3.4857\n",
      "Epoch 6 Batch 500 Loss 3.4860\n",
      "Epoch 6 Batch 600 Loss 3.4837\n",
      "Epoch 6 Batch 700 Loss 3.4830\n",
      "Epoch 6 Batch 800 Loss 3.4807\n",
      "Epoch 6 Batch 900 Loss 3.4792\n",
      "Saving checkpoint for epoch 6 at /home/ubuntu/aiffel/music_transformer/models/ckpt-3\n",
      "Epoch 6 Loss 3.4790\n",
      "Time taken for 1 epoch: 619.1123960018158 secs\n",
      "\n",
      "Epoch 7 Batch 0 Loss 3.5073\n",
      "Epoch 7 Batch 100 Loss 3.4689\n",
      "Epoch 7 Batch 200 Loss 3.4748\n",
      "Epoch 7 Batch 300 Loss 3.4696\n",
      "Epoch 7 Batch 400 Loss 3.4685\n",
      "Epoch 7 Batch 500 Loss 3.4670\n",
      "Epoch 7 Batch 600 Loss 3.4659\n",
      "Epoch 7 Batch 700 Loss 3.4650\n",
      "Epoch 7 Batch 800 Loss 3.4633\n",
      "Epoch 7 Batch 900 Loss 3.4615\n",
      "Epoch 7 Loss 3.4613\n",
      "Time taken for 1 epoch: 625.2978875637054 secs\n",
      "\n",
      "Epoch 8 Batch 0 Loss 3.4459\n",
      "Epoch 8 Batch 100 Loss 3.4640\n",
      "Epoch 8 Batch 200 Loss 3.4590\n",
      "Epoch 8 Batch 300 Loss 3.4540\n",
      "Epoch 8 Batch 400 Loss 3.4511\n",
      "Epoch 8 Batch 500 Loss 3.4494\n",
      "Epoch 8 Batch 600 Loss 3.4477\n",
      "Epoch 8 Batch 700 Loss 3.4486\n",
      "Epoch 8 Batch 800 Loss 3.4471\n",
      "Epoch 8 Batch 900 Loss 3.4468\n",
      "Saving checkpoint for epoch 8 at /home/ubuntu/aiffel/music_transformer/models/ckpt-4\n",
      "Epoch 8 Loss 3.4464\n",
      "Time taken for 1 epoch: 619.7230710983276 secs\n",
      "\n",
      "Epoch 9 Batch 0 Loss 3.4990\n",
      "Epoch 9 Batch 100 Loss 3.4531\n",
      "Epoch 9 Batch 200 Loss 3.4450\n",
      "Epoch 9 Batch 300 Loss 3.4425\n",
      "Epoch 9 Batch 400 Loss 3.4403\n",
      "Epoch 9 Batch 500 Loss 3.4390\n",
      "Epoch 9 Batch 600 Loss 3.4379\n",
      "Epoch 9 Batch 700 Loss 3.4384\n",
      "Epoch 9 Batch 800 Loss 3.4378\n",
      "Epoch 9 Batch 900 Loss 3.4365\n",
      "Epoch 9 Loss 3.4363\n",
      "Time taken for 1 epoch: 627.0007441043854 secs\n",
      "\n",
      "Epoch 10 Batch 0 Loss 3.5005\n",
      "Epoch 10 Batch 100 Loss 3.4454\n",
      "Epoch 10 Batch 200 Loss 3.4394\n",
      "Epoch 10 Batch 300 Loss 3.4364\n",
      "Epoch 10 Batch 400 Loss 3.4321\n",
      "Epoch 10 Batch 500 Loss 3.4321\n",
      "Epoch 10 Batch 600 Loss 3.4308\n",
      "Epoch 10 Batch 700 Loss 3.4306\n",
      "Epoch 10 Batch 800 Loss 3.4299\n",
      "Epoch 10 Batch 900 Loss 3.4288\n",
      "Saving checkpoint for epoch 10 at /home/ubuntu/aiffel/music_transformer/models/ckpt-5\n",
      "Epoch 10 Loss 3.4287\n",
      "Time taken for 1 epoch: 622.7549061775208 secs\n",
      "\n",
      "Epoch 11 Batch 0 Loss 3.3890\n",
      "Epoch 11 Batch 100 Loss 3.4364\n",
      "Epoch 11 Batch 200 Loss 3.4325\n",
      "Epoch 11 Batch 300 Loss 3.4277\n",
      "Epoch 11 Batch 400 Loss 3.4225\n",
      "Epoch 11 Batch 500 Loss 3.4193\n",
      "Epoch 11 Batch 600 Loss 3.4166\n",
      "Epoch 11 Batch 700 Loss 3.4146\n",
      "Epoch 11 Batch 800 Loss 3.4119\n",
      "Epoch 11 Batch 900 Loss 3.4081\n",
      "Epoch 11 Loss 3.4071\n",
      "Time taken for 1 epoch: 625.3280680179596 secs\n",
      "\n",
      "Epoch 12 Batch 0 Loss 3.3647\n",
      "Epoch 12 Batch 100 Loss 3.3743\n",
      "Epoch 12 Batch 200 Loss 3.3747\n",
      "Epoch 12 Batch 300 Loss 3.3727\n",
      "Epoch 12 Batch 400 Loss 3.3709\n",
      "Epoch 12 Batch 500 Loss 3.3703\n",
      "Epoch 12 Batch 600 Loss 3.3702\n",
      "Epoch 12 Batch 700 Loss 3.3711\n",
      "Epoch 12 Batch 800 Loss 3.3701\n",
      "Epoch 12 Batch 900 Loss 3.3692\n",
      "Saving checkpoint for epoch 12 at /home/ubuntu/aiffel/music_transformer/models/ckpt-6\n",
      "Epoch 12 Loss 3.3691\n",
      "Time taken for 1 epoch: 624.5368006229401 secs\n",
      "\n",
      "Epoch 13 Batch 0 Loss 3.4017\n",
      "Epoch 13 Batch 100 Loss 3.3522\n",
      "Epoch 13 Batch 200 Loss 3.3543\n",
      "Epoch 13 Batch 300 Loss 3.3595\n",
      "Epoch 13 Batch 400 Loss 3.3573\n",
      "Epoch 13 Batch 500 Loss 3.3591\n",
      "Epoch 13 Batch 600 Loss 3.3585\n",
      "Epoch 13 Batch 700 Loss 3.3593\n",
      "Epoch 13 Batch 800 Loss 3.3589\n",
      "Epoch 13 Batch 900 Loss 3.3584\n",
      "Epoch 13 Loss 3.3584\n",
      "Time taken for 1 epoch: 619.4494123458862 secs\n",
      "\n",
      "Epoch 14 Batch 0 Loss 3.3411\n",
      "Epoch 14 Batch 100 Loss 3.3467\n",
      "Epoch 14 Batch 200 Loss 3.3473\n",
      "Epoch 14 Batch 300 Loss 3.3495\n",
      "Epoch 14 Batch 400 Loss 3.3497\n",
      "Epoch 14 Batch 500 Loss 3.3503\n",
      "Epoch 14 Batch 600 Loss 3.3503\n",
      "Epoch 14 Batch 700 Loss 3.3502\n",
      "Epoch 14 Batch 800 Loss 3.3504\n",
      "Epoch 14 Batch 900 Loss 3.3496\n",
      "Saving checkpoint for epoch 14 at /home/ubuntu/aiffel/music_transformer/models/ckpt-7\n",
      "Epoch 14 Loss 3.3495\n",
      "Time taken for 1 epoch: 626.8563272953033 secs\n",
      "\n",
      "Epoch 15 Batch 0 Loss 3.3061\n",
      "Epoch 15 Batch 100 Loss 3.3410\n",
      "Epoch 15 Batch 200 Loss 3.3398\n",
      "Epoch 15 Batch 300 Loss 3.3408\n",
      "Epoch 15 Batch 400 Loss 3.3411\n",
      "Epoch 15 Batch 500 Loss 3.3422\n",
      "Epoch 15 Batch 600 Loss 3.3415\n",
      "Epoch 15 Batch 700 Loss 3.3426\n",
      "Epoch 15 Batch 800 Loss 3.3435\n",
      "Epoch 15 Batch 900 Loss 3.3430\n",
      "Epoch 15 Loss 3.3430\n",
      "Time taken for 1 epoch: 621.1452322006226 secs\n",
      "\n",
      "Epoch 16 Batch 0 Loss 3.3453\n",
      "Epoch 16 Batch 100 Loss 3.3298\n",
      "Epoch 16 Batch 200 Loss 3.3324\n",
      "Epoch 16 Batch 300 Loss 3.3333\n",
      "Epoch 16 Batch 400 Loss 3.3332\n",
      "Epoch 16 Batch 500 Loss 3.3357\n",
      "Epoch 16 Batch 600 Loss 3.3356\n",
      "Epoch 16 Batch 700 Loss 3.3367\n",
      "Epoch 16 Batch 800 Loss 3.3369\n",
      "Epoch 16 Batch 900 Loss 3.3364\n",
      "Saving checkpoint for epoch 16 at /home/ubuntu/aiffel/music_transformer/models/ckpt-8\n",
      "Epoch 16 Loss 3.3365\n",
      "Time taken for 1 epoch: 626.9159209728241 secs\n",
      "\n",
      "Epoch 17 Batch 0 Loss 3.3537\n",
      "Epoch 17 Batch 100 Loss 3.3235\n",
      "Epoch 17 Batch 200 Loss 3.3255\n",
      "Epoch 17 Batch 300 Loss 3.3269\n",
      "Epoch 17 Batch 400 Loss 3.3267\n",
      "Epoch 17 Batch 500 Loss 3.3286\n",
      "Epoch 17 Batch 600 Loss 3.3290\n",
      "Epoch 17 Batch 700 Loss 3.3294\n",
      "Epoch 17 Batch 800 Loss 3.3300\n",
      "Epoch 17 Batch 900 Loss 3.3301\n",
      "Epoch 17 Loss 3.3301\n",
      "Time taken for 1 epoch: 622.136203289032 secs\n",
      "\n",
      "Epoch 18 Batch 0 Loss 3.3122\n",
      "Epoch 18 Batch 100 Loss 3.3183\n",
      "Epoch 18 Batch 200 Loss 3.3219\n",
      "Epoch 18 Batch 300 Loss 3.3225\n",
      "Epoch 18 Batch 400 Loss 3.3219\n",
      "Epoch 18 Batch 500 Loss 3.3227\n",
      "Epoch 18 Batch 600 Loss 3.3228\n",
      "Epoch 18 Batch 700 Loss 3.3234\n",
      "Epoch 18 Batch 800 Loss 3.3241\n",
      "Epoch 18 Batch 900 Loss 3.3237\n",
      "Saving checkpoint for epoch 18 at /home/ubuntu/aiffel/music_transformer/models/ckpt-9\n",
      "Epoch 18 Loss 3.3236\n",
      "Time taken for 1 epoch: 626.9004833698273 secs\n",
      "\n",
      "Epoch 19 Batch 0 Loss 3.3551\n",
      "Epoch 19 Batch 100 Loss 3.3128\n",
      "Epoch 19 Batch 200 Loss 3.3142\n",
      "Epoch 19 Batch 300 Loss 3.3174\n",
      "Epoch 19 Batch 400 Loss 3.3177\n",
      "Epoch 19 Batch 500 Loss 3.3186\n",
      "Epoch 19 Batch 600 Loss 3.3179\n",
      "Epoch 19 Batch 700 Loss 3.3185\n",
      "Epoch 19 Batch 800 Loss 3.3188\n",
      "Epoch 19 Batch 900 Loss 3.3194\n",
      "Epoch 19 Loss 3.3189\n",
      "Time taken for 1 epoch: 622.7513794898987 secs\n",
      "\n",
      "Epoch 20 Batch 0 Loss 3.2813\n",
      "Epoch 20 Batch 100 Loss 3.3088\n",
      "Epoch 20 Batch 200 Loss 3.3117\n",
      "Epoch 20 Batch 300 Loss 3.3129\n",
      "Epoch 20 Batch 400 Loss 3.3125\n",
      "Epoch 20 Batch 500 Loss 3.3140\n",
      "Epoch 20 Batch 600 Loss 3.3142\n",
      "Epoch 20 Batch 700 Loss 3.3150\n",
      "Epoch 20 Batch 800 Loss 3.3156\n",
      "Epoch 20 Batch 900 Loss 3.3155\n",
      "Saving checkpoint for epoch 20 at /home/ubuntu/aiffel/music_transformer/models/ckpt-10\n",
      "Epoch 20 Loss 3.3155\n",
      "Time taken for 1 epoch: 621.8488533496857 secs\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Batch 0 Loss 3.3129\n",
      "Epoch 21 Batch 100 Loss 3.3063\n",
      "Epoch 21 Batch 200 Loss 3.3087\n",
      "Epoch 21 Batch 300 Loss 3.3083\n",
      "Epoch 21 Batch 400 Loss 3.3078\n",
      "Epoch 21 Batch 500 Loss 3.3094\n",
      "Epoch 21 Batch 600 Loss 3.3085\n",
      "Epoch 21 Batch 700 Loss 3.3090\n",
      "Epoch 21 Batch 800 Loss 3.3095\n",
      "Epoch 21 Batch 900 Loss 3.3098\n",
      "Epoch 21 Loss 3.3100\n",
      "Time taken for 1 epoch: 629.5233943462372 secs\n",
      "\n",
      "Epoch 22 Batch 0 Loss 3.3107\n",
      "Epoch 22 Batch 100 Loss 3.2988\n",
      "Epoch 22 Batch 200 Loss 3.3025\n",
      "Epoch 22 Batch 300 Loss 3.3021\n",
      "Epoch 22 Batch 400 Loss 3.3025\n",
      "Epoch 22 Batch 500 Loss 3.3040\n",
      "Epoch 22 Batch 600 Loss 3.3031\n",
      "Epoch 22 Batch 700 Loss 3.3035\n",
      "Epoch 22 Batch 800 Loss 3.3041\n",
      "Epoch 22 Batch 900 Loss 3.3040\n",
      "Saving checkpoint for epoch 22 at /home/ubuntu/aiffel/music_transformer/models/ckpt-11\n",
      "Epoch 22 Loss 3.3041\n",
      "Time taken for 1 epoch: 618.9508826732635 secs\n",
      "\n",
      "Epoch 23 Batch 0 Loss 3.2957\n",
      "Epoch 23 Batch 100 Loss 3.2886\n",
      "Epoch 23 Batch 200 Loss 3.2939\n",
      "Epoch 23 Batch 300 Loss 3.2941\n",
      "Epoch 23 Batch 400 Loss 3.2946\n",
      "Epoch 23 Batch 500 Loss 3.2960\n",
      "Epoch 23 Batch 600 Loss 3.2958\n",
      "Epoch 23 Batch 700 Loss 3.2956\n",
      "Epoch 23 Batch 800 Loss 3.2959\n",
      "Epoch 23 Batch 900 Loss 3.2958\n",
      "Epoch 23 Loss 3.2957\n",
      "Time taken for 1 epoch: 623.9548051357269 secs\n",
      "\n",
      "Epoch 24 Batch 0 Loss 3.2638\n",
      "Epoch 24 Batch 100 Loss 3.2746\n",
      "Epoch 24 Batch 200 Loss 3.2801\n",
      "Epoch 24 Batch 300 Loss 3.2822\n",
      "Epoch 24 Batch 400 Loss 3.2833\n",
      "Epoch 24 Batch 500 Loss 3.2849\n",
      "Epoch 24 Batch 600 Loss 3.2842\n",
      "Epoch 24 Batch 700 Loss 3.2845\n",
      "Epoch 24 Batch 800 Loss 3.2849\n",
      "Epoch 24 Batch 900 Loss 3.2842\n",
      "Saving checkpoint for epoch 24 at /home/ubuntu/aiffel/music_transformer/models/ckpt-12\n",
      "Epoch 24 Loss 3.2840\n",
      "Time taken for 1 epoch: 624.8189194202423 secs\n",
      "\n",
      "Epoch 25 Batch 0 Loss 3.2722\n",
      "Epoch 25 Batch 100 Loss 3.2667\n",
      "Epoch 25 Batch 200 Loss 3.2700\n",
      "Epoch 25 Batch 300 Loss 3.2720\n",
      "Epoch 25 Batch 400 Loss 3.2715\n",
      "Epoch 25 Batch 500 Loss 3.2728\n",
      "Epoch 25 Batch 600 Loss 3.2715\n",
      "Epoch 25 Batch 700 Loss 3.2712\n",
      "Epoch 25 Batch 800 Loss 3.2718\n",
      "Epoch 25 Batch 900 Loss 3.2715\n",
      "Epoch 25 Loss 3.2716\n",
      "Time taken for 1 epoch: 627.8362560272217 secs\n",
      "\n",
      "Epoch 26 Batch 0 Loss 3.2958\n",
      "Epoch 26 Batch 100 Loss 3.2508\n",
      "Epoch 26 Batch 200 Loss 3.2546\n",
      "Epoch 26 Batch 300 Loss 3.2562\n",
      "Epoch 26 Batch 400 Loss 3.2577\n",
      "Epoch 26 Batch 500 Loss 3.2597\n",
      "Epoch 26 Batch 600 Loss 3.2590\n",
      "Epoch 26 Batch 700 Loss 3.2590\n",
      "Epoch 26 Batch 800 Loss 3.2593\n",
      "Epoch 26 Batch 900 Loss 3.2593\n",
      "Saving checkpoint for epoch 26 at /home/ubuntu/aiffel/music_transformer/models/ckpt-13\n",
      "Epoch 26 Loss 3.2593\n",
      "Time taken for 1 epoch: 622.2593762874603 secs\n",
      "\n",
      "Epoch 27 Batch 0 Loss 3.2899\n",
      "Epoch 27 Batch 100 Loss 3.2448\n",
      "Epoch 27 Batch 200 Loss 3.2493\n",
      "Epoch 27 Batch 300 Loss 3.2502\n",
      "Epoch 27 Batch 400 Loss 3.2511\n",
      "Epoch 27 Batch 500 Loss 3.2519\n",
      "Epoch 27 Batch 600 Loss 3.2516\n",
      "Epoch 27 Batch 700 Loss 3.2512\n",
      "Epoch 27 Batch 800 Loss 3.2517\n",
      "Epoch 27 Batch 900 Loss 3.2524\n",
      "Epoch 27 Loss 3.2525\n",
      "Time taken for 1 epoch: 622.4829683303833 secs\n",
      "\n",
      "Epoch 28 Batch 0 Loss 3.2529\n",
      "Epoch 28 Batch 100 Loss 3.2386\n",
      "Epoch 28 Batch 200 Loss 3.2416\n",
      "Epoch 28 Batch 300 Loss 3.2432\n",
      "Epoch 28 Batch 400 Loss 3.2457\n",
      "Epoch 28 Batch 500 Loss 3.2475\n",
      "Epoch 28 Batch 600 Loss 3.2464\n",
      "Epoch 28 Batch 700 Loss 3.2461\n",
      "Epoch 28 Batch 800 Loss 3.2468\n",
      "Epoch 28 Batch 900 Loss 3.2471\n",
      "Saving checkpoint for epoch 28 at /home/ubuntu/aiffel/music_transformer/models/ckpt-14\n",
      "Epoch 28 Loss 3.2467\n",
      "Time taken for 1 epoch: 619.6127388477325 secs\n",
      "\n",
      "Epoch 29 Batch 0 Loss 3.2085\n",
      "Epoch 29 Batch 100 Loss 3.2270\n",
      "Epoch 29 Batch 200 Loss 3.2351\n",
      "Epoch 29 Batch 300 Loss 3.2378\n",
      "Epoch 29 Batch 400 Loss 3.2403\n",
      "Epoch 29 Batch 500 Loss 3.2425\n",
      "Epoch 29 Batch 600 Loss 3.2418\n",
      "Epoch 29 Batch 700 Loss 3.2415\n",
      "Epoch 29 Batch 800 Loss 3.2423\n",
      "Epoch 29 Batch 900 Loss 3.2423\n",
      "Epoch 29 Loss 3.2420\n",
      "Time taken for 1 epoch: 623.2535543441772 secs\n",
      "\n",
      "Epoch 30 Batch 0 Loss 3.2755\n",
      "Epoch 30 Batch 100 Loss 3.2287\n",
      "Epoch 30 Batch 200 Loss 3.2298\n",
      "Epoch 30 Batch 300 Loss 3.2303\n",
      "Epoch 30 Batch 400 Loss 3.2332\n",
      "Epoch 30 Batch 500 Loss 3.2359\n",
      "Epoch 30 Batch 600 Loss 3.2352\n",
      "Epoch 30 Batch 700 Loss 3.2354\n",
      "Epoch 30 Batch 800 Loss 3.2359\n",
      "Epoch 30 Batch 900 Loss 3.2364\n",
      "Saving checkpoint for epoch 30 at /home/ubuntu/aiffel/music_transformer/models/ckpt-15\n",
      "Epoch 30 Loss 3.2361\n",
      "Time taken for 1 epoch: 623.2148771286011 secs\n",
      "\n",
      "Epoch 31 Batch 0 Loss 3.3022\n",
      "Epoch 31 Batch 100 Loss 3.2238\n",
      "Epoch 31 Batch 200 Loss 3.2248\n",
      "Epoch 31 Batch 300 Loss 3.2268\n",
      "Epoch 31 Batch 400 Loss 3.2281\n",
      "Epoch 31 Batch 500 Loss 3.2307\n",
      "Epoch 31 Batch 600 Loss 3.2302\n",
      "Epoch 31 Batch 700 Loss 3.2298\n",
      "Epoch 31 Batch 800 Loss 3.2310\n",
      "Epoch 31 Batch 900 Loss 3.2311\n",
      "Epoch 31 Loss 3.2312\n",
      "Time taken for 1 epoch: 628.9457154273987 secs\n",
      "\n",
      "Epoch 32 Batch 0 Loss 3.2084\n",
      "Epoch 32 Batch 100 Loss 3.2142\n",
      "Epoch 32 Batch 200 Loss 3.2177\n",
      "Epoch 32 Batch 300 Loss 3.2203\n",
      "Epoch 32 Batch 400 Loss 3.2225\n",
      "Epoch 32 Batch 500 Loss 3.2245\n",
      "Epoch 32 Batch 600 Loss 3.2238\n",
      "Epoch 32 Batch 700 Loss 3.2242\n",
      "Epoch 32 Batch 800 Loss 3.2250\n",
      "Epoch 32 Batch 900 Loss 3.2250\n",
      "Saving checkpoint for epoch 32 at /home/ubuntu/aiffel/music_transformer/models/ckpt-16\n",
      "Epoch 32 Loss 3.2254\n",
      "Time taken for 1 epoch: 630.2022368907928 secs\n",
      "\n",
      "Epoch 33 Batch 0 Loss 3.2464\n",
      "Epoch 33 Batch 100 Loss 3.2121\n",
      "Epoch 33 Batch 200 Loss 3.2177\n",
      "Epoch 33 Batch 300 Loss 3.2179\n",
      "Epoch 33 Batch 400 Loss 3.2192\n",
      "Epoch 33 Batch 500 Loss 3.2214\n",
      "Epoch 33 Batch 600 Loss 3.2208\n",
      "Epoch 33 Batch 700 Loss 3.2200\n",
      "Epoch 33 Batch 800 Loss 3.2213\n",
      "Epoch 33 Batch 900 Loss 3.2217\n",
      "Epoch 33 Loss 3.2215\n",
      "Time taken for 1 epoch: 623.6643998622894 secs\n",
      "\n",
      "Epoch 34 Batch 0 Loss 3.2138\n",
      "Epoch 34 Batch 100 Loss 3.2088\n",
      "Epoch 34 Batch 200 Loss 3.2098\n",
      "Epoch 34 Batch 300 Loss 3.2122\n",
      "Epoch 34 Batch 400 Loss 3.2138\n",
      "Epoch 34 Batch 500 Loss 3.2160\n",
      "Epoch 34 Batch 600 Loss 3.2144\n",
      "Epoch 34 Batch 700 Loss 3.2150\n",
      "Epoch 34 Batch 800 Loss 3.2158\n",
      "Epoch 34 Batch 900 Loss 3.2165\n",
      "Saving checkpoint for epoch 34 at /home/ubuntu/aiffel/music_transformer/models/ckpt-17\n",
      "Epoch 34 Loss 3.2167\n",
      "Time taken for 1 epoch: 625.8791060447693 secs\n",
      "\n",
      "Epoch 35 Batch 0 Loss 3.2377\n",
      "Epoch 35 Batch 100 Loss 3.2019\n",
      "Epoch 35 Batch 200 Loss 3.2076\n",
      "Epoch 35 Batch 300 Loss 3.2107\n",
      "Epoch 35 Batch 400 Loss 3.2118\n",
      "Epoch 35 Batch 500 Loss 3.2142\n",
      "Epoch 35 Batch 600 Loss 3.2135\n",
      "Epoch 35 Batch 700 Loss 3.2129\n",
      "Epoch 35 Batch 800 Loss 3.2142\n",
      "Epoch 35 Batch 900 Loss 3.2143\n",
      "Epoch 35 Loss 3.2140\n",
      "Time taken for 1 epoch: 622.7437098026276 secs\n",
      "\n",
      "Epoch 36 Batch 0 Loss 3.2338\n",
      "Epoch 36 Batch 100 Loss 3.2043\n",
      "Epoch 36 Batch 200 Loss 3.2055\n",
      "Epoch 36 Batch 300 Loss 3.2064\n",
      "Epoch 36 Batch 400 Loss 3.2083\n",
      "Epoch 36 Batch 500 Loss 3.2101\n",
      "Epoch 36 Batch 600 Loss 3.2088\n",
      "Epoch 36 Batch 700 Loss 3.2088\n",
      "Epoch 36 Batch 800 Loss 3.2095\n",
      "Epoch 36 Batch 900 Loss 3.2100\n",
      "Saving checkpoint for epoch 36 at /home/ubuntu/aiffel/music_transformer/models/ckpt-18\n",
      "Epoch 36 Loss 3.2101\n",
      "Time taken for 1 epoch: 624.9473481178284 secs\n",
      "\n",
      "Epoch 37 Batch 0 Loss 3.2721\n",
      "Epoch 37 Batch 100 Loss 3.2002\n",
      "Epoch 37 Batch 200 Loss 3.2024\n",
      "Epoch 37 Batch 300 Loss 3.2040\n",
      "Epoch 37 Batch 400 Loss 3.2046\n",
      "Epoch 37 Batch 500 Loss 3.2065\n",
      "Epoch 37 Batch 600 Loss 3.2063\n",
      "Epoch 37 Batch 700 Loss 3.2061\n",
      "Epoch 37 Batch 800 Loss 3.2067\n",
      "Epoch 37 Batch 900 Loss 3.2069\n",
      "Epoch 37 Loss 3.2072\n",
      "Time taken for 1 epoch: 625.8141975402832 secs\n",
      "\n",
      "Epoch 38 Batch 0 Loss 3.2217\n",
      "Epoch 38 Batch 100 Loss 3.1926\n",
      "Epoch 38 Batch 200 Loss 3.1993\n",
      "Epoch 38 Batch 300 Loss 3.2016\n",
      "Epoch 38 Batch 400 Loss 3.2026\n",
      "Epoch 38 Batch 500 Loss 3.2048\n",
      "Epoch 38 Batch 600 Loss 3.2029\n",
      "Epoch 38 Batch 700 Loss 3.2033\n",
      "Epoch 38 Batch 800 Loss 3.2041\n",
      "Epoch 38 Batch 900 Loss 3.2050\n",
      "Saving checkpoint for epoch 38 at /home/ubuntu/aiffel/music_transformer/models/ckpt-19\n",
      "Epoch 38 Loss 3.2052\n",
      "Time taken for 1 epoch: 625.286482334137 secs\n",
      "\n",
      "Epoch 39 Batch 0 Loss 3.1819\n",
      "Epoch 39 Batch 100 Loss 3.1857\n",
      "Epoch 39 Batch 200 Loss 3.1935\n",
      "Epoch 39 Batch 300 Loss 3.1944\n",
      "Epoch 39 Batch 400 Loss 3.1974\n",
      "Epoch 39 Batch 500 Loss 3.1999\n",
      "Epoch 39 Batch 600 Loss 3.1991\n",
      "Epoch 39 Batch 700 Loss 3.1989\n",
      "Epoch 39 Batch 800 Loss 3.2000\n",
      "Epoch 39 Batch 900 Loss 3.2006\n",
      "Epoch 39 Loss 3.2007\n",
      "Time taken for 1 epoch: 620.3102416992188 secs\n",
      "\n",
      "Epoch 40 Batch 0 Loss 3.1909\n",
      "Epoch 40 Batch 100 Loss 3.1874\n",
      "Epoch 40 Batch 200 Loss 3.1927\n",
      "Epoch 40 Batch 300 Loss 3.1934\n",
      "Epoch 40 Batch 400 Loss 3.1959\n",
      "Epoch 40 Batch 500 Loss 3.1980\n",
      "Epoch 40 Batch 600 Loss 3.1966\n",
      "Epoch 40 Batch 700 Loss 3.1960\n",
      "Epoch 40 Batch 800 Loss 3.1970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Batch 900 Loss 3.1972\n",
      "Saving checkpoint for epoch 40 at /home/ubuntu/aiffel/music_transformer/models/ckpt-20\n",
      "Epoch 40 Loss 3.1977\n",
      "Time taken for 1 epoch: 627.5284788608551 secs\n",
      "\n",
      "Epoch 41 Batch 0 Loss 3.2045\n",
      "Epoch 41 Batch 100 Loss 3.1809\n",
      "Epoch 41 Batch 200 Loss 3.1870\n",
      "Epoch 41 Batch 300 Loss 3.1869\n",
      "Epoch 41 Batch 400 Loss 3.1894\n",
      "Epoch 41 Batch 500 Loss 3.1918\n",
      "Epoch 41 Batch 600 Loss 3.1912\n",
      "Epoch 41 Batch 700 Loss 3.1911\n",
      "Epoch 41 Batch 800 Loss 3.1917\n",
      "Epoch 41 Batch 900 Loss 3.1923\n",
      "Epoch 41 Loss 3.1925\n",
      "Time taken for 1 epoch: 620.1299521923065 secs\n",
      "\n",
      "Epoch 42 Batch 0 Loss 3.2176\n",
      "Epoch 42 Batch 100 Loss 3.1769\n",
      "Epoch 42 Batch 200 Loss 3.1821\n",
      "Epoch 42 Batch 300 Loss 3.1824\n",
      "Epoch 42 Batch 400 Loss 3.1847\n",
      "Epoch 42 Batch 500 Loss 3.1879\n",
      "Epoch 42 Batch 600 Loss 3.1865\n",
      "Epoch 42 Batch 700 Loss 3.1869\n",
      "Epoch 42 Batch 800 Loss 3.1882\n",
      "Epoch 42 Batch 900 Loss 3.1890\n",
      "Saving checkpoint for epoch 42 at /home/ubuntu/aiffel/music_transformer/models/ckpt-21\n",
      "Epoch 42 Loss 3.1889\n",
      "Time taken for 1 epoch: 629.1873965263367 secs\n",
      "\n",
      "Epoch 43 Batch 0 Loss 3.1938\n",
      "Epoch 43 Batch 100 Loss 3.1724\n",
      "Epoch 43 Batch 200 Loss 3.1757\n",
      "Epoch 43 Batch 300 Loss 3.1777\n",
      "Epoch 43 Batch 400 Loss 3.1814\n",
      "Epoch 43 Batch 500 Loss 3.1849\n",
      "Epoch 43 Batch 600 Loss 3.1840\n",
      "Epoch 43 Batch 700 Loss 3.1840\n",
      "Epoch 43 Batch 800 Loss 3.1855\n",
      "Epoch 43 Batch 900 Loss 3.1860\n",
      "Epoch 43 Loss 3.1857\n",
      "Time taken for 1 epoch: 623.5810031890869 secs\n",
      "\n",
      "Epoch 44 Batch 0 Loss 3.2338\n",
      "Epoch 44 Batch 100 Loss 3.1687\n",
      "Epoch 44 Batch 200 Loss 3.1733\n",
      "Epoch 44 Batch 300 Loss 3.1768\n",
      "Epoch 44 Batch 400 Loss 3.1795\n",
      "Epoch 44 Batch 500 Loss 3.1828\n",
      "Epoch 44 Batch 600 Loss 3.1818\n",
      "Epoch 44 Batch 700 Loss 3.1823\n",
      "Epoch 44 Batch 800 Loss 3.1837\n",
      "Epoch 44 Batch 900 Loss 3.1836\n",
      "Saving checkpoint for epoch 44 at /home/ubuntu/aiffel/music_transformer/models/ckpt-22\n",
      "Epoch 44 Loss 3.1836\n",
      "Time taken for 1 epoch: 620.954204082489 secs\n",
      "\n",
      "Epoch 45 Batch 0 Loss 3.1401\n",
      "Epoch 45 Batch 100 Loss 3.1645\n",
      "Epoch 45 Batch 200 Loss 3.1712\n",
      "Epoch 45 Batch 300 Loss 3.1722\n",
      "Epoch 45 Batch 400 Loss 3.1761\n",
      "Epoch 45 Batch 500 Loss 3.1795\n",
      "Epoch 45 Batch 600 Loss 3.1785\n",
      "Epoch 45 Batch 700 Loss 3.1785\n",
      "Epoch 45 Batch 800 Loss 3.1799\n",
      "Epoch 45 Batch 900 Loss 3.1805\n",
      "Epoch 45 Loss 3.1805\n",
      "Time taken for 1 epoch: 628.3026304244995 secs\n",
      "\n",
      "Epoch 46 Batch 0 Loss 3.1853\n",
      "Epoch 46 Batch 100 Loss 3.1605\n",
      "Epoch 46 Batch 200 Loss 3.1694\n",
      "Epoch 46 Batch 300 Loss 3.1715\n",
      "Epoch 46 Batch 400 Loss 3.1735\n",
      "Epoch 46 Batch 500 Loss 3.1769\n",
      "Epoch 46 Batch 600 Loss 3.1755\n",
      "Epoch 46 Batch 700 Loss 3.1760\n",
      "Epoch 46 Batch 800 Loss 3.1774\n",
      "Epoch 46 Batch 900 Loss 3.1778\n",
      "Saving checkpoint for epoch 46 at /home/ubuntu/aiffel/music_transformer/models/ckpt-23\n",
      "Epoch 46 Loss 3.1781\n",
      "Time taken for 1 epoch: 620.8033177852631 secs\n",
      "\n",
      "Epoch 47 Batch 0 Loss 3.1612\n",
      "Epoch 47 Batch 100 Loss 3.1586\n",
      "Epoch 47 Batch 200 Loss 3.1648\n",
      "Epoch 47 Batch 300 Loss 3.1663\n",
      "Epoch 47 Batch 400 Loss 3.1693\n",
      "Epoch 47 Batch 500 Loss 3.1728\n",
      "Epoch 47 Batch 600 Loss 3.1718\n",
      "Epoch 47 Batch 700 Loss 3.1723\n",
      "Epoch 47 Batch 800 Loss 3.1737\n",
      "Epoch 47 Batch 900 Loss 3.1743\n",
      "Epoch 47 Loss 3.1745\n",
      "Time taken for 1 epoch: 627.3180904388428 secs\n",
      "\n",
      "Epoch 48 Batch 0 Loss 3.1576\n",
      "Epoch 48 Batch 100 Loss 3.1555\n",
      "Epoch 48 Batch 200 Loss 3.1614\n",
      "Epoch 48 Batch 300 Loss 3.1640\n",
      "Epoch 48 Batch 400 Loss 3.1673\n",
      "Epoch 48 Batch 500 Loss 3.1712\n",
      "Epoch 48 Batch 600 Loss 3.1697\n",
      "Epoch 48 Batch 700 Loss 3.1698\n",
      "Epoch 48 Batch 800 Loss 3.1706\n",
      "Epoch 48 Batch 900 Loss 3.1716\n",
      "Saving checkpoint for epoch 48 at /home/ubuntu/aiffel/music_transformer/models/ckpt-24\n",
      "Epoch 48 Loss 3.1717\n",
      "Time taken for 1 epoch: 620.2487716674805 secs\n",
      "\n",
      "Epoch 49 Batch 0 Loss 3.1583\n",
      "Epoch 49 Batch 100 Loss 3.1576\n",
      "Epoch 49 Batch 200 Loss 3.1623\n",
      "Epoch 49 Batch 300 Loss 3.1639\n",
      "Epoch 49 Batch 400 Loss 3.1657\n",
      "Epoch 49 Batch 500 Loss 3.1690\n",
      "Epoch 49 Batch 600 Loss 3.1680\n",
      "Epoch 49 Batch 700 Loss 3.1675\n",
      "Epoch 49 Batch 800 Loss 3.1693\n",
      "Epoch 49 Batch 900 Loss 3.1698\n",
      "Epoch 49 Loss 3.1699\n",
      "Time taken for 1 epoch: 622.5750870704651 secs\n",
      "\n",
      "Epoch 50 Batch 0 Loss 3.1642\n",
      "Epoch 50 Batch 100 Loss 3.1502\n",
      "Epoch 50 Batch 200 Loss 3.1552\n",
      "Epoch 50 Batch 300 Loss 3.1593\n",
      "Epoch 50 Batch 400 Loss 3.1629\n",
      "Epoch 50 Batch 500 Loss 3.1659\n",
      "Epoch 50 Batch 600 Loss 3.1656\n",
      "Epoch 50 Batch 700 Loss 3.1652\n",
      "Epoch 50 Batch 800 Loss 3.1665\n",
      "Epoch 50 Batch 900 Loss 3.1668\n",
      "Saving checkpoint for epoch 50 at /home/ubuntu/aiffel/music_transformer/models/ckpt-25\n",
      "Epoch 50 Loss 3.1666\n",
      "Time taken for 1 epoch: 626.1153836250305 secs\n",
      "\n",
      "Epoch 51 Batch 0 Loss 3.1204\n",
      "Epoch 51 Batch 100 Loss 3.1473\n",
      "Epoch 51 Batch 200 Loss 3.1540\n",
      "Epoch 51 Batch 300 Loss 3.1564\n",
      "Epoch 51 Batch 400 Loss 3.1589\n",
      "Epoch 51 Batch 500 Loss 3.1627\n",
      "Epoch 51 Batch 600 Loss 3.1621\n",
      "Epoch 51 Batch 700 Loss 3.1617\n",
      "Epoch 51 Batch 800 Loss 3.1628\n",
      "Epoch 51 Batch 900 Loss 3.1634\n",
      "Epoch 51 Loss 3.1635\n",
      "Time taken for 1 epoch: 629.853031873703 secs\n",
      "\n",
      "Epoch 52 Batch 0 Loss 3.2127\n",
      "Epoch 52 Batch 100 Loss 3.1460\n",
      "Epoch 52 Batch 200 Loss 3.1543\n",
      "Epoch 52 Batch 300 Loss 3.1551\n",
      "Epoch 52 Batch 400 Loss 3.1580\n",
      "Epoch 52 Batch 500 Loss 3.1614\n",
      "Epoch 52 Batch 600 Loss 3.1599\n",
      "Epoch 52 Batch 700 Loss 3.1601\n",
      "Epoch 52 Batch 800 Loss 3.1611\n",
      "Epoch 52 Batch 900 Loss 3.1617\n",
      "Saving checkpoint for epoch 52 at /home/ubuntu/aiffel/music_transformer/models/ckpt-26\n",
      "Epoch 52 Loss 3.1619\n",
      "Time taken for 1 epoch: 626.9718797206879 secs\n",
      "\n",
      "Epoch 53 Batch 0 Loss 3.1750\n",
      "Epoch 53 Batch 100 Loss 3.1456\n",
      "Epoch 53 Batch 200 Loss 3.1501\n",
      "Epoch 53 Batch 300 Loss 3.1525\n",
      "Epoch 53 Batch 400 Loss 3.1555\n",
      "Epoch 53 Batch 500 Loss 3.1577\n",
      "Epoch 53 Batch 600 Loss 3.1579\n",
      "Epoch 53 Batch 700 Loss 3.1581\n",
      "Epoch 53 Batch 800 Loss 3.1597\n",
      "Epoch 53 Batch 900 Loss 3.1605\n",
      "Epoch 53 Loss 3.1603\n",
      "Time taken for 1 epoch: 624.6763482093811 secs\n",
      "\n",
      "Epoch 54 Batch 0 Loss 3.1097\n",
      "Epoch 54 Batch 100 Loss 3.1476\n",
      "Epoch 54 Batch 200 Loss 3.1489\n",
      "Epoch 54 Batch 300 Loss 3.1504\n",
      "Epoch 54 Batch 400 Loss 3.1525\n",
      "Epoch 54 Batch 500 Loss 3.1573\n",
      "Epoch 54 Batch 600 Loss 3.1566\n",
      "Epoch 54 Batch 700 Loss 3.1565\n",
      "Epoch 54 Batch 800 Loss 3.1573\n",
      "Epoch 54 Batch 900 Loss 3.1576\n",
      "Saving checkpoint for epoch 54 at /home/ubuntu/aiffel/music_transformer/models/ckpt-27\n",
      "Epoch 54 Loss 3.1579\n",
      "Time taken for 1 epoch: 631.8196716308594 secs\n",
      "\n",
      "Epoch 55 Batch 0 Loss 3.1592\n",
      "Epoch 55 Batch 100 Loss 3.1425\n",
      "Epoch 55 Batch 200 Loss 3.1477\n",
      "Epoch 55 Batch 300 Loss 3.1499\n",
      "Epoch 55 Batch 400 Loss 3.1525\n",
      "Epoch 55 Batch 500 Loss 3.1551\n",
      "Epoch 55 Batch 600 Loss 3.1537\n",
      "Epoch 55 Batch 700 Loss 3.1542\n",
      "Epoch 55 Batch 800 Loss 3.1555\n",
      "Epoch 55 Batch 900 Loss 3.1562\n",
      "Epoch 55 Loss 3.1563\n",
      "Time taken for 1 epoch: 631.2413518428802 secs\n",
      "\n",
      "Epoch 56 Batch 0 Loss 3.1635\n",
      "Epoch 56 Batch 100 Loss 3.1389\n",
      "Epoch 56 Batch 200 Loss 3.1431\n",
      "Epoch 56 Batch 300 Loss 3.1468\n",
      "Epoch 56 Batch 400 Loss 3.1504\n",
      "Epoch 56 Batch 500 Loss 3.1543\n",
      "Epoch 56 Batch 600 Loss 3.1533\n",
      "Epoch 56 Batch 700 Loss 3.1527\n",
      "Epoch 56 Batch 800 Loss 3.1539\n",
      "Epoch 56 Batch 900 Loss 3.1542\n",
      "Saving checkpoint for epoch 56 at /home/ubuntu/aiffel/music_transformer/models/ckpt-28\n",
      "Epoch 56 Loss 3.1544\n",
      "Time taken for 1 epoch: 633.9754917621613 secs\n",
      "\n",
      "Epoch 57 Batch 0 Loss 3.1516\n",
      "Epoch 57 Batch 100 Loss 3.1372\n",
      "Epoch 57 Batch 200 Loss 3.1416\n",
      "Epoch 57 Batch 300 Loss 3.1437\n",
      "Epoch 57 Batch 400 Loss 3.1476\n",
      "Epoch 57 Batch 500 Loss 3.1512\n",
      "Epoch 57 Batch 600 Loss 3.1507\n",
      "Epoch 57 Batch 700 Loss 3.1509\n",
      "Epoch 57 Batch 800 Loss 3.1522\n",
      "Epoch 57 Batch 900 Loss 3.1530\n",
      "Epoch 57 Loss 3.1533\n",
      "Time taken for 1 epoch: 628.447408914566 secs\n",
      "\n",
      "Epoch 58 Batch 0 Loss 3.1013\n",
      "Epoch 58 Batch 100 Loss 3.1356\n",
      "Epoch 58 Batch 200 Loss 3.1419\n",
      "Epoch 58 Batch 300 Loss 3.1436\n",
      "Epoch 58 Batch 400 Loss 3.1463\n",
      "Epoch 58 Batch 500 Loss 3.1503\n",
      "Epoch 58 Batch 600 Loss 3.1497\n",
      "Epoch 58 Batch 700 Loss 3.1493\n",
      "Epoch 58 Batch 800 Loss 3.1512\n",
      "Epoch 58 Batch 900 Loss 3.1512\n",
      "Saving checkpoint for epoch 58 at /home/ubuntu/aiffel/music_transformer/models/ckpt-29\n",
      "Epoch 58 Loss 3.1511\n",
      "Time taken for 1 epoch: 628.8324007987976 secs\n",
      "\n",
      "Epoch 59 Batch 0 Loss 3.1561\n",
      "Epoch 59 Batch 100 Loss 3.1351\n",
      "Epoch 59 Batch 200 Loss 3.1403\n",
      "Epoch 59 Batch 300 Loss 3.1414\n",
      "Epoch 59 Batch 400 Loss 3.1436\n",
      "Epoch 59 Batch 500 Loss 3.1485\n",
      "Epoch 59 Batch 600 Loss 3.1472\n",
      "Epoch 59 Batch 700 Loss 3.1475\n",
      "Epoch 59 Batch 800 Loss 3.1484\n",
      "Epoch 59 Batch 900 Loss 3.1488\n",
      "Epoch 59 Loss 3.1492\n",
      "Time taken for 1 epoch: 627.2528884410858 secs\n",
      "\n",
      "Epoch 60 Batch 0 Loss 3.0986\n",
      "Epoch 60 Batch 100 Loss 3.1351\n",
      "Epoch 60 Batch 200 Loss 3.1373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Batch 300 Loss 3.1404\n",
      "Epoch 60 Batch 400 Loss 3.1429\n",
      "Epoch 60 Batch 500 Loss 3.1462\n",
      "Epoch 60 Batch 600 Loss 3.1463\n",
      "Epoch 60 Batch 700 Loss 3.1462\n",
      "Epoch 60 Batch 800 Loss 3.1467\n",
      "Epoch 60 Batch 900 Loss 3.1477\n",
      "Saving checkpoint for epoch 60 at /home/ubuntu/aiffel/music_transformer/models/ckpt-30\n",
      "Epoch 60 Loss 3.1478\n",
      "Time taken for 1 epoch: 633.646773815155 secs\n",
      "\n",
      "Epoch 61 Batch 0 Loss 3.1394\n",
      "Epoch 61 Batch 100 Loss 3.1344\n",
      "Epoch 61 Batch 200 Loss 3.1376\n",
      "Epoch 61 Batch 300 Loss 3.1377\n",
      "Epoch 61 Batch 400 Loss 3.1399\n",
      "Epoch 61 Batch 500 Loss 3.1443\n",
      "Epoch 61 Batch 600 Loss 3.1434\n",
      "Epoch 61 Batch 700 Loss 3.1436\n",
      "Epoch 61 Batch 800 Loss 3.1449\n",
      "Epoch 61 Batch 900 Loss 3.1455\n",
      "Epoch 61 Loss 3.1458\n",
      "Time taken for 1 epoch: 622.3965454101562 secs\n",
      "\n",
      "Epoch 62 Batch 0 Loss 3.1063\n",
      "Epoch 62 Batch 100 Loss 3.1286\n",
      "Epoch 62 Batch 200 Loss 3.1363\n",
      "Epoch 62 Batch 300 Loss 3.1374\n",
      "Epoch 62 Batch 400 Loss 3.1395\n",
      "Epoch 62 Batch 500 Loss 3.1427\n",
      "Epoch 62 Batch 600 Loss 3.1419\n",
      "Epoch 62 Batch 700 Loss 3.1418\n",
      "Epoch 62 Batch 800 Loss 3.1441\n",
      "Epoch 62 Batch 900 Loss 3.1444\n",
      "Saving checkpoint for epoch 62 at /home/ubuntu/aiffel/music_transformer/models/ckpt-31\n",
      "Epoch 62 Loss 3.1442\n",
      "Time taken for 1 epoch: 628.5208506584167 secs\n",
      "\n",
      "Epoch 63 Batch 0 Loss 3.1213\n",
      "Epoch 63 Batch 100 Loss 3.1312\n",
      "Epoch 63 Batch 200 Loss 3.1323\n",
      "Epoch 63 Batch 300 Loss 3.1352\n",
      "Epoch 63 Batch 400 Loss 3.1375\n",
      "Epoch 63 Batch 500 Loss 3.1411\n",
      "Epoch 63 Batch 600 Loss 3.1405\n",
      "Epoch 63 Batch 700 Loss 3.1403\n",
      "Epoch 63 Batch 800 Loss 3.1418\n",
      "Epoch 63 Batch 900 Loss 3.1431\n",
      "Epoch 63 Loss 3.1430\n",
      "Time taken for 1 epoch: 629.1968870162964 secs\n",
      "\n",
      "Epoch 64 Batch 0 Loss 3.1186\n",
      "Epoch 64 Batch 100 Loss 3.1264\n",
      "Epoch 64 Batch 200 Loss 3.1304\n",
      "Epoch 64 Batch 300 Loss 3.1332\n",
      "Epoch 64 Batch 400 Loss 3.1354\n",
      "Epoch 64 Batch 500 Loss 3.1395\n",
      "Epoch 64 Batch 600 Loss 3.1390\n",
      "Epoch 64 Batch 700 Loss 3.1385\n",
      "Epoch 64 Batch 800 Loss 3.1403\n",
      "Epoch 64 Batch 900 Loss 3.1415\n",
      "Saving checkpoint for epoch 64 at /home/ubuntu/aiffel/music_transformer/models/ckpt-32\n",
      "Epoch 64 Loss 3.1415\n",
      "Time taken for 1 epoch: 627.9375557899475 secs\n",
      "\n",
      "Epoch 65 Batch 0 Loss 3.1222\n",
      "Epoch 65 Batch 100 Loss 3.1303\n",
      "Epoch 65 Batch 200 Loss 3.1309\n",
      "Epoch 65 Batch 300 Loss 3.1318\n",
      "Epoch 65 Batch 400 Loss 3.1344\n",
      "Epoch 65 Batch 500 Loss 3.1380\n",
      "Epoch 65 Batch 600 Loss 3.1377\n",
      "Epoch 65 Batch 700 Loss 3.1376\n",
      "Epoch 65 Batch 800 Loss 3.1393\n",
      "Epoch 65 Batch 900 Loss 3.1401\n",
      "Epoch 65 Loss 3.1404\n",
      "Time taken for 1 epoch: 634.4303517341614 secs\n",
      "\n",
      "Epoch 66 Batch 0 Loss 3.1241\n",
      "Epoch 66 Batch 100 Loss 3.1250\n",
      "Epoch 66 Batch 200 Loss 3.1274\n",
      "Epoch 66 Batch 300 Loss 3.1301\n",
      "Epoch 66 Batch 400 Loss 3.1324\n",
      "Epoch 66 Batch 500 Loss 3.1362\n",
      "Epoch 66 Batch 600 Loss 3.1358\n",
      "Epoch 66 Batch 700 Loss 3.1363\n",
      "Epoch 66 Batch 800 Loss 3.1378\n",
      "Epoch 66 Batch 900 Loss 3.1390\n",
      "Saving checkpoint for epoch 66 at /home/ubuntu/aiffel/music_transformer/models/ckpt-33\n",
      "Epoch 66 Loss 3.1391\n",
      "Time taken for 1 epoch: 621.769987821579 secs\n",
      "\n",
      "Epoch 67 Batch 0 Loss 3.1669\n",
      "Epoch 67 Batch 100 Loss 3.1221\n",
      "Epoch 67 Batch 200 Loss 3.1259\n",
      "Epoch 67 Batch 300 Loss 3.1285\n",
      "Epoch 67 Batch 400 Loss 3.1319\n",
      "Epoch 67 Batch 500 Loss 3.1355\n",
      "Epoch 67 Batch 600 Loss 3.1361\n",
      "Epoch 67 Batch 700 Loss 3.1354\n",
      "Epoch 67 Batch 800 Loss 3.1368\n",
      "Epoch 67 Batch 900 Loss 3.1379\n",
      "Epoch 67 Loss 3.1381\n",
      "Time taken for 1 epoch: 627.6819014549255 secs\n",
      "\n",
      "Epoch 68 Batch 0 Loss 3.1660\n",
      "Epoch 68 Batch 100 Loss 3.1185\n",
      "Epoch 68 Batch 200 Loss 3.1236\n",
      "Epoch 68 Batch 300 Loss 3.1269\n",
      "Epoch 68 Batch 400 Loss 3.1305\n",
      "Epoch 68 Batch 500 Loss 3.1343\n",
      "Epoch 68 Batch 600 Loss 3.1332\n",
      "Epoch 68 Batch 700 Loss 3.1333\n",
      "Epoch 68 Batch 800 Loss 3.1343\n",
      "Epoch 68 Batch 900 Loss 3.1359\n",
      "Saving checkpoint for epoch 68 at /home/ubuntu/aiffel/music_transformer/models/ckpt-34\n",
      "Epoch 68 Loss 3.1362\n",
      "Time taken for 1 epoch: 624.8125789165497 secs\n",
      "\n",
      "Epoch 69 Batch 0 Loss 3.1668\n",
      "Epoch 69 Batch 100 Loss 3.1202\n",
      "Epoch 69 Batch 200 Loss 3.1242\n",
      "Epoch 69 Batch 300 Loss 3.1261\n",
      "Epoch 69 Batch 400 Loss 3.1292\n",
      "Epoch 69 Batch 500 Loss 3.1339\n",
      "Epoch 69 Batch 600 Loss 3.1333\n",
      "Epoch 69 Batch 700 Loss 3.1339\n",
      "Epoch 69 Batch 800 Loss 3.1350\n",
      "Epoch 69 Batch 900 Loss 3.1358\n",
      "Epoch 69 Loss 3.1360\n",
      "Time taken for 1 epoch: 628.0515022277832 secs\n",
      "\n",
      "Epoch 70 Batch 0 Loss 3.1243\n",
      "Epoch 70 Batch 100 Loss 3.1201\n",
      "Epoch 70 Batch 200 Loss 3.1260\n",
      "Epoch 70 Batch 300 Loss 3.1261\n",
      "Epoch 70 Batch 400 Loss 3.1292\n",
      "Epoch 70 Batch 500 Loss 3.1332\n",
      "Epoch 70 Batch 600 Loss 3.1321\n",
      "Epoch 70 Batch 700 Loss 3.1319\n",
      "Epoch 70 Batch 800 Loss 3.1332\n",
      "Epoch 70 Batch 900 Loss 3.1346\n",
      "Saving checkpoint for epoch 70 at /home/ubuntu/aiffel/music_transformer/models/ckpt-35\n",
      "Epoch 70 Loss 3.1342\n",
      "Time taken for 1 epoch: 627.1639964580536 secs\n",
      "\n",
      "Epoch 71 Batch 0 Loss 3.1387\n",
      "Epoch 71 Batch 100 Loss 3.1136\n",
      "Epoch 71 Batch 200 Loss 3.1203\n",
      "Epoch 71 Batch 300 Loss 3.1231\n",
      "Epoch 71 Batch 400 Loss 3.1265\n",
      "Epoch 71 Batch 500 Loss 3.1317\n",
      "Epoch 71 Batch 600 Loss 3.1306\n",
      "Epoch 71 Batch 700 Loss 3.1304\n",
      "Epoch 71 Batch 800 Loss 3.1323\n",
      "Epoch 71 Batch 900 Loss 3.1334\n",
      "Epoch 71 Loss 3.1336\n",
      "Time taken for 1 epoch: 627.1468689441681 secs\n",
      "\n",
      "Epoch 72 Batch 0 Loss 3.0826\n",
      "Epoch 72 Batch 100 Loss 3.1184\n",
      "Epoch 72 Batch 200 Loss 3.1204\n",
      "Epoch 72 Batch 300 Loss 3.1231\n",
      "Epoch 72 Batch 400 Loss 3.1269\n",
      "Epoch 72 Batch 500 Loss 3.1301\n",
      "Epoch 72 Batch 600 Loss 3.1299\n",
      "Epoch 72 Batch 700 Loss 3.1302\n",
      "Epoch 72 Batch 800 Loss 3.1309\n",
      "Epoch 72 Batch 900 Loss 3.1321\n",
      "Saving checkpoint for epoch 72 at /home/ubuntu/aiffel/music_transformer/models/ckpt-36\n",
      "Epoch 72 Loss 3.1328\n",
      "Time taken for 1 epoch: 619.4933111667633 secs\n",
      "\n",
      "Epoch 73 Batch 0 Loss 3.1457\n",
      "Epoch 73 Batch 100 Loss 3.1137\n",
      "Epoch 73 Batch 200 Loss 3.1194\n",
      "Epoch 73 Batch 300 Loss 3.1211\n",
      "Epoch 73 Batch 400 Loss 3.1253\n",
      "Epoch 73 Batch 500 Loss 3.1306\n",
      "Epoch 73 Batch 600 Loss 3.1286\n",
      "Epoch 73 Batch 700 Loss 3.1291\n",
      "Epoch 73 Batch 800 Loss 3.1303\n",
      "Epoch 73 Batch 900 Loss 3.1311\n",
      "Epoch 73 Loss 3.1314\n",
      "Time taken for 1 epoch: 624.4742016792297 secs\n",
      "\n",
      "Epoch 74 Batch 0 Loss 3.1822\n",
      "Epoch 74 Batch 100 Loss 3.1149\n",
      "Epoch 74 Batch 200 Loss 3.1189\n",
      "Epoch 74 Batch 300 Loss 3.1208\n",
      "Epoch 74 Batch 400 Loss 3.1249\n",
      "Epoch 74 Batch 500 Loss 3.1287\n",
      "Epoch 74 Batch 600 Loss 3.1281\n",
      "Epoch 74 Batch 700 Loss 3.1280\n",
      "Epoch 74 Batch 800 Loss 3.1290\n",
      "Epoch 74 Batch 900 Loss 3.1300\n",
      "Saving checkpoint for epoch 74 at /home/ubuntu/aiffel/music_transformer/models/ckpt-37\n",
      "Epoch 74 Loss 3.1305\n",
      "Time taken for 1 epoch: 620.7317748069763 secs\n",
      "\n",
      "Epoch 75 Batch 0 Loss 3.0299\n",
      "Epoch 75 Batch 100 Loss 3.1083\n",
      "Epoch 75 Batch 200 Loss 3.1146\n",
      "Epoch 75 Batch 300 Loss 3.1184\n",
      "Epoch 75 Batch 400 Loss 3.1225\n",
      "Epoch 75 Batch 500 Loss 3.1272\n",
      "Epoch 75 Batch 600 Loss 3.1271\n",
      "Epoch 75 Batch 700 Loss 3.1279\n",
      "Epoch 75 Batch 800 Loss 3.1286\n",
      "Epoch 75 Batch 900 Loss 3.1290\n",
      "Epoch 75 Loss 3.1291\n",
      "Time taken for 1 epoch: 620.2047426700592 secs\n",
      "\n",
      "Epoch 76 Batch 0 Loss 3.1291\n",
      "Epoch 76 Batch 100 Loss 3.1117\n",
      "Epoch 76 Batch 200 Loss 3.1170\n",
      "Epoch 76 Batch 300 Loss 3.1192\n",
      "Epoch 76 Batch 400 Loss 3.1219\n",
      "Epoch 76 Batch 500 Loss 3.1269\n",
      "Epoch 76 Batch 600 Loss 3.1266\n",
      "Epoch 76 Batch 700 Loss 3.1263\n",
      "Epoch 76 Batch 800 Loss 3.1280\n",
      "Epoch 76 Batch 900 Loss 3.1287\n",
      "Saving checkpoint for epoch 76 at /home/ubuntu/aiffel/music_transformer/models/ckpt-38\n",
      "Epoch 76 Loss 3.1288\n",
      "Time taken for 1 epoch: 625.2239530086517 secs\n",
      "\n",
      "Epoch 77 Batch 0 Loss 3.1064\n",
      "Epoch 77 Batch 100 Loss 3.1130\n",
      "Epoch 77 Batch 200 Loss 3.1153\n",
      "Epoch 77 Batch 300 Loss 3.1177\n",
      "Epoch 77 Batch 400 Loss 3.1201\n",
      "Epoch 77 Batch 500 Loss 3.1254\n",
      "Epoch 77 Batch 600 Loss 3.1238\n",
      "Epoch 77 Batch 700 Loss 3.1245\n",
      "Epoch 77 Batch 800 Loss 3.1266\n",
      "Epoch 77 Batch 900 Loss 3.1271\n",
      "Epoch 77 Loss 3.1274\n",
      "Time taken for 1 epoch: 620.9270305633545 secs\n",
      "\n",
      "Epoch 78 Batch 0 Loss 3.1226\n",
      "Epoch 78 Batch 100 Loss 3.1085\n",
      "Epoch 78 Batch 200 Loss 3.1142\n",
      "Epoch 78 Batch 300 Loss 3.1169\n",
      "Epoch 78 Batch 400 Loss 3.1207\n",
      "Epoch 78 Batch 500 Loss 3.1244\n",
      "Epoch 78 Batch 600 Loss 3.1240\n",
      "Epoch 78 Batch 700 Loss 3.1242\n",
      "Epoch 78 Batch 800 Loss 3.1264\n",
      "Epoch 78 Batch 900 Loss 3.1269\n",
      "Saving checkpoint for epoch 78 at /home/ubuntu/aiffel/music_transformer/models/ckpt-39\n",
      "Epoch 78 Loss 3.1269\n",
      "Time taken for 1 epoch: 622.0417196750641 secs\n",
      "\n",
      "Epoch 79 Batch 0 Loss 3.1010\n",
      "Epoch 79 Batch 100 Loss 3.1096\n",
      "Epoch 79 Batch 200 Loss 3.1127\n",
      "Epoch 79 Batch 300 Loss 3.1163\n",
      "Epoch 79 Batch 400 Loss 3.1195\n",
      "Epoch 79 Batch 500 Loss 3.1241\n",
      "Epoch 79 Batch 600 Loss 3.1228\n",
      "Epoch 79 Batch 700 Loss 3.1233\n",
      "Epoch 79 Batch 800 Loss 3.1248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Batch 900 Loss 3.1261\n",
      "Epoch 79 Loss 3.1258\n",
      "Time taken for 1 epoch: 621.1210341453552 secs\n",
      "\n",
      "Epoch 80 Batch 0 Loss 3.1003\n",
      "Epoch 80 Batch 100 Loss 3.1088\n",
      "Epoch 80 Batch 200 Loss 3.1156\n",
      "Epoch 80 Batch 300 Loss 3.1169\n",
      "Epoch 80 Batch 400 Loss 3.1192\n",
      "Epoch 80 Batch 500 Loss 3.1233\n",
      "Epoch 80 Batch 600 Loss 3.1230\n",
      "Epoch 80 Batch 700 Loss 3.1228\n",
      "Epoch 80 Batch 800 Loss 3.1238\n",
      "Epoch 80 Batch 900 Loss 3.1248\n",
      "Saving checkpoint for epoch 80 at /home/ubuntu/aiffel/music_transformer/models/ckpt-40\n",
      "Epoch 80 Loss 3.1249\n",
      "Time taken for 1 epoch: 633.0606722831726 secs\n",
      "\n",
      "Epoch 81 Batch 0 Loss 3.1615\n",
      "Epoch 81 Batch 100 Loss 3.1053\n",
      "Epoch 81 Batch 200 Loss 3.1120\n",
      "Epoch 81 Batch 300 Loss 3.1150\n",
      "Epoch 81 Batch 400 Loss 3.1166\n",
      "Epoch 81 Batch 500 Loss 3.1214\n",
      "Epoch 81 Batch 600 Loss 3.1212\n",
      "Epoch 81 Batch 700 Loss 3.1213\n",
      "Epoch 81 Batch 800 Loss 3.1234\n",
      "Epoch 81 Batch 900 Loss 3.1236\n",
      "Epoch 81 Loss 3.1238\n",
      "Time taken for 1 epoch: 620.6981153488159 secs\n",
      "\n",
      "Epoch 82 Batch 0 Loss 3.1751\n",
      "Epoch 82 Batch 100 Loss 3.1092\n",
      "Epoch 82 Batch 200 Loss 3.1129\n",
      "Epoch 82 Batch 300 Loss 3.1141\n",
      "Epoch 82 Batch 400 Loss 3.1162\n",
      "Epoch 82 Batch 500 Loss 3.1211\n",
      "Epoch 82 Batch 600 Loss 3.1204\n",
      "Epoch 82 Batch 700 Loss 3.1212\n",
      "Epoch 82 Batch 800 Loss 3.1223\n",
      "Epoch 82 Batch 900 Loss 3.1231\n",
      "Saving checkpoint for epoch 82 at /home/ubuntu/aiffel/music_transformer/models/ckpt-41\n",
      "Epoch 82 Loss 3.1235\n",
      "Time taken for 1 epoch: 632.3811621665955 secs\n",
      "\n",
      "Epoch 83 Batch 0 Loss 3.1319\n",
      "Epoch 83 Batch 100 Loss 3.1069\n",
      "Epoch 83 Batch 200 Loss 3.1096\n",
      "Epoch 83 Batch 300 Loss 3.1129\n",
      "Epoch 83 Batch 400 Loss 3.1156\n",
      "Epoch 83 Batch 500 Loss 3.1197\n",
      "Epoch 83 Batch 600 Loss 3.1192\n",
      "Epoch 83 Batch 700 Loss 3.1195\n",
      "Epoch 83 Batch 800 Loss 3.1205\n",
      "Epoch 83 Batch 900 Loss 3.1219\n",
      "Epoch 83 Loss 3.1221\n",
      "Time taken for 1 epoch: 628.8498239517212 secs\n",
      "\n",
      "Epoch 84 Batch 0 Loss 3.1276\n",
      "Epoch 84 Batch 100 Loss 3.1095\n",
      "Epoch 84 Batch 200 Loss 3.1101\n",
      "Epoch 84 Batch 300 Loss 3.1123\n",
      "Epoch 84 Batch 400 Loss 3.1148\n",
      "Epoch 84 Batch 500 Loss 3.1193\n",
      "Epoch 84 Batch 600 Loss 3.1187\n",
      "Epoch 84 Batch 700 Loss 3.1184\n",
      "Epoch 84 Batch 800 Loss 3.1201\n",
      "Epoch 84 Batch 900 Loss 3.1212\n",
      "Saving checkpoint for epoch 84 at /home/ubuntu/aiffel/music_transformer/models/ckpt-42\n",
      "Epoch 84 Loss 3.1215\n",
      "Time taken for 1 epoch: 621.9335806369781 secs\n",
      "\n",
      "Epoch 85 Batch 0 Loss 3.0792\n",
      "Epoch 85 Batch 100 Loss 3.1028\n",
      "Epoch 85 Batch 200 Loss 3.1082\n",
      "Epoch 85 Batch 300 Loss 3.1103\n",
      "Epoch 85 Batch 400 Loss 3.1140\n",
      "Epoch 85 Batch 500 Loss 3.1190\n",
      "Epoch 85 Batch 600 Loss 3.1183\n",
      "Epoch 85 Batch 700 Loss 3.1181\n",
      "Epoch 85 Batch 800 Loss 3.1199\n",
      "Epoch 85 Batch 900 Loss 3.1213\n",
      "Epoch 85 Loss 3.1213\n",
      "Time taken for 1 epoch: 621.422708272934 secs\n",
      "\n",
      "Epoch 86 Batch 0 Loss 3.0819\n",
      "Epoch 86 Batch 100 Loss 3.1033\n",
      "Epoch 86 Batch 200 Loss 3.1093\n",
      "Epoch 86 Batch 300 Loss 3.1114\n",
      "Epoch 86 Batch 400 Loss 3.1140\n",
      "Epoch 86 Batch 500 Loss 3.1181\n",
      "Epoch 86 Batch 600 Loss 3.1174\n",
      "Epoch 86 Batch 700 Loss 3.1178\n",
      "Epoch 86 Batch 800 Loss 3.1193\n",
      "Epoch 86 Batch 900 Loss 3.1203\n",
      "Saving checkpoint for epoch 86 at /home/ubuntu/aiffel/music_transformer/models/ckpt-43\n",
      "Epoch 86 Loss 3.1207\n",
      "Time taken for 1 epoch: 618.3331518173218 secs\n",
      "\n",
      "Epoch 87 Batch 0 Loss 3.1229\n",
      "Epoch 87 Batch 100 Loss 3.1023\n",
      "Epoch 87 Batch 200 Loss 3.1068\n",
      "Epoch 87 Batch 300 Loss 3.1092\n",
      "Epoch 87 Batch 400 Loss 3.1125\n",
      "Epoch 87 Batch 500 Loss 3.1170\n",
      "Epoch 87 Batch 600 Loss 3.1179\n",
      "Epoch 87 Batch 700 Loss 3.1173\n",
      "Epoch 87 Batch 800 Loss 3.1190\n",
      "Epoch 87 Batch 900 Loss 3.1197\n",
      "Epoch 87 Loss 3.1200\n",
      "Time taken for 1 epoch: 622.2734265327454 secs\n",
      "\n",
      "Epoch 88 Batch 0 Loss 3.1767\n",
      "Epoch 88 Batch 100 Loss 3.1003\n",
      "Epoch 88 Batch 200 Loss 3.1059\n",
      "Epoch 88 Batch 300 Loss 3.1101\n",
      "Epoch 88 Batch 400 Loss 3.1136\n",
      "Epoch 88 Batch 500 Loss 3.1169\n",
      "Epoch 88 Batch 600 Loss 3.1160\n",
      "Epoch 88 Batch 700 Loss 3.1169\n",
      "Epoch 88 Batch 800 Loss 3.1178\n",
      "Epoch 88 Batch 900 Loss 3.1195\n",
      "Saving checkpoint for epoch 88 at /home/ubuntu/aiffel/music_transformer/models/ckpt-44\n",
      "Epoch 88 Loss 3.1197\n",
      "Time taken for 1 epoch: 623.0753486156464 secs\n",
      "\n",
      "Epoch 89 Batch 0 Loss 3.0895\n",
      "Epoch 89 Batch 100 Loss 3.1079\n",
      "Epoch 89 Batch 200 Loss 3.1077\n",
      "Epoch 89 Batch 300 Loss 3.1087\n",
      "Epoch 89 Batch 400 Loss 3.1119\n",
      "Epoch 89 Batch 500 Loss 3.1176\n",
      "Epoch 89 Batch 600 Loss 3.1169\n",
      "Epoch 89 Batch 700 Loss 3.1167\n",
      "Epoch 89 Batch 800 Loss 3.1178\n",
      "Epoch 89 Batch 900 Loss 3.1189\n",
      "Epoch 89 Loss 3.1193\n",
      "Time taken for 1 epoch: 626.5080034732819 secs\n",
      "\n",
      "Epoch 90 Batch 0 Loss 3.0910\n",
      "Epoch 90 Batch 100 Loss 3.0997\n",
      "Epoch 90 Batch 200 Loss 3.1063\n",
      "Epoch 90 Batch 300 Loss 3.1074\n",
      "Epoch 90 Batch 400 Loss 3.1118\n",
      "Epoch 90 Batch 500 Loss 3.1161\n",
      "Epoch 90 Batch 600 Loss 3.1148\n",
      "Epoch 90 Batch 700 Loss 3.1147\n",
      "Epoch 90 Batch 800 Loss 3.1167\n",
      "Epoch 90 Batch 900 Loss 3.1174\n",
      "Saving checkpoint for epoch 90 at /home/ubuntu/aiffel/music_transformer/models/ckpt-45\n",
      "Epoch 90 Loss 3.1176\n",
      "Time taken for 1 epoch: 622.6690111160278 secs\n",
      "\n",
      "Epoch 91 Batch 0 Loss 3.1001\n",
      "Epoch 91 Batch 100 Loss 3.1018\n",
      "Epoch 91 Batch 200 Loss 3.1059\n",
      "Epoch 91 Batch 300 Loss 3.1085\n",
      "Epoch 91 Batch 400 Loss 3.1123\n",
      "Epoch 91 Batch 500 Loss 3.1159\n",
      "Epoch 91 Batch 600 Loss 3.1139\n",
      "Epoch 91 Batch 700 Loss 3.1148\n",
      "Epoch 91 Batch 800 Loss 3.1160\n",
      "Epoch 91 Batch 900 Loss 3.1172\n",
      "Epoch 91 Loss 3.1175\n",
      "Time taken for 1 epoch: 628.8793354034424 secs\n",
      "\n",
      "Epoch 92 Batch 0 Loss 3.1348\n",
      "Epoch 92 Batch 100 Loss 3.1043\n",
      "Epoch 92 Batch 200 Loss 3.1046\n",
      "Epoch 92 Batch 300 Loss 3.1075\n",
      "Epoch 92 Batch 400 Loss 3.1117\n",
      "Epoch 92 Batch 500 Loss 3.1154\n",
      "Epoch 92 Batch 600 Loss 3.1143\n",
      "Epoch 92 Batch 700 Loss 3.1143\n",
      "Epoch 92 Batch 800 Loss 3.1161\n",
      "Epoch 92 Batch 900 Loss 3.1170\n",
      "Saving checkpoint for epoch 92 at /home/ubuntu/aiffel/music_transformer/models/ckpt-46\n",
      "Epoch 92 Loss 3.1174\n",
      "Time taken for 1 epoch: 621.6823766231537 secs\n",
      "\n",
      "Epoch 93 Batch 0 Loss 3.1393\n",
      "Epoch 93 Batch 100 Loss 3.1033\n",
      "Epoch 93 Batch 200 Loss 3.1041\n",
      "Epoch 93 Batch 300 Loss 3.1074\n",
      "Epoch 93 Batch 400 Loss 3.1107\n",
      "Epoch 93 Batch 500 Loss 3.1148\n",
      "Epoch 93 Batch 600 Loss 3.1140\n",
      "Epoch 93 Batch 700 Loss 3.1142\n",
      "Epoch 93 Batch 800 Loss 3.1157\n",
      "Epoch 93 Batch 900 Loss 3.1166\n",
      "Epoch 93 Loss 3.1168\n",
      "Time taken for 1 epoch: 626.6893002986908 secs\n",
      "\n",
      "Epoch 94 Batch 0 Loss 3.1583\n",
      "Epoch 94 Batch 100 Loss 3.1000\n",
      "Epoch 94 Batch 200 Loss 3.1034\n",
      "Epoch 94 Batch 300 Loss 3.1061\n",
      "Epoch 94 Batch 400 Loss 3.1098\n",
      "Epoch 94 Batch 500 Loss 3.1142\n",
      "Epoch 94 Batch 600 Loss 3.1136\n",
      "Epoch 94 Batch 700 Loss 3.1141\n",
      "Epoch 94 Batch 800 Loss 3.1150\n",
      "Epoch 94 Batch 900 Loss 3.1160\n",
      "Saving checkpoint for epoch 94 at /home/ubuntu/aiffel/music_transformer/models/ckpt-47\n",
      "Epoch 94 Loss 3.1160\n",
      "Time taken for 1 epoch: 627.3440184593201 secs\n",
      "\n",
      "Epoch 95 Batch 0 Loss 3.0784\n",
      "Epoch 95 Batch 100 Loss 3.0981\n",
      "Epoch 95 Batch 200 Loss 3.1014\n",
      "Epoch 95 Batch 300 Loss 3.1054\n",
      "Epoch 95 Batch 400 Loss 3.1090\n",
      "Epoch 95 Batch 500 Loss 3.1137\n",
      "Epoch 95 Batch 600 Loss 3.1131\n",
      "Epoch 95 Batch 700 Loss 3.1129\n",
      "Epoch 95 Batch 800 Loss 3.1148\n",
      "Epoch 95 Batch 900 Loss 3.1155\n",
      "Epoch 95 Loss 3.1155\n",
      "Time taken for 1 epoch: 621.766491651535 secs\n",
      "\n",
      "Epoch 96 Batch 0 Loss 3.0369\n",
      "Epoch 96 Batch 100 Loss 3.0952\n",
      "Epoch 96 Batch 200 Loss 3.1017\n",
      "Epoch 96 Batch 300 Loss 3.1037\n",
      "Epoch 96 Batch 400 Loss 3.1073\n",
      "Epoch 96 Batch 500 Loss 3.1109\n",
      "Epoch 96 Batch 600 Loss 3.1110\n",
      "Epoch 96 Batch 700 Loss 3.1119\n",
      "Epoch 96 Batch 800 Loss 3.1140\n",
      "Epoch 96 Batch 900 Loss 3.1149\n",
      "Saving checkpoint for epoch 96 at /home/ubuntu/aiffel/music_transformer/models/ckpt-48\n",
      "Epoch 96 Loss 3.1149\n",
      "Time taken for 1 epoch: 629.5704762935638 secs\n",
      "\n",
      "Epoch 97 Batch 0 Loss 3.1712\n",
      "Epoch 97 Batch 100 Loss 3.0968\n",
      "Epoch 97 Batch 200 Loss 3.1009\n",
      "Epoch 97 Batch 300 Loss 3.1038\n",
      "Epoch 97 Batch 400 Loss 3.1078\n",
      "Epoch 97 Batch 500 Loss 3.1118\n",
      "Epoch 97 Batch 600 Loss 3.1114\n",
      "Epoch 97 Batch 700 Loss 3.1116\n",
      "Epoch 97 Batch 800 Loss 3.1131\n",
      "Epoch 97 Batch 900 Loss 3.1141\n",
      "Epoch 97 Loss 3.1146\n",
      "Time taken for 1 epoch: 623.0074133872986 secs\n",
      "\n",
      "Epoch 98 Batch 0 Loss 3.0937\n",
      "Epoch 98 Batch 100 Loss 3.0984\n",
      "Epoch 98 Batch 200 Loss 3.1040\n",
      "Epoch 98 Batch 300 Loss 3.1049\n",
      "Epoch 98 Batch 400 Loss 3.1075\n",
      "Epoch 98 Batch 500 Loss 3.1113\n",
      "Epoch 98 Batch 600 Loss 3.1120\n",
      "Epoch 98 Batch 700 Loss 3.1125\n",
      "Epoch 98 Batch 800 Loss 3.1136\n",
      "Epoch 98 Batch 900 Loss 3.1142\n",
      "Saving checkpoint for epoch 98 at /home/ubuntu/aiffel/music_transformer/models/ckpt-49\n",
      "Epoch 98 Loss 3.1146\n",
      "Time taken for 1 epoch: 632.3865303993225 secs\n",
      "\n",
      "Epoch 99 Batch 0 Loss 3.1267\n",
      "Epoch 99 Batch 100 Loss 3.0963\n",
      "Epoch 99 Batch 200 Loss 3.0999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Batch 300 Loss 3.1032\n",
      "Epoch 99 Batch 400 Loss 3.1056\n",
      "Epoch 99 Batch 500 Loss 3.1104\n",
      "Epoch 99 Batch 600 Loss 3.1110\n",
      "Epoch 99 Batch 700 Loss 3.1113\n",
      "Epoch 99 Batch 800 Loss 3.1129\n",
      "Epoch 99 Batch 900 Loss 3.1135\n",
      "Epoch 99 Loss 3.1137\n",
      "Time taken for 1 epoch: 627.6714272499084 secs\n",
      "\n",
      "Epoch 100 Batch 0 Loss 3.0769\n",
      "Epoch 100 Batch 100 Loss 3.0927\n",
      "Epoch 100 Batch 200 Loss 3.0983\n",
      "Epoch 100 Batch 300 Loss 3.1018\n",
      "Epoch 100 Batch 400 Loss 3.1065\n",
      "Epoch 100 Batch 500 Loss 3.1112\n",
      "Epoch 100 Batch 600 Loss 3.1098\n",
      "Epoch 100 Batch 700 Loss 3.1104\n",
      "Epoch 100 Batch 800 Loss 3.1118\n",
      "Epoch 100 Batch 900 Loss 3.1124\n",
      "Saving checkpoint for epoch 100 at /home/ubuntu/aiffel/music_transformer/models/ckpt-50\n",
      "Epoch 100 Loss 3.1128\n",
      "Time taken for 1 epoch: 626.2907378673553 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EPOCHS = 20  \n",
    "EPOCHS = 100\n",
    "\n",
    "loss_data = {'loss': []}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions, _ = music_transformer(inp, True, None, None, None)\n",
    "            loss = loss_function(tar, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, music_transformer.trainable_variables)    \n",
    "        optimizer.apply_gradients(zip(gradients, music_transformer.trainable_variables))\n",
    "\n",
    "        train_loss(loss)\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f}'.format(\n",
    "                epoch + 1, batch, train_loss.result()))\n",
    "            loss_data['loss'].append(train_loss.result())\n",
    "\n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(loss_data['loss'], 'r')\n",
    "plt.legend(['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : 제공된 체크포인트 파일을 이용하여 다양한 midi 파일 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/aiffel/music_transformer/models/ckpt-50'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((train_data_pad, train_label_pad))\n",
    "test_dataset = test_dataset.map(tensor_casting)\n",
    "test_dataset = test_dataset.shuffle(10000).batch(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "194\n",
      "2\n",
      "114\n",
      "205\n",
      "2\n",
      "110\n",
      "190\n",
      "4\n",
      "117\n",
      "205\n",
      "1\n",
      "109\n",
      "188\n",
      "7\n",
      "306\n",
      "2\n",
      "313\n",
      "2\n",
      "336\n",
      "7\n",
      "112\n",
      "177\n",
      "7\n",
      "388\n",
      "9\n",
      "389\n",
      "2\n",
      "111\n",
      "194\n",
      "3\n",
      "389\n",
      "6\n",
      "317\n",
      "2\n",
      "120\n",
      "208\n",
      "2\n",
      "122\n",
      "201\n",
      "1\n",
      "337\n",
      "3\n",
      "332\n",
      "17\n",
      "118\n",
      "206\n",
      "2\n",
      "120\n",
      "201\n",
      "1\n",
      "334\n",
      "7\n",
      "118\n",
      "203\n",
      "1\n",
      "332\n",
      "1\n",
      "317\n",
      "2\n",
      "112\n",
      "204\n",
      "9\n",
      "332\n",
      "14\n",
      "115\n",
      "197\n",
      "3\n",
      "322\n",
      "1\n",
      "112\n",
      "195\n",
      "4\n",
      "389\n",
      "2\n",
      "119\n",
      "200\n",
      "5\n",
      "328\n",
      "3\n",
      "319\n",
      "1\n",
      "114\n",
      "184\n",
      "4\n",
      "307\n",
      "1\n",
      "117\n",
      "175\n",
      "2\n",
      "122\n",
      "209\n",
      "4\n",
      "119\n",
      "202\n",
      "2\n",
      "328\n",
      "1\n",
      "111\n",
      "182\n",
      "2\n",
      "334\n",
      "3\n",
      "310\n",
      "10\n",
      "115\n",
      "189\n",
      "7\n",
      "317\n",
      "8\n",
      "116\n",
      "192\n",
      "8\n",
      "320\n",
      "4\n",
      "117\n",
      "207\n",
      "4\n",
      "335\n",
      "1\n",
      "120\n",
      "209\n",
      "7\n",
      "301\n",
      "4\n",
      "116\n",
      "197\n",
      "1\n",
      "326\n",
      "2\n",
      "338\n",
      "2\n",
      "335\n",
      "4\n",
      "115\n",
      "180\n",
      "8\n",
      "105\n",
      "204\n",
      "17\n",
      "332\n",
      "2\n",
      "120\n",
      "193\n",
      "3\n",
      "388\n",
      "6\n",
      "326\n",
      "1\n",
      "115\n",
      "202\n",
      "46\n",
      "332\n",
      "8\n",
      "331\n",
      "1\n",
      "113\n",
      "198\n",
      "13\n",
      "326\n",
      "3\n",
      "293\n",
      "1\n",
      "117\n",
      "192\n",
      "2\n",
      "115\n",
      "185\n",
      "4\n",
      "310\n",
      "13\n",
      "118\n",
      "176\n",
      "3\n",
      "316\n",
      "13\n",
      "318\n",
      "6\n",
      "119\n",
      "197\n",
      "7\n",
      "325\n",
      "8\n",
      "125\n",
      "205\n",
      "9\n",
      "323\n",
      "31\n",
      "118\n",
      "189\n",
      "1\n",
      "114\n",
      "198\n",
      "1\n",
      "117\n",
      "189\n",
      "3\n",
      "331\n",
      "2\n",
      "317\n",
      "19\n",
      "116\n",
      "202\n",
      "10\n",
      "389\n",
      "4\n",
      "333\n",
      "3\n",
      "117\n",
      "193\n",
      "1\n",
      "338\n",
      "19\n",
      "321\n",
      "19\n",
      "117\n",
      "208\n",
      "2\n",
      "339\n",
      "17\n",
      "336\n",
      "8\n",
      "116\n",
      "197\n",
      "2\n",
      "304\n",
      "13\n",
      "114\n",
      "202\n",
      "19\n",
      "330\n",
      "10\n",
      "117\n",
      "216\n",
      "9\n",
      "344\n",
      "17\n",
      "121\n",
      "216\n",
      "1\n",
      "351\n",
      "12\n",
      "120\n",
      "214\n",
      "6\n",
      "313\n",
      "9\n",
      "122\n",
      "185\n",
      "9\n",
      "301\n",
      "5\n",
      "117\n",
      "174\n",
      "7\n",
      "302\n",
      "6\n",
      "118\n",
      "204\n",
      "14\n",
      "301\n",
      "9\n",
      "118\n",
      "190\n",
      "1\n",
      "388\n",
      "19\n",
      "389\n",
      "7\n",
      "342\n",
      "6\n",
      "118\n",
      "176\n",
      "15\n",
      "304\n",
      "2\n",
      "119\n",
      "183\n",
      "21\n",
      "311\n",
      "4\n",
      "117\n",
      "180\n",
      "9\n",
      "308\n",
      "1\n",
      "330\n",
      "9\n",
      "120\n",
      "191\n",
      "3\n",
      "116\n",
      "183\n",
      "10\n",
      "311\n",
      "15\n",
      "315\n",
      "19\n",
      "118\n",
      "179\n",
      "17\n",
      "113\n",
      "177\n",
      "1\n",
      "302\n",
      "9\n",
      "305\n",
      "8\n",
      "311\n",
      "1\n",
      "308\n",
      "9\n",
      "117\n",
      "189\n",
      "2\n",
      "115\n",
      "182\n",
      "6\n",
      "307\n",
      "2\n",
      "303\n",
      "1\n",
      "118\n",
      "175\n",
      "1\n",
      "388\n",
      "6\n",
      "123\n",
      "207\n",
      "51\n",
      "109\n",
      "180\n",
      "3\n",
      "333\n",
      "8\n",
      "339\n",
      "2\n",
      "120\n",
      "191\n",
      "1\n",
      "337\n",
      "24\n",
      "307\n",
      "37\n",
      "122\n",
      "197\n",
      "3\n",
      "122\n",
      "209\n",
      "9\n",
      "337\n",
      "14\n",
      "388\n",
      "7\n",
      "340\n",
      "38\n",
      "124\n",
      "178\n",
      "3\n",
      "337\n",
      "24\n",
      "124\n",
      "214\n",
      "19\n",
      "319\n",
      "7\n",
      "125\n",
      "199\n",
      "1\n",
      "338\n",
      "12\n",
      "331\n",
      "34\n",
      "120\n",
      "208\n",
      "6\n",
      "336\n",
      "4\n",
      "123\n",
      "215\n",
      "2\n",
      "121\n",
      "197\n",
      "5\n",
      "331\n",
      "3\n",
      "119\n",
      "174\n",
      "4\n",
      "123\n",
      "211\n",
      "3\n",
      "343\n",
      "5\n",
      "350\n",
      "5\n",
      "118\n",
      "206\n",
      "3\n",
      "119\n",
      "197\n",
      "13\n",
      "337\n",
      "15\n",
      "122\n",
      "200\n",
      "1\n",
      "331\n",
      "3\n",
      "322\n",
      "4\n",
      "124\n",
      "218\n",
      "1\n",
      "124\n",
      "203\n",
      "21\n",
      "119\n",
      "199\n",
      "5\n",
      "334\n",
      "1\n",
      "339\n",
      "12\n",
      "117\n",
      "211\n",
      "12\n",
      "339\n",
      "8\n",
      "121\n",
      "192\n",
      "12\n",
      "324\n",
      "32\n",
      "325\n",
      "19\n",
      "122\n",
      "214\n",
      "4\n",
      "342\n",
      "36\n",
      "388\n",
      "33\n",
      "389\n",
      "6\n",
      "340\n",
      "2\n",
      "115\n",
      "205\n",
      "11\n",
      "327\n",
      "4\n",
      "119\n",
      "205\n",
      "20\n",
      "115\n",
      "205\n",
      "2\n",
      "321\n",
      "12\n",
      "318\n",
      "12\n",
      "121\n",
      "211\n",
      "2\n",
      "117\n",
      "183\n",
      "13\n",
      "323\n",
      "2\n",
      "332\n",
      "1\n",
      "341\n",
      "10\n",
      "341\n",
      "34\n",
      "118\n",
      "211\n",
      "2\n",
      "119\n",
      "205\n",
      "12\n",
      "335\n",
      "4\n",
      "119\n",
      "197\n",
      "18\n",
      "332\n",
      "18\n",
      "114\n",
      "192\n",
      "2\n",
      "339\n",
      "20\n",
      "320\n",
      "7\n",
      "118\n",
      "204\n",
      "5\n",
      "332\n",
      "14\n",
      "112\n",
      "183\n",
      "6\n",
      "323\n",
      "21\n",
      "117\n",
      "207\n",
      "1\n",
      "332\n",
      "33\n",
      "318\n",
      "2\n",
      "111\n",
      "184\n",
      "22\n",
      "312\n",
      "9\n",
      "311\n",
      "12\n",
      "120\n",
      "192\n",
      "15\n",
      "322\n",
      "67\n",
      "112\n",
      "198\n",
      "2\n",
      "108\n",
      "192\n",
      "2\n",
      "310\n",
      "16\n",
      "321\n",
      "2\n",
      "111\n",
      "165\n",
      "15\n",
      "317\n",
      "22\n",
      "334\n",
      "1\n",
      "330\n",
      "19\n",
      "118\n",
      "203\n",
      "17\n",
      "304\n",
      "12\n",
      "116\n",
      "207\n",
      "15\n",
      "326\n",
      "9\n",
      "330\n",
      "25\n",
      "113\n",
      "163\n",
      "13\n",
      "296\n",
      "6\n",
      "111\n",
      "189\n",
      "15\n",
      "121\n",
      "210\n",
      "1\n",
      "332\n",
      "19\n",
      "333\n",
      "13\n",
      "119\n",
      "206\n",
      "1\n",
      "118\n",
      "208\n",
      "8\n",
      "337\n",
      "1\n",
      "110\n",
      "182\n",
      "8\n",
      "322\n",
      "2\n",
      "310\n",
      "6\n",
      "118\n",
      "206\n",
      "4\n",
      "332\n",
      "12\n",
      "114\n",
      "204\n",
      "2\n",
      "116\n",
      "182\n",
      "2\n",
      "117\n",
      "213\n",
      "27\n",
      "331\n",
      "1\n",
      "119\n",
      "212\n",
      "1\n",
      "116\n",
      "190\n",
      "6\n",
      "339\n",
      "3\n",
      "339\n",
      "10\n",
      "340\n",
      "18\n",
      "114\n",
      "207\n",
      "1\n",
      "117\n",
      "199\n",
      "1\n",
      "117\n",
      "199\n",
      "5\n",
      "327\n",
      "16\n",
      "112\n",
      "192\n",
      "4\n",
      "320\n",
      "20\n",
      "115\n",
      "205\n",
      "1\n",
      "320\n",
      "16\n",
      "336\n",
      "12\n",
      "123\n",
      "191\n",
      "5\n",
      "319\n",
      "16\n",
      "119\n",
      "208\n",
      "15\n",
      "336\n",
      "12\n",
      "325\n",
      "1\n",
      "117\n",
      "197\n",
      "14\n",
      "114\n",
      "210\n",
      "9\n",
      "329\n",
      "2\n",
      "337\n",
      "3\n",
      "337\n",
      "15\n",
      "117\n",
      "207\n",
      "3\n",
      "335\n",
      "15\n",
      "109\n",
      "196\n",
      "8\n",
      "324\n",
      "3\n",
      "108\n",
      "196\n",
      "6\n",
      "335\n",
      "6\n",
      "319\n",
      "1\n",
      "112\n",
      "215\n",
      "4\n",
      "319\n",
      "3\n",
      "112\n",
      "203\n",
      "26\n",
      "318\n",
      "5\n",
      "109\n",
      "192\n",
      "4\n",
      "329\n",
      "1\n",
      "112\n",
      "200\n",
      "1\n",
      "110\n",
      "184\n",
      "19\n",
      "320\n",
      "6\n",
      "109\n",
      "182\n",
      "6\n",
      "313\n",
      "4\n",
      "323\n",
      "8\n",
      "318\n",
      "10\n",
      "111\n",
      "197\n",
      "16\n",
      "122\n",
      "207\n",
      "7\n",
      "337\n",
      "2\n",
      "114\n",
      "199\n",
      "6\n",
      "324\n",
      "1\n",
      "113\n",
      "200\n",
      "2\n",
      "115\n",
      "208\n",
      "13\n",
      "117\n",
      "204\n",
      "2\n",
      "324\n",
      "4\n",
      "332\n",
      "2\n",
      "115\n",
      "204\n",
      "6\n",
      "389\n",
      "9\n",
      "315\n",
      "1\n",
      "321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1000\n",
    "_inputs = np.zeros([1, N], dtype=np.int32)\n",
    "\n",
    "for x, y in test_dataset.take(1):\n",
    "    _inputs[:, :length] = x[None, :]\n",
    "    \n",
    "for i in range(N - length):\n",
    "    predictions, _ = music_transformer(_inputs[:, i:i+length], True, None, None, None)\n",
    "    predictions = tf.squeeze(predictions, 0)    \n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "    print(predicted_id)\n",
    "    \n",
    "    # 예측된 단어를 다음 입력으로 모델에 전달\n",
    "    # 이전 은닉 상태와 함께\n",
    "    _inputs[:, i+length] = predicted_id\n",
    "\n",
    "_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event():\n",
    "    def __init__(self, time, note, cc, on, velocity):\n",
    "        self.time = time\n",
    "        self.note = note\n",
    "        self.on = on\n",
    "        self.cc = cc\n",
    "        self.velocity = velocity\n",
    "\n",
    "    def get_event_sequence(self):\n",
    "        return [self.time, self.note, int(self.on)]\n",
    "\n",
    "class Note():\n",
    "    def __init__(self):\n",
    "        self.pitch = 0\n",
    "        self.start_time = 0\n",
    "        self.end_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_list = []\n",
    "time = 0\n",
    "event = None\n",
    "\n",
    "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim # 388\n",
    "\n",
    "for _input in _inputs[0]:\n",
    "    # interval\n",
    "    if _input < IntervalDim: \n",
    "        time += _input\n",
    "        event = Event(time, 0, False, 0, 0)\n",
    "\n",
    "    # velocity\n",
    "    elif _input < NoteOnOffset:\n",
    "        if event is None:\n",
    "            continue\n",
    "        event.velocity = (_input - VelocityOffset) / VelocityDim * 128\n",
    "\n",
    "    # note on\n",
    "    elif _input < NoteOffOffset:\n",
    "        if event is None:\n",
    "            continue\n",
    "\n",
    "        event.note = _input - NoteOnOffset\n",
    "        event.on = True\n",
    "        event_list.append(event)\n",
    "\n",
    "        event = None\n",
    "\n",
    "    # note off\n",
    "    elif _input < CCOffset:\n",
    "        if event is None:\n",
    "            continue\n",
    "        event.note = _input - NoteOffOffset\n",
    "        event.on = False\n",
    "        event_list.append(event)\n",
    "        event = None\n",
    "\n",
    "    ## CC\n",
    "    else:\n",
    "        if event is None:\n",
    "            continue\n",
    "        event.cc = True\n",
    "        on = _input - CCOffset == 1\n",
    "        event.on = on\n",
    "        event_list.append(event)\n",
    "        event = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track 0: \n",
      "<meta message set_tempo tempo=500000 time=0>\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_off channel=0 note=91 velocity=0 time=1\n",
      "note_on channel=0 note=79 velocity=52 time=1\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=82 velocity=32 time=0\n",
      "note_off channel=0 note=79 velocity=0 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=91 velocity=72 time=0\n",
      "note_off channel=0 note=91 velocity=0 time=2\n",
      "note_on channel=0 note=79 velocity=56 time=1\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_on channel=0 note=82 velocity=36 time=0\n",
      "note_off channel=0 note=79 velocity=0 time=0\n",
      "note_off channel=0 note=67 velocity=0 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=91 velocity=68 time=0\n",
      "note_off channel=0 note=91 velocity=0 time=1\n",
      "note_on channel=0 note=79 velocity=52 time=1\n",
      "note_on channel=0 note=82 velocity=44 time=1\n",
      "note_off channel=0 note=79 velocity=0 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=91 velocity=72 time=0\n",
      "note_off channel=0 note=91 velocity=0 time=2\n",
      "note_on channel=0 note=79 velocity=56 time=0\n",
      "note_on channel=0 note=82 velocity=48 time=0\n",
      "note_off channel=0 note=79 velocity=0 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=91 velocity=64 time=1\n",
      "note_off channel=0 note=91 velocity=0 time=1\n",
      "note_on channel=0 note=82 velocity=56 time=1\n",
      "note_on channel=0 note=79 velocity=52 time=0\n",
      "note_off channel=0 note=79 velocity=0 time=1\n",
      "note_off channel=0 note=82 velocity=0 time=1\n",
      "note_on channel=0 note=91 velocity=64 time=0\n",
      "note_off channel=0 note=91 velocity=0 time=1\n",
      "note_on channel=0 note=79 velocity=56 time=0\n",
      "note_on channel=0 note=82 velocity=36 time=1\n",
      "note_off channel=0 note=79 velocity=0 time=1\n",
      "note_off channel=0 note=82 velocity=0 time=1\n",
      "note_on channel=0 note=91 velocity=76 time=0\n",
      "note_on channel=0 note=61 velocity=56 time=1\n",
      "note_off channel=0 note=91 velocity=0 time=1\n",
      "note_on channel=0 note=67 velocity=56 time=1\n",
      "note_on channel=0 note=69 velocity=64 time=6\n",
      "note_on channel=0 note=81 velocity=32 time=0\n",
      "note_on channel=0 note=77 velocity=16 time=0\n",
      "note_on channel=0 note=89 velocity=56 time=1\n",
      "note_off channel=0 note=81 velocity=0 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_off channel=0 note=89 velocity=0 time=1\n",
      "note_on channel=0 note=81 velocity=44 time=3\n",
      "note_on channel=0 note=77 velocity=24 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=1\n",
      "note_on channel=0 note=89 velocity=60 time=0\n",
      "note_off channel=0 note=67 velocity=0 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=0\n",
      "note_off channel=0 note=61 velocity=0 time=0\n",
      "note_off channel=0 note=89 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=28 time=2\n",
      "note_on channel=0 note=81 velocity=48 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=1\n",
      "note_on channel=0 note=89 velocity=72 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=0\n",
      "note_on channel=0 note=61 velocity=56 time=1\n",
      "note_off channel=0 note=89 velocity=0 time=1\n",
      "note_on channel=0 note=67 velocity=56 time=1\n",
      "note_on channel=0 note=70 velocity=72 time=3\n",
      "note_on channel=0 note=82 velocity=52 time=1\n",
      "note_on channel=0 note=76 velocity=52 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=1\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=88 velocity=64 time=0\n",
      "note_off channel=0 note=88 velocity=0 time=1\n",
      "note_on channel=0 note=76 velocity=56 time=1\n",
      "note_off channel=0 note=61 velocity=0 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_on channel=0 note=82 velocity=52 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=2\n",
      "note_off channel=0 note=67 velocity=0 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=88 velocity=72 time=0\n",
      "note_off channel=0 note=88 velocity=0 time=2\n",
      "note_on channel=0 note=76 velocity=48 time=0\n",
      "note_on channel=0 note=82 velocity=56 time=0\n",
      "note_on channel=0 note=62 velocity=68 time=1\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=88 velocity=64 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_on channel=0 note=67 velocity=60 time=0\n",
      "note_off channel=0 note=88 velocity=0 time=1\n",
      "note_on channel=0 note=71 velocity=84 time=3\n",
      "control_change channel=0 control=64 value=0 time=1\n",
      "note_on channel=0 note=83 velocity=60 time=0\n",
      "note_on channel=0 note=74 velocity=44 time=0\n",
      "control_change channel=0 control=64 value=127 time=1\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_off channel=0 note=83 velocity=0 time=0\n",
      "note_on channel=0 note=86 velocity=68 time=0\n",
      "note_off channel=0 note=62 velocity=0 time=2\n",
      "note_off channel=0 note=86 velocity=0 time=0\n",
      "note_off channel=0 note=67 velocity=0 time=0\n",
      "note_on channel=0 note=81 velocity=64 time=0\n",
      "note_on channel=0 note=48 velocity=60 time=0\n",
      "note_on channel=0 note=72 velocity=72 time=0\n",
      "note_off channel=0 note=60 velocity=0 time=1\n",
      "note_off channel=0 note=56 velocity=0 time=1\n",
      "note_on channel=0 note=66 velocity=56 time=4\n",
      "note_on channel=0 note=54 velocity=68 time=0\n",
      "note_off channel=0 note=61 velocity=0 time=1\n",
      "note_off channel=0 note=67 velocity=0 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=1\n",
      "note_off channel=0 note=58 velocity=0 time=0\n",
      "note_off channel=0 note=46 velocity=0 time=0\n",
      "note_on channel=0 note=76 velocity=68 time=1\n",
      "note_on channel=0 note=69 velocity=44 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=76 velocity=52 time=0\n",
      "note_off channel=0 note=80 velocity=0 time=0\n",
      "note_off channel=0 note=75 velocity=0 time=0\n",
      "note_on channel=0 note=64 velocity=40 time=6\n",
      "note_off channel=0 note=73 velocity=0 time=1\n",
      "note_off channel=0 note=77 velocity=0 time=5\n",
      "note_off channel=0 note=71 velocity=0 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=76 velocity=68 time=1\n",
      "note_on channel=0 note=78 velocity=80 time=0\n",
      "note_off channel=0 note=46 velocity=0 time=0\n",
      "note_off channel=0 note=78 velocity=0 time=3\n",
      "note_on channel=0 note=80 velocity=72 time=0\n",
      "note_on channel=0 note=78 velocity=64 time=8\n",
      "note_off channel=0 note=48 velocity=0 time=0\n",
      "note_off channel=0 note=54 velocity=0 time=0\n",
      "note_off channel=0 note=66 velocity=0 time=0\n",
      "note_off channel=0 note=72 velocity=0 time=0\n",
      "note_off channel=0 note=80 velocity=0 time=0\n",
      "note_off channel=0 note=78 velocity=0 time=1\n",
      "note_on channel=0 note=77 velocity=72 time=2\n",
      "note_off channel=0 note=77 velocity=0 time=4\n",
      "note_off channel=0 note=69 velocity=0 time=0\n",
      "note_on channel=0 note=80 velocity=68 time=1\n",
      "note_off channel=0 note=59 velocity=0 time=4\n",
      "note_off channel=0 note=64 velocity=0 time=0\n",
      "control_change channel=0 control=64 value=0 time=7\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=57 velocity=56 time=3\n",
      "note_on channel=0 note=54 velocity=40 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=1\n",
      "note_off channel=0 note=81 velocity=0 time=0\n",
      "note_on channel=0 note=68 velocity=56 time=4\n",
      "note_on channel=0 note=69 velocity=56 time=0\n",
      "note_off channel=0 note=72 velocity=0 time=0\n",
      "note_off channel=0 note=68 velocity=0 time=0\n",
      "note_on channel=0 note=84 velocity=64 time=6\n",
      "note_on channel=0 note=83 velocity=52 time=0\n",
      "note_off channel=0 note=83 velocity=0 time=1\n",
      "note_off channel=0 note=84 velocity=0 time=0\n",
      "note_on channel=0 note=84 velocity=64 time=7\n",
      "note_off channel=0 note=80 velocity=0 time=0\n",
      "note_off channel=0 note=84 velocity=0 time=3\n",
      "note_on channel=0 note=83 velocity=80 time=2\n",
      "note_off channel=0 note=78 velocity=0 time=0\n",
      "note_on channel=0 note=70 velocity=64 time=2\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_off channel=0 note=58 velocity=0 time=2\n",
      "note_on channel=0 note=80 velocity=60 time=5\n",
      "note_off channel=0 note=54 velocity=0 time=0\n",
      "note_off channel=0 note=57 velocity=0 time=0\n",
      "note_on channel=0 note=85 velocity=60 time=5\n",
      "note_off channel=0 note=69 velocity=0 time=0\n",
      "note_off channel=0 note=80 velocity=0 time=0\n",
      "note_on channel=0 note=80 velocity=72 time=0\n",
      "note_off channel=0 note=80 velocity=0 time=4\n",
      "note_on channel=0 note=78 velocity=60 time=1\n",
      "note_off channel=0 note=63 velocity=0 time=6\n",
      "note_on channel=0 note=68 velocity=36 time=0\n",
      "note_off channel=0 note=68 velocity=0 time=2\n",
      "note_on channel=0 note=67 velocity=36 time=2\n",
      "note_off channel=0 note=67 velocity=0 time=2\n",
      "note_off channel=0 note=83 velocity=0 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_on channel=0 note=70 velocity=52 time=0\n",
      "note_off channel=0 note=72 velocity=0 time=3\n",
      "note_on channel=0 note=56 velocity=84 time=2\n",
      "note_off channel=0 note=56 velocity=0 time=2\n",
      "note_on channel=0 note=71 velocity=56 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_on channel=0 note=70 velocity=80 time=6\n",
      "note_off channel=0 note=85 velocity=0 time=0\n",
      "note_off channel=0 note=52 velocity=0 time=1\n",
      "note_off channel=0 note=59 velocity=0 time=1\n",
      "note_off channel=0 note=79 velocity=0 time=1\n",
      "note_on channel=0 note=68 velocity=72 time=0\n",
      "note_off channel=0 note=68 velocity=0 time=2\n",
      "note_off channel=0 note=78 velocity=0 time=0\n",
      "note_off channel=0 note=71 velocity=0 time=0\n",
      "note_on channel=0 note=71 velocity=68 time=0\n",
      "note_off channel=0 note=66 velocity=0 time=4\n",
      "note_on channel=0 note=77 velocity=76 time=3\n",
      "note_off channel=0 note=76 velocity=0 time=2\n",
      "note_off channel=0 note=59 velocity=0 time=3\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_on channel=0 note=70 velocity=84 time=2\n",
      "note_off channel=0 note=70 velocity=0 time=2\n",
      "note_on channel=0 note=73 velocity=68 time=3\n",
      "note_off channel=0 note=73 velocity=0 time=2\n",
      "control_change channel=0 control=64 value=0 time=7\n",
      "note_on channel=0 note=68 velocity=76 time=5\n",
      "note_off channel=0 note=71 velocity=0 time=0\n",
      "note_on channel=0 note=57 velocity=44 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=5\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=1\n",
      "note_on channel=0 note=81 velocity=68 time=3\n",
      "note_off channel=0 note=64 velocity=0 time=1\n",
      "note_on channel=0 note=76 velocity=84 time=2\n",
      "note_on channel=0 note=66 velocity=60 time=0\n",
      "note_on channel=0 note=82 velocity=68 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=1\n",
      "note_off channel=0 note=84 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=80 time=6\n",
      "note_off channel=0 note=65 velocity=0 time=1\n",
      "note_on channel=0 note=41 velocity=92 time=4\n",
      "note_on channel=0 note=35 velocity=72 time=0\n",
      "note_on channel=0 note=45 velocity=60 time=1\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_off channel=0 note=62 velocity=0 time=4\n",
      "note_off channel=0 note=57 velocity=0 time=0\n",
      "note_off channel=0 note=68 velocity=0 time=0\n",
      "control_change channel=0 control=64 value=0 time=1\n",
      "note_off channel=0 note=76 velocity=0 time=3\n",
      "note_on channel=0 note=67 velocity=20 time=2\n",
      "note_on channel=0 note=65 velocity=44 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=0\n",
      "note_on channel=0 note=71 velocity=80 time=3\n",
      "note_on channel=0 note=63 velocity=64 time=0\n",
      "note_off channel=0 note=67 velocity=0 time=1\n",
      "note_off channel=0 note=72 velocity=0 time=1\n",
      "note_off channel=0 note=66 velocity=0 time=0\n",
      "note_on channel=0 note=57 velocity=64 time=1\n",
      "note_on channel=0 note=75 velocity=68 time=0\n",
      "note_off channel=0 note=57 velocity=0 time=1\n",
      "note_off channel=0 note=66 velocity=0 time=0\n",
      "note_off channel=0 note=75 velocity=0 time=1\n",
      "note_on channel=0 note=64 velocity=52 time=16\n",
      "note_off channel=0 note=35 velocity=0 time=0\n",
      "note_off channel=0 note=41 velocity=0 time=0\n",
      "note_off channel=0 note=45 velocity=0 time=0\n",
      "note_on channel=0 note=54 velocity=44 time=0\n",
      "note_off channel=0 note=71 velocity=0 time=0\n",
      "note_on channel=0 note=71 velocity=68 time=2\n",
      "note_off channel=0 note=71 velocity=0 time=1\n",
      "control_change channel=0 control=64 value=127 time=0\n",
      "note_off channel=0 note=71 velocity=0 time=0\n",
      "note_on channel=0 note=68 velocity=60 time=1\n",
      "note_off channel=0 note=68 velocity=0 time=1\n",
      "note_off channel=0 note=65 velocity=0 time=0\n",
      "note_on channel=0 note=65 velocity=52 time=1\n",
      "note_off channel=0 note=61 velocity=0 time=0\n",
      "note_on channel=0 note=71 velocity=56 time=0\n",
      "note_on channel=0 note=61 velocity=20 time=1\n",
      "note_off channel=0 note=63 velocity=0 time=0\n",
      "note_off channel=0 note=64 velocity=0 time=0\n",
      "note_on channel=0 note=64 velocity=32 time=2\n",
      "note_off channel=0 note=65 velocity=0 time=0\n",
      "note_on channel=0 note=65 velocity=36 time=0\n",
      "note_off channel=0 note=65 velocity=0 time=1\n",
      "note_off channel=0 note=65 velocity=0 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=1\n",
      "note_off channel=0 note=65 velocity=0 time=2\n",
      "note_on channel=0 note=58 velocity=84 time=1\n",
      "note_off channel=0 note=58 velocity=0 time=1\n",
      "note_on channel=0 note=63 velocity=88 time=1\n",
      "note_off channel=0 note=63 velocity=0 time=3\n",
      "note_on channel=0 note=67 velocity=44 time=1\n",
      "note_off channel=0 note=79 velocity=0 time=2\n",
      "note_on channel=0 note=68 velocity=68 time=0\n",
      "control_change channel=0 control=64 value=127 time=4\n",
      "note_off channel=0 note=54 velocity=0 time=0\n",
      "note_on channel=0 note=74 velocity=60 time=6\n",
      "note_off channel=0 note=57 velocity=0 time=0\n",
      "note_off channel=0 note=74 velocity=0 time=4\n",
      "note_off channel=0 note=61 velocity=0 time=0\n",
      "note_off channel=0 note=71 velocity=0 time=0\n",
      "note_on channel=0 note=78 velocity=64 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=1\n",
      "note_off channel=0 note=64 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=80 time=0\n",
      "note_on channel=0 note=63 velocity=36 time=1\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_off channel=0 note=75 velocity=0 time=1\n",
      "note_off channel=0 note=67 velocity=0 time=1\n",
      "control_change channel=0 control=64 value=127 time=0\n",
      "note_on channel=0 note=62 velocity=52 time=0\n",
      "note_off channel=0 note=65 velocity=0 time=2\n",
      "note_off channel=0 note=74 velocity=0 time=1\n",
      "note_on channel=0 note=75 velocity=64 time=1\n",
      "note_off channel=0 note=78 velocity=0 time=0\n",
      "note_on channel=0 note=78 velocity=56 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=66 velocity=48 time=1\n",
      "note_on channel=0 note=80 velocity=80 time=3\n",
      "note_off channel=0 note=80 velocity=0 time=1\n",
      "note_off channel=0 note=68 velocity=0 time=0\n",
      "note_off channel=0 note=75 velocity=0 time=0\n",
      "note_off channel=0 note=78 velocity=0 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=1\n",
      "note_on channel=0 note=87 velocity=68 time=3\n",
      "note_off channel=0 note=58 velocity=0 time=1\n",
      "note_off channel=0 note=92 velocity=0 time=1\n",
      "note_on channel=0 note=65 velocity=48 time=2\n",
      "note_on channel=0 note=88 velocity=64 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=52 time=1\n",
      "note_on channel=0 note=86 velocity=56 time=0\n",
      "note_on channel=0 note=72 velocity=52 time=5\n",
      "note_off channel=0 note=86 velocity=0 time=1\n",
      "note_off channel=0 note=63 velocity=0 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=1\n",
      "note_off channel=0 note=86 velocity=0 time=1\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_on channel=0 note=86 velocity=80 time=1\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=48 time=1\n",
      "note_off channel=0 note=87 velocity=0 time=2\n",
      "note_off channel=0 note=88 velocity=0 time=0\n",
      "note_on channel=0 note=88 velocity=68 time=1\n",
      "note_on channel=0 note=55 velocity=32 time=2\n",
      "note_off channel=0 note=66 velocity=0 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=1\n",
      "note_off channel=0 note=79 velocity=0 time=1\n",
      "note_off channel=0 note=86 velocity=0 time=0\n",
      "note_on channel=0 note=84 velocity=76 time=0\n",
      "note_on channel=0 note=80 velocity=88 time=2\n",
      "note_off channel=0 note=80 velocity=0 time=3\n",
      "note_on channel=0 note=45 velocity=80 time=2\n",
      "note_off channel=0 note=40 velocity=0 time=1\n",
      "note_off channel=0 note=67 velocity=0 time=2\n",
      "note_off channel=0 note=65 velocity=0 time=0\n",
      "note_on channel=0 note=54 velocity=64 time=0\n",
      "note_off channel=0 note=57 velocity=0 time=2\n",
      "note_off channel=0 note=83 velocity=0 time=1\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=48 time=2\n",
      "note_off channel=0 note=72 velocity=0 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=1\n",
      "note_on channel=0 note=74 velocity=60 time=2\n",
      "note_off channel=0 note=62 velocity=0 time=1\n",
      "note_on channel=0 note=70 velocity=64 time=13\n",
      "note_off channel=0 note=55 velocity=0 time=0\n",
      "note_off channel=0 note=84 velocity=0 time=0\n",
      "note_off channel=0 note=88 velocity=0 time=0\n",
      "note_off channel=0 note=56 velocity=0 time=1\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_on channel=0 note=74 velocity=84 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=1\n",
      "note_off channel=0 note=72 velocity=0 time=1\n",
      "note_on channel=0 note=61 velocity=64 time=1\n",
      "note_off channel=0 note=45 velocity=0 time=0\n",
      "note_on channel=0 note=80 velocity=72 time=0\n",
      "note_on channel=0 note=65 velocity=32 time=0\n",
      "note_off channel=0 note=75 velocity=0 time=0\n",
      "note_off channel=0 note=80 velocity=0 time=0\n",
      "note_on channel=0 note=80 velocity=84 time=0\n",
      "control_change channel=0 control=64 value=0 time=1\n",
      "control_change channel=0 control=64 value=127 time=19\n",
      "note_off channel=0 note=54 velocity=0 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=1\n",
      "note_off channel=0 note=65 velocity=0 time=0\n",
      "note_on channel=0 note=65 velocity=44 time=0\n",
      "note_on channel=0 note=83 velocity=72 time=1\n",
      "note_on channel=0 note=79 velocity=44 time=9\n",
      "note_off channel=0 note=61 velocity=0 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_off channel=0 note=80 velocity=0 time=0\n",
      "note_on channel=0 note=76 velocity=76 time=0\n",
      "note_on channel=0 note=62 velocity=76 time=0\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_on channel=0 note=62 velocity=56 time=0\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_on channel=0 note=62 velocity=48 time=12\n",
      "note_off channel=0 note=62 velocity=0 time=2\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=66 velocity=36 time=6\n",
      "note_off channel=0 note=65 velocity=0 time=0\n",
      "note_off channel=0 note=83 velocity=0 time=0\n",
      "note_off channel=0 note=66 velocity=0 time=2\n",
      "note_on channel=0 note=78 velocity=72 time=4\n",
      "note_off channel=0 note=75 velocity=0 time=1\n",
      "note_off channel=0 note=76 velocity=0 time=0\n",
      "note_on channel=0 note=76 velocity=56 time=1\n",
      "note_off channel=0 note=79 velocity=0 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=3\n",
      "note_on channel=0 note=48 velocity=64 time=5\n",
      "note_off channel=0 note=49 velocity=0 time=1\n",
      "note_on channel=0 note=61 velocity=60 time=11\n",
      "note_on channel=0 note=77 velocity=52 time=0\n",
      "note_on channel=0 note=64 velocity=52 time=0\n",
      "note_on channel=0 note=81 velocity=80 time=0\n",
      "note_on channel=0 note=73 velocity=56 time=0\n",
      "note_off channel=0 note=61 velocity=0 time=3\n",
      "note_on channel=0 note=58 velocity=44 time=2\n",
      "note_off channel=0 note=56 velocity=0 time=3\n",
      "note_off channel=0 note=78 velocity=0 time=0\n",
      "note_off channel=0 note=60 velocity=0 time=2\n",
      "note_on channel=0 note=50 velocity=52 time=2\n",
      "note_off channel=0 note=50 velocity=0 time=2\n",
      "note_on channel=0 note=62 velocity=24 time=8\n",
      "note_off channel=0 note=48 velocity=0 time=0\n",
      "note_off channel=0 note=64 velocity=0 time=3\n",
      "control_change channel=0 control=64 value=127 time=4\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_on channel=0 note=62 velocity=40 time=1\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=45 velocity=40 time=0\n",
      "note_off channel=0 note=73 velocity=0 time=0\n",
      "note_off channel=0 note=81 velocity=0 time=0\n",
      "note_off channel=0 note=45 velocity=0 time=5\n",
      "note_off channel=0 note=71 velocity=0 time=7\n",
      "note_off channel=0 note=58 velocity=0 time=0\n",
      "note_off channel=0 note=38 velocity=0 time=0\n",
      "note_off channel=0 note=49 velocity=0 time=6\n",
      "note_off channel=0 note=70 velocity=0 time=5\n",
      "note_off channel=0 note=64 velocity=0 time=7\n",
      "note_on channel=0 note=81 velocity=52 time=2\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_on channel=0 note=63 velocity=40 time=1\n",
      "note_on channel=0 note=57 velocity=72 time=6\n",
      "note_off channel=0 note=74 velocity=0 time=3\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=67 velocity=56 time=4\n",
      "note_on channel=0 note=66 velocity=24 time=11\n",
      "note_off channel=0 note=79 velocity=0 time=0\n",
      "note_off channel=0 note=54 velocity=0 time=1\n",
      "note_on channel=0 note=62 velocity=28 time=1\n",
      "note_off channel=0 note=62 velocity=0 time=4\n",
      "note_off channel=0 note=81 velocity=0 time=0\n",
      "note_on channel=0 note=82 velocity=56 time=3\n",
      "note_off channel=0 note=63 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=52 time=1\n",
      "note_on channel=0 note=52 velocity=24 time=0\n",
      "note_off channel=0 note=65 velocity=0 time=6\n",
      "note_off channel=0 note=57 velocity=0 time=0\n",
      "note_off channel=0 note=74 velocity=0 time=1\n",
      "note_off channel=0 note=64 velocity=0 time=1\n",
      "note_off channel=0 note=70 velocity=0 time=1\n",
      "note_off channel=0 note=53 velocity=0 time=10\n",
      "note_off channel=0 note=67 velocity=0 time=0\n",
      "note_on channel=0 note=78 velocity=48 time=6\n",
      "note_off channel=0 note=66 velocity=0 time=0\n",
      "note_off channel=0 note=63 velocity=0 time=1\n",
      "note_on channel=0 note=59 velocity=64 time=11\n",
      "note_off channel=0 note=52 velocity=0 time=0\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_off channel=0 note=82 velocity=0 time=0\n",
      "note_off channel=0 note=66 velocity=0 time=1\n",
      "note_on channel=0 note=74 velocity=52 time=6\n",
      "note_on channel=0 note=76 velocity=80 time=2\n",
      "note_on channel=0 note=72 velocity=68 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=2\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=64 velocity=44 time=8\n",
      "note_off channel=0 note=78 velocity=0 time=0\n",
      "note_off channel=0 note=64 velocity=0 time=3\n",
      "note_on channel=0 note=60 velocity=44 time=1\n",
      "note_off channel=0 note=60 velocity=0 time=3\n",
      "note_on channel=0 note=52 velocity=56 time=5\n",
      "note_off channel=0 note=59 velocity=0 time=0\n",
      "note_off channel=0 note=49 velocity=0 time=4\n",
      "note_on channel=0 note=70 velocity=80 time=0\n",
      "note_on channel=0 note=69 velocity=44 time=0\n",
      "note_off channel=0 note=69 velocity=0 time=3\n",
      "note_off channel=0 note=74 velocity=0 time=0\n",
      "note_off channel=0 note=66 velocity=0 time=1\n",
      "note_on channel=0 note=77 velocity=72 time=4\n",
      "note_off channel=0 note=72 velocity=0 time=0\n",
      "note_on channel=0 note=62 velocity=92 time=0\n",
      "note_off channel=0 note=79 velocity=0 time=1\n",
      "note_on channel=0 note=72 velocity=76 time=2\n",
      "note_on channel=0 note=59 velocity=48 time=1\n",
      "note_off channel=0 note=71 velocity=0 time=7\n",
      "note_off channel=0 note=64 velocity=0 time=1\n",
      "note_on channel=0 note=74 velocity=76 time=1\n",
      "note_off channel=0 note=77 velocity=0 time=0\n",
      "note_on channel=0 note=77 velocity=64 time=21\n",
      "note_off channel=0 note=52 velocity=0 time=0\n",
      "note_off channel=0 note=62 velocity=0 time=0\n",
      "note_off channel=0 note=70 velocity=0 time=0\n",
      "note_off channel=0 note=76 velocity=0 time=1\n",
      "note_off channel=0 note=72 velocity=0 time=0\n",
      "note_on channel=0 note=68 velocity=40 time=9\n",
      "note_off channel=0 note=59 velocity=0 time=0\n",
      "note_off channel=0 note=68 velocity=0 time=0\n",
      "note_on channel=0 note=68 velocity=56 time=0\n",
      "<meta message end_of_track time=0>\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 이벤트를 바탕으로 midi파일 만들기\n",
    "from mido import Message, MidiFile, MidiTrack, MetaMessage, bpm2tempo\n",
    "\n",
    "midi = MidiFile()\n",
    "output_midi_path = os.getenv('HOME')+'/aiffel/music_transformer/data/output_file1_1F2N.mid'\n",
    "\n",
    "# Instantiate a MIDI Track (contains a list of MIDI events)\n",
    "track = MidiTrack()\n",
    "track.append(MetaMessage(\"set_tempo\", tempo=bpm2tempo(120)))\n",
    "# Append the track to the pattern\n",
    "midi.tracks.append(track)\n",
    "\n",
    "prev_time = 0\n",
    "pitches = [None for _ in range(128)]\n",
    "for event in event_list:\n",
    "    tick = (event.time - prev_time) // 3\n",
    "    midi.ticks_per_beat = 8\n",
    "    prev_time = event.time\n",
    "\n",
    "    # case NOTE:\n",
    "    if not event.cc:\n",
    "        if event.on:\n",
    "            if pitches[event.note] is not None:\n",
    "                # Instantiate a MIDI note off event, append it to the track\n",
    "                off = Message('note_off', note=event.note, velocity=0, time=0)\n",
    "                track.append(off)\n",
    "                pitches[event.note] = None\n",
    "\n",
    "            # Instantiate a MIDI note on event, append it to the track\n",
    "            on = Message('note_on', note=event.note, velocity=int(event.velocity), time=tick)\n",
    "            track.append(on)\n",
    "            pitches[event.note] = prev_time\n",
    "        else:\n",
    "            # Instantiate a MIDI note off event, append it to the track\n",
    "            off = Message('note_off', note=event.note, velocity=0, time=tick)\n",
    "            track.append(off)\n",
    "            pitches[event.note] = None\n",
    "\n",
    "#     case CC:\n",
    "    elif event.cc:\n",
    "        if event.on:\n",
    "            cc = Message('control_change', control=64, time=tick, value=127)\n",
    "        else:\n",
    "            cc = Message('control_change', control=64, time=tick, value=0)\n",
    "\n",
    "        track.append(cc)\n",
    "\n",
    "    for pitch in range(128):\n",
    "        if pitches[pitch] is not None and pitches[pitch] + 100 < prev_time:\n",
    "            off = Message('note_off', note=pitch, velocity=0, time=0)\n",
    "            track.append(off)\n",
    "            pitches[pitch] = None\n",
    "\n",
    "\n",
    "# Add the end of track event, append it to the track\n",
    "track.append(MetaMessage(\"end_of_track\"))\n",
    "\n",
    "# Save the pattern to disk\n",
    "midi.save(output_midi_path)\n",
    "\n",
    "for i, track in enumerate(midi.tracks):\n",
    "    print('Track {}: {}'.format(i, track.name))\n",
    "    for msg in track:\n",
    "        print(msg)\n",
    "\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
