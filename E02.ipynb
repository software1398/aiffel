{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target Name 확인하기\n",
      "[0 1 2 3 4 5 6 7 8 9] \n",
      "\n",
      "데이터 Describe\n",
      "\n",
      "Dicision Tree 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n",
      "\n",
      "Random Forest 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n",
      "\n",
      "SVM 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "\n",
      "SGD Classifier 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.82      0.95      0.88        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.97      0.88      0.92        34\n",
      "           4       0.97      0.97      0.97        37\n",
      "           5       0.82      1.00      0.90        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.91      0.97      0.94        33\n",
      "           8       0.97      0.70      0.81        43\n",
      "           9       0.91      0.91      0.91        32\n",
      "\n",
      "    accuracy                           0.93       360\n",
      "   macro avg       0.93      0.93      0.93       360\n",
      "weighted avg       0.93      0.93      0.93       360\n",
      "\n",
      "\n",
      "Logistic Regression(로지스틱 회귀) 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.84      0.88        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.96      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "print(\"target Name 확인하기\")\n",
    "print(digits.target_names, \"\\n\")\n",
    "\n",
    "# 데이터 Describe\n",
    "print(\"데이터 Describe\")\n",
    "#print(digits.DESCR)\n",
    "\n",
    "#digits_df = pd.DataFrame(data = digits_data, columns = digits.feature_names)\n",
    "\n",
    "# train과 test 분류하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                   digits_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print()\n",
    "print(\"Dicision Tree 모델\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Random Forest 모델\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"SVM 모델\")\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"SGD Classifier 모델\")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Logistic Regression(로지스틱 회귀) 모델\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨의 분류는 SMV모델이 99%이상의 정확도를 보이고 있으며,   \n",
    "target이 균형이 있게 분포되어 있므로 accuracy 지표를 사용해도 무방하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target Name 확인하기\n",
      "['class_0' 'class_1' 'class_2'] \n",
      "\n",
      "데이터 Describe\n",
      "\n",
      "Dicision Tree 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.83      0.91        12\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.96      0.94      0.95        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n",
      "\n",
      "Random Forest 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        17\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "\n",
      "SVM 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86         7\n",
      "           1       0.58      0.88      0.70        17\n",
      "           2       0.33      0.08      0.13        12\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.59      0.61      0.56        36\n",
      "weighted avg       0.55      0.61      0.54        36\n",
      "\n",
      "\n",
      "SGD Classifier 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.91      0.59      0.71        17\n",
      "           2       0.65      0.92      0.76        12\n",
      "\n",
      "    accuracy                           0.78        36\n",
      "   macro avg       0.81      0.83      0.80        36\n",
      "weighted avg       0.82      0.78      0.77        36\n",
      "\n",
      "\n",
      "Logistic Regression(로지스틱 회귀) 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.97      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "print(\"target Name 확인하기\")\n",
    "print(wine.target_names, \"\\n\")\n",
    "\n",
    "# 데이터 Describe\n",
    "print(\"데이터 Describe\")\n",
    "#print(wine.DESCR)\n",
    "\n",
    "#digits_df = pd.DataFrame(data = wine_data, columns = wine.feature_names)\n",
    "\n",
    "# train과 test 분류하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data,\n",
    "                                                   wine_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print()\n",
    "print(\"Dicision Tree 모델\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Random Forest 모델\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"SVM 모델\")\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"SGD Classifier 모델\")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Logistic Regression(로지스틱 회귀) 모델\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와인 분류는 Random forest모델이 100%의 정확도를 보이고 있으며,   \n",
    "feature가 많은 경우 Dicision Tree모델보다 정확도가 좀 더 상승하였다.\n",
    "와인의 종류를 정확히 분류해야 하기 때문에 precision이 더 중요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target Name 확인하기\n",
      "['malignant' 'benign'] \n",
      "\n",
      "(569, 30)\n",
      "데이터 Describe\n",
      "\n",
      "Dicision Tree 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.82      0.87        40\n",
      "           1       0.91      0.96      0.93        74\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.91      0.89      0.90       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "\n",
      "Random Forest 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        40\n",
      "           1       1.00      1.00      1.00        74\n",
      "\n",
      "    accuracy                           1.00       114\n",
      "   macro avg       1.00      1.00      1.00       114\n",
      "weighted avg       1.00      1.00      1.00       114\n",
      "\n",
      "\n",
      "SVM 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.72      0.84        40\n",
      "           1       0.87      1.00      0.93        74\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.94      0.86      0.89       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "\n",
      "SGD Classifier 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        40\n",
      "           1       0.86      1.00      0.92        74\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.93      0.85      0.87       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "\n",
      "Logistic Regression(로지스틱 회귀) 모델\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        40\n",
      "           1       0.93      1.00      0.96        74\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.96      0.93      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "breast_cancer_data = breast_cancer.data\n",
    "breast_cancer_label = breast_cancer.target\n",
    "print(\"target Name 확인하기\")\n",
    "print(breast_cancer.target_names, \"\\n\")\n",
    "# print(breast_cancer_data.shape)\n",
    "# 데이터 Describe\n",
    "print(\"데이터 Describe\")\n",
    "#print(breast_cancer.DESCR)\n",
    "\n",
    "#digits_df = pd.DataFrame(data = breast_cancer_data, columns = breast_cancer.feature_names)\n",
    "\n",
    "# train과 test 분류하기\n",
    "X_train, X_test, y_train, y_test = train_test_split(breast_cancer_data,\n",
    "                                                   breast_cancer_label,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=7)\n",
    "\n",
    "print()\n",
    "print(\"Dicision Tree 모델\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Random Forest 모델\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred = random_forest.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"SVM 모델\")\n",
    "from sklearn import svm\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"SGD Classifier 모델\")\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print()\n",
    "print(\"Logistic Regression(로지스틱 회귀) 모델\")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic_model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "유방암 여부를 판별하는 경우는 Random forest모델이 100%의 정확도를 보였으며,   \n",
    "feature가 많은 데이터여서 다양한 특징을 조합한 랜덤포레스트가 높은 성능을 보인다.   \n",
    "암환자 판별의 경우는 실제 환자(양)을 정확히 예측해야 하므로 recall지표를 주의깊게   \n",
    "봐야한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
