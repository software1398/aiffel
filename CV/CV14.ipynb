{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CV14 - 카메라 스티커앱을 개선하자\n",
    "### 프로젝트 1. moviepy로 비디오 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoClip, VideoFileClip\n",
    "from moviepy.editor import ipython_display\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### moviepy를 이용하여 주피터 노트북에서 비디오를 읽고 쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/404 [00:00<?, ?it/s, now=None]                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4.\n",
      "MoviePy - Writing audio in mvpyresultTEMP_MPY_wvf_snd.mp3\n",
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n"
     ]
    }
   ],
   "source": [
    "# 읽기\n",
    "video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/video2.mp4'\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "clip.ipython_display(fps=30, loop=True, autoplay=True, rd_kwargs=dict(logger=None))\n",
    "\n",
    "# 쓰기\n",
    "result_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult.mp4'\n",
    "clip.write_videofile(result_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### moviepy로 읽은 동영상을 numpy로 변환하여 영상밝기를 50% 어둡게 만든 후 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  17%|█▋        | 67/403 [00:00<00:00, 662.61it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult2.mp4.\n",
      "Moviepy - Writing video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult2.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# 읽기\n",
    "video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/video2.mp4'\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "clip.ipython_display(fps=30, loop=True, autoplay=True, rd_kwargs=dict(logger=None))\n",
    "\n",
    "# clip 에서 numpy 로 데이터 추출\n",
    "vlen = int(clip.duration*clip.fps)\n",
    "video_container = np.zeros((vlen, clip.size[1], clip.size[0], 3), dtype=np.uint8)\n",
    "for i in range(vlen):\n",
    "    img = clip.get_frame(i/clip.fps)\n",
    "    video_container[i] = (img * 0.5).astype(np.uint8)\n",
    "\n",
    "# 새 clip 만들기\n",
    "dur = vlen / clip.fps\n",
    "outclip = VideoClip(lambda t: video_container[int(round(t*clip.fps))], duration=dur)\n",
    "\n",
    "# 쓰기\n",
    "result_video_path2 = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult2.mp4'\n",
    "outclip.write_videofile(result_video_path2, fps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### moivepy와 OpenCV를 사용할 때 영상을 읽고 쓰는 시간을 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  16%|█▋        | 66/403 [00:00<00:00, 656.01it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4.\n",
      "Moviepy - Writing video /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/aiffel0042/aiffel/video_sticker_app/images/mvpyresult.mp4\n",
      "[INFO] moviepy time : 2.60ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# CASE 1 : moviepy 사용\n",
    "start = cv2.getTickCount()\n",
    "clip = VideoFileClip(video_path)\n",
    "clip = clip.resize(width=640)\n",
    "\n",
    "vlen = int(clip.duration*clip.fps)\n",
    "video_container = np.zeros((vlen, clip.size[1], clip.size[0], 3), dtype=np.uint8)\n",
    "\n",
    "for i in range(vlen):\n",
    "    img = clip.get_frame(i/clip.fps)\n",
    "    video_container[i] = (img * 0.5).astype(np.uint8)\n",
    "\n",
    "dur = vlen / clip.fps\n",
    "outclip = VideoClip(lambda t: video_container[int(round(t*clip.fps))], duration=dur)\n",
    "\n",
    "mvpy_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/mvpyresult.mp4'\n",
    "outclip.write_videofile(mvpy_video_path, fps=30)\n",
    "\n",
    "time = (cv2.getTickCount() - start) / cv2.getTickFrequency()\n",
    "print (f'[INFO] moviepy time : {time:.2f}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] cv time : 1.23ms\n"
     ]
    }
   ],
   "source": [
    "# CASE 2 : OpenCV 사용\n",
    "start = cv2.getTickCount()\n",
    "vc = cv2.VideoCapture(video_path)\n",
    "\n",
    "cv_video_path = os.getenv('HOME')+'/aiffel/video_sticker_app/images/cvresult.mp4'\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "vw = cv2.VideoWriter(cv_video_path, fourcc, 30, (640,360))\n",
    "\n",
    "vlen = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "for i in range(vlen):\n",
    "    ret, img = vc.read()\n",
    "    if ret == False: break\n",
    "    \n",
    "    img_result = cv2.resize(img, (640, 360)) * 0.5\n",
    "    vw.write(img_result.astype(np.uint8))\n",
    "    \n",
    "time = (cv2.getTickCount() - start) / cv2.getTickFrequency()\n",
    "print (f'[INFO] cv time : {time:.2f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "openCV가 moivepy보다 처리 속도가 빠르다.\n",
    "### 프로젝트 2. 어디까지 만들고 싶은지 정의하기\n",
    "#### 웹캠을 이용한 실시간 스티커앱 만들기\n",
    "addsticker.py에서 img2sticker_orig 메소드를 복사하여 새로운 newaddsticker.py에 img2sticker라는 이름으로 저장한다.  \n",
    "webcam_sticker.py라는 파일에 다음 코드를 입력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "\n",
    "from newaddsticker import img2sticker\n",
    "\n",
    "detector_hog = dlib.get_frontal_face_detector()\n",
    "landmark_predictor = dlib.shape_predictor('./models/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "def main():\n",
    "    cv2.namedWindow('show', 0)\n",
    "    cv2.resizeWindow('show', 640, 360)\n",
    "\n",
    "    vc = cv2.VideoCapture(0)\n",
    "    img_sticker = cv2.imread('./images/king.png')\n",
    "\n",
    "    vlen = int(vc.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print (vlen) # 웹캠은 video length 가 0 입니다.\n",
    "\n",
    "    # 정해진 길이가 없기 때문에 while 을 주로 사용합니다.\n",
    "    # for i in range(vlen):\n",
    "    while True:\n",
    "        ret, img = vc.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "        start = cv2.getTickCount()\n",
    "        img = cv2.flip(img, 1)  # 보통 웹캠은 좌우 반전\n",
    "\n",
    "        # 스티커 메소드를 사용\n",
    "        img_result = img2sticker(img, img_sticker.copy(), detector_hog, landmark_predictor)   \n",
    "\n",
    "        time = (cv2.getTickCount() - start) / cv2.getTickFrequency() * 1000\n",
    "        print ('[INFO] time: %.2fms'%time)\n",
    "\n",
    "        cv2.imshow('show', img_result)\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 얼굴을 인식하지 못하는 거리가 있다.\n",
    "일반적으로 15cm ~ 130cm 사이의 거리에서 얼굴 인식이 된다고 한다.  \n",
    "#### 고개를 상하좌우로 움직여서 몇 도까지 정상적으로 작동하는지 확인\n",
    "yaw, pitch, roll각도\n",
    "#### 스티커앱의 스펙(허용 거리, 허용 인원 수, 허용 각도, 안정성) 정하기\n",
    "### 프로젝트 3. 스티커 Out Bound 예외처리 하기\n",
    "#### 좌우 경계 밖으로 나가는 경우 예외 상황 발생\n",
    "#### 코드을 확인하여 수정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_x = x - w // 2\n",
    "refined_y = y - h\n",
    "\n",
    "if refined_y < 0:\n",
    "    img_sticker = img_sticker[-refined_y:]\n",
    "    refined_y = 0\n",
    "\n",
    "###\n",
    "# TODO : x 축 예외처리 코드 추가\n",
    "###\n",
    "if refined_x < 0:\n",
    "    img_sticker = img_sticker[:, -refined_x:]\n",
    "    refined_x = 0\n",
    "elif refined_x + img_sticker.shape[1] >= img_orig.shape[1]:\n",
    "    img_sticker = img_sticker[:, :-(img_sticker.shape[1]+refined_x-img_orig.shape[1])]\n",
    "\n",
    "img_bgr = img_orig.copy()\n",
    "sticker_area = img_bgr[refined_y:refined_y+img_sticker.shape[0], refined_x:refined_x+img_sticker.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 다른 예외 상황 정의하기\n",
    "예) 고개를 왼쪽아래로 향하게 할 때 스티커 모양이 일정한 것\n",
    "### 프로젝트 4. 스티커앱 분석 - 거리, 인원 수, 각도, 시계열 안정성\n",
    "#### 멀어지는 경우에 스티커앱이 작동하지 않는 이유는 뭘까?\n",
    "detection이 안 되기 때문에, detector_hog단계에서  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "# detector\n",
    "img_rgb_vga = cv2.resize(img_rgb, (640, 360))\n",
    "dlib_rects = detector_hog(img_rgb_vga, 0)\n",
    "if len(dlib_rects) < 1:\n",
    "    return img_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### detection 문제 해결하기 위해 img2sticker 메소드 코드를 간단히 수정하기\n",
    "이미지 피라미드를 조절하여 성능 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2sticker(img_orig, img_sticker, detector_hog, landmark_predictor):\n",
    "    # preprocess\n",
    "    img_rgb = cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # detector\n",
    "    img_rgb_vga = cv2.resize(img_rgb, (640, 360))\n",
    "    dlib_rects = detector_hog(img_rgb_vga, 1) # <- 이미지 피라미드 수 변경\n",
    "    if len(dlib_rects) < 1:\n",
    "        return img_orig\n",
    "\n",
    "    # landmark\n",
    "    list_landmarks = []\n",
    "    for dlib_rect in dlib_rects:\n",
    "        points = landmark_predictor(img_rgb_vga, dlib_rect)\n",
    "        list_points = list(map(lambda p: (p.x, p.y), points.parts()))\n",
    "        list_landmarks.append(list_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 코드 수정 후 실행 속도가 현저히 느리진다. 30ms -> 90ms\n",
    "실시간 구동이 거의 불가능하다.  \n",
    "#### 실행시간을 줄이는 방법을 찾아보자\n",
    "hog detector를 deeplearning 기반 detector로 변경 가능  \n",
    "https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/  \n",
    "opencv는 intel cpu을 사용 시 dnn모듈이 가속화 지원"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
