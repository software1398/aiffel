{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E18 - 뉴스 요약봇 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 텍스트 요약\n",
    "\n",
    "긴 길이의 문서에서 핵심 내용만 간추려서 요약한 문장으로 변환하는 것   \n",
    "요약시 정보의 손실이 최소화되어야 한다   \n",
    "추출적 요약과 추상적 요약으로 접근할 수 있다.   \n",
    "\n",
    "###### 추출적 요약\n",
    "원문에서 문장들을 추출하여 요약하는 방식.   \n",
    "문장 중에서 요약문에 들어갈 핵심문장을 구별한다는 의미에서 문장 분류(text classification)의 문제라고 볼 수도 있다.   \n",
    "10개의 문장이 있을 경우 3개의 문장을 추출하여 요약문을 만든다고 볼 수 있으며 연결된 3개의 문장이 자연스럽지 않을 수 있다.   \n",
    "https://www.aclweb.org/anthology/W04-3252.pdf   \n",
    "전통적인 머신 러닝 방식에 속하는 텍스트랭크라는 알고리즘을 사용한다.\n",
    "대표적인 예로 네이버 뉴스 서비스에 있는 요약봇 기능이다.   \n",
    "\n",
    "###### 추상적 요약\n",
    "원문으로부터 요약된 새로운 문장을 생성하는 방식.   \n",
    "자연어 생성(Netural language generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 텍스트 요약 훈련하기\n",
    "seq2seq   \n",
    "두 개의 RNN을 사용하여 입력 시퀀스로부터 출력 시퀀스를 생성하는 자연어 생성 모델.   \n",
    "첫번째 RNN, 인코더을 통해 하나의 고정된 벡터로 변환, 문맥 정보을 가진 벡터, context vector   \n",
    "두번째 RNN, 디코더는 context vector을 전달받아 단어를 하나씩 생성하여 요약 문장을 만들어낸다.   \n",
    "\n",
    "이번에서 RNN이 아니라 LSTM를 사용한다.    \n",
    "LSTM의 특징은 다음 time step의 셀에 hidden state와 cell state도 같이 전달하는 점이다.   \n",
    "\n",
    "시작 토큰과 종료 토큰이 필요하다. 전처리를 해야 한다.   \n",
    "\n",
    "새로운 매커니즘, 어텐션 매커니즘 이용   \n",
    "마지막 time step의 hidden state는 전달한 context vector로서 이미 입력 시퀀스의 정보가 많이 소실된 상태다.   \n",
    "어텐션은 인코더의 모든 단계의 hidden state의 정보를 context vector에 반영한다.    \n",
    "하지만 모든 hidden state가 동일한 비중으로 반영되지 않고   \n",
    "현재 디코더의 time step을 예측할 때 인코더의 각 step이 얼마나 영향을 미치는지에 따른 가중합으로 계산한다.   \n",
    "예) 0.2h1+0.3h2+0.1h3+0.15h4+0.25h5   \n",
    "그래서 디코더의 각 step마다 그 가중치의 합은 달라진다.   \n",
    "의문) 인코더가 진행되면서 각 단계의 context vector는 매번 바뀌나?  \n",
    "\n",
    "1. seq2seq를 사용\n",
    "2. LSTM을 사용, hidden state와 cell state도 사용\n",
    "3. 디코더의 예측 시퀀스 앞뒤로 토큰 추가 sos, eos\n",
    "4. seq2seq을 실행하면 디코더는 시작 토큰을 입력받아서 예측을 시작\n",
    "5. seq2seq 기본 모델이 아니라 어텐션 매커니즘 사용하여 인코더의 hidden state의 중요도에 따라 context vector 계산\n",
    "6. 계산된 context vector을 이용하여 다음 단어을 예측한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 데이터 준비하기\n",
    "캐글에서 제공된 아마존 리뷰 데이터셋 사용   \n",
    "https://www.kaggle.com/snap/amazon-fine-food-reviews   \n",
    "reviews.csv 파일(286.97MB)\n",
    "\n",
    "NLTK의 불용어 사용   \n",
    "NLTK(Natural Language Toolkit): 100여개의 불용어가 미리 정의되어 있다.   \n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/aiffel0042/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 100000\n"
     ]
    }
   ],
   "source": [
    "# Reviews.csv: 568,454개의 샘플\n",
    "\n",
    "data = pd.read_csv(os.getenv(\"HOME\")+\"/aiffel/news_summarization/data/Reviews.csv\", nrows = 100000)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41619</th>\n",
       "      <td>BIG DISAPPOINTMENT !!!!! I'm so glad that Amaz...</td>\n",
       "      <td>Tastes Very Strong and Harsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37492</th>\n",
       "      <td>These bars are amazing when you look at the st...</td>\n",
       "      <td>Delicious flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17249</th>\n",
       "      <td>I used to drink Crystal Light over 10 years ag...</td>\n",
       "      <td>They have definitely changed things!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9120</th>\n",
       "      <td>this product is great tasting and you don't ev...</td>\n",
       "      <td>great taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23907</th>\n",
       "      <td>I have a bag of Popchips everyday with lunch. ...</td>\n",
       "      <td>Popchips 5 Stars, Chili Lime Flavor 3 Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10655</th>\n",
       "      <td>All I can say is that our two dogs love these ...</td>\n",
       "      <td>Canine Testimonial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53905</th>\n",
       "      <td>I don't see how anyone can go wrong with any o...</td>\n",
       "      <td>May Ploy Curry Sauce - Get Sum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>Makes my dog's poo smell like roses!  No just ...</td>\n",
       "      <td>Super Dooooo per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30273</th>\n",
       "      <td>We have tried numerous recipes, but this makes...</td>\n",
       "      <td>Best GF bread we've found yet!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87557</th>\n",
       "      <td>This is by far the best cheese popcorn I have ...</td>\n",
       "      <td>Unbelievably Cheesy!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84171</th>\n",
       "      <td>It does not seem to be as strong a seasoning e...</td>\n",
       "      <td>MSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95307</th>\n",
       "      <td>I love this water.  It's the only water I drin...</td>\n",
       "      <td>great product, but beware of seller!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73409</th>\n",
       "      <td>These are the only graham crackers I've found ...</td>\n",
       "      <td>Real Graham Crackers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52426</th>\n",
       "      <td>Chinese Black Rice is interesting. It reminds ...</td>\n",
       "      <td>Chinese Black Rice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88584</th>\n",
       "      <td>This is our favorite chip and the single servi...</td>\n",
       "      <td>Taste fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  \\\n",
       "41619  BIG DISAPPOINTMENT !!!!! I'm so glad that Amaz...   \n",
       "37492  These bars are amazing when you look at the st...   \n",
       "17249  I used to drink Crystal Light over 10 years ag...   \n",
       "9120   this product is great tasting and you don't ev...   \n",
       "23907  I have a bag of Popchips everyday with lunch. ...   \n",
       "10655  All I can say is that our two dogs love these ...   \n",
       "53905  I don't see how anyone can go wrong with any o...   \n",
       "20627  Makes my dog's poo smell like roses!  No just ...   \n",
       "30273  We have tried numerous recipes, but this makes...   \n",
       "87557  This is by far the best cheese popcorn I have ...   \n",
       "84171  It does not seem to be as strong a seasoning e...   \n",
       "95307  I love this water.  It's the only water I drin...   \n",
       "73409  These are the only graham crackers I've found ...   \n",
       "52426  Chinese Black Rice is interesting. It reminds ...   \n",
       "88584  This is our favorite chip and the single servi...   \n",
       "\n",
       "                                           Summary  \n",
       "41619                 Tastes Very Strong and Harsh  \n",
       "37492                             Delicious flavor  \n",
       "17249         They have definitely changed things!  \n",
       "9120                                   great taste  \n",
       "23907  Popchips 5 Stars, Chili Lime Flavor 3 Stars  \n",
       "10655                           Canine Testimonial  \n",
       "53905               May Ploy Curry Sauce - Get Sum  \n",
       "20627                             Super Dooooo per  \n",
       "30273               Best GF bread we've found yet!  \n",
       "87557                         Unbelievably Cheesy!  \n",
       "84171                                          MSG  \n",
       "95307         great product, but beware of seller!  \n",
       "73409                         Real Graham Crackers  \n",
       "52426                           Chinese Black Rice  \n",
       "88584                                  Taste fresh  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련할 summary, text열만 분리하여 저장하기\n",
    "\n",
    "data = data[['Text','Summary']]\n",
    "data.head()\n",
    "\n",
    "#랜덤한 15개 샘플 출력\n",
    "data.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 열에서 중복을 배제한 유일한 샘플의 수 : 88426\n",
      "Summary 열에서 중복을 배제한 유일한 샘플의 수 : 72348\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리하기\n",
    "# 1. 중복 샘플과 Null값인 샘플 제거하기\n",
    "\n",
    "print('Text 열에서 중복을 배제한 유일한 샘플의 수 :', data['Text'].nunique())\n",
    "print('Summary 열에서 중복을 배제한 유일한 샘플의 수 :', data['Summary'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88426\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['Text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text       0\n",
      "Summary    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Null값 확인하기\n",
    "\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88425\n"
     ]
    }
   ],
   "source": [
    "# dropna(): null값인 행 제거\n",
    "\n",
    "data.dropna(axis = 0, inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 정규화\n",
    "# it'll == it will, mustn't == must not 이런 표현은 같은 의미이므로 같은 표현으로 통일시켜주는\n",
    "# 텍스트 정규화가 필요하다.\n",
    "# https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                        \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                        \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                        \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                        \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                        \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                        \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                        \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                        \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                        \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                        \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                        \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                        \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                        \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                        \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                        \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                        \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                        \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                        \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                        \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                        \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                        \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                        \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# 불용어 제거하기\n",
    "\n",
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "\n",
    "# text 전처리시에만 사용하고 summary에는 사용하지 않음.\n",
    "# summary는 이미 요약된 단어들로 이루어졌기 때문에 그대로 둠으로써 의미가 잘 나타나도록 한다.\n",
    "\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"', '', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\", \"\",sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# 전처리가 제대로 되는지 확인하기\n",
    "\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, False))  # 불용어를 제거하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better',\n",
       " 'product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo',\n",
       " 'confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch',\n",
       " 'looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal',\n",
       " 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = []\n",
    "\n",
    "# 전체 Text 데이터에 대한 전처리 : 10분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Text']:\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "\n",
    "# 전처리 후 출력\n",
    "clean_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good quality dog food',\n",
       " 'not as advertised',\n",
       " 'delight says it all',\n",
       " 'cough medicine',\n",
       " 'great taffy']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_summary = []\n",
    "\n",
    "# 전체 Summary 데이터에 대한 전처리 : 5분 이상 시간이 걸릴 수 있습니다. \n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, False))\n",
    "\n",
    "clean_summary[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 과정에서 문장의 단어가 모두 제거될 수도 있으므로 빈 샘플 확인하기\n",
    "# 만약 있다면 null값을 대체하기\n",
    "\n",
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text        0\n",
       "Summary    70\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 88355\n"
     ]
    }
   ],
   "source": [
    "# 전처리 과정에 모든 단어가 제거된 샘플은 제거하기\n",
    "\n",
    "data.dropna(axis=0, inplace=True)\n",
    "print('전체 샘플수 :',(len(data)))#데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 2\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.792428272310566\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 4.010729443721352\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAcyklEQVR4nO3dfbhWdZ3v8fdHUCSfkYcLwdx4ZDqplQ9oNllZTIrphJ2jhmdMKhrOcZy06cFgbErnGmbgNCcda8QoG/EhlcsyOT6kiDpOJwI3SgEqx62QbuEIPiFqkuD3/LF+u25u7r33gsW6773g87qudd1rfe/1W/f3J8rX33r4LUUEZmZm22u3VidgZmbV5kJiZmaFuJCYmVkhLiRmZlaIC4mZmRXiQmJmZoW4kJiZWSEuJGYlkfRazfK2pN/VbP/FdhzvJEmdZeRqVkT/VidgtrOKiL271iWtAr4QEfe1LiOzcnhEYtZkknaTNEXSU5JelDRH0qD03UxJt9bsO0PSfEl7AXcDB9WMag5qVR/MarmQmDXfhcAZwEeAg4CXgX9N330FeK+kz0r6EDAJmBgRrwOnAqsjYu+0rG5B7mZb8akts+b778BfR0QngKRLgWckfSYi3pB0LvBzYAPwxa79zPoqFxKz5jsEuE3S2zWxzcAw4LmIWCTpaWAoMKcVCZptC5/aMmu+Z4FTI2L/mmXPiHgOQNIFwABgNXBxTTtP1W19kguJWfNdDUyTdAiApCGSxqf1PwH+ATgX+AxwsaSjUrvngQMl7deCnM265UJi1nz/AswF7pW0AfgV8H5J/YEbgBkR8euIeBL4W+B6SQMi4gngJuBpSa/4ri3rK+QXW5mZWREekZiZWSEuJGZmVogLiZmZFeJCYmZmhexyDyQOHjw42traWp2GmVmlLF68+IWIGNLou12ukLS1tdHe3t7qNMzMKkXSb7v7zqe2zMysEBcSMzMrxIXEzMwKcSExM7NCXEjMzKwQFxIzMyvEhcTMzApxITEzs0JcSMzMrJBd7sn2Itqm3Nnj96umn9akTMzM+g6PSMzMrJBSC4mkVZKWSloiqT3FBkmaJ+nJ9HlAzf5TJXVIWiHplJr4sek4HZKulKQUHyDplhRfKKmtzP6YmdnWmjEi+WhEHBURY9L2FGB+RIwG5qdtJB0OTACOAMYBV0nql9rMBCYDo9MyLsUnAS9HxGHA5cCMJvTHzMxqtOLU1nhgdlqfDZxRE785IjZGxEqgAzhe0nBg34hYENkL5q+ra9N1rFuBsV2jFTMza46yC0kA90paLGlyig2LiDUA6XNoio8Anq1p25liI9J6fXyLNhGxCVgPHFifhKTJktolta9bt26HdMzMzDJl37X1wYhYLWkoME/SEz3s22gkET3Ee2qzZSBiFjALYMyYMVt9b2Zm26/UEUlErE6fa4HbgOOB59PpKtLn2rR7J3BwTfORwOoUH9kgvkUbSf2B/YCXyuiLmZk1VlohkbSXpH261oGTgWXAXGBi2m0icHtanwtMSHdijSK7qL4onf7aIOmEdP3jvLo2Xcc6E7g/XUcxM7MmKfPU1jDgtnTtuz/w44j4uaSHgTmSJgHPAGcBRMRySXOAx4BNwAURsTkd63zgWmAgcHdaAK4BrpfUQTYSmVBif8zMrIHSCklEPA28r0H8RWBsN22mAdMaxNuBIxvE3yQVIjMzaw0/2W5mZoW4kJiZWSEuJGZmVogLiZmZFeJCYmZmhbiQmJlZIS4kZmZWiAuJmZkV4kJiZmaFuJCYmVkhLiRmZlaIC4mZmRXiQmJmZoW4kJiZWSEuJGZmVogLiZmZFeJCYmZmhbiQmJlZIS4kZmZWiAuJmZkV4kJiZmaFuJCYmVkhLiRmZlaIC4mZmRXiQmJmZoW4kJiZWSEuJGZmVogLiZmZFeJCYmZmhbiQmJlZIS4kZmZWSOmFRFI/SY9KuiNtD5I0T9KT6fOAmn2nSuqQtELSKTXxYyUtTd9dKUkpPkDSLSm+UFJb2f0xM7MtNWNEchHweM32FGB+RIwG5qdtJB0OTACOAMYBV0nql9rMBCYDo9MyLsUnAS9HxGHA5cCMcrtiZmb1Si0kkkYCpwE/rAmPB2an9dnAGTXxmyNiY0SsBDqA4yUNB/aNiAUREcB1dW26jnUrMLZrtGJmZs1R9ojkCuBi4O2a2LCIWAOQPoem+Ajg2Zr9OlNsRFqvj2/RJiI2AeuBA+uTkDRZUruk9nXr1hXtk5mZ1SitkEg6HVgbEYvzNmkQix7iPbXZMhAxKyLGRMSYIUOG5EzHzMzy6F/isT8IfFLSJ4A9gX0l3QA8L2l4RKxJp63Wpv07gYNr2o8EVqf4yAbx2jadkvoD+wEvldUhMzPbWmkjkoiYGhEjI6KN7CL6/RFxLjAXmJh2mwjcntbnAhPSnVijyC6qL0qnvzZIOiFd/zivrk3Xsc5Mv7HViMTMzMpT5oikO9OBOZImAc8AZwFExHJJc4DHgE3ABRGxObU5H7gWGAjcnRaAa4DrJXWQjUQmNKsTZmaWaUohiYgHgQfT+ovA2G72mwZMaxBvB45sEH+TVIjMzKw1/GS7mZkV0mshkXSWpH3S+jck/VTSMeWnZmZmVZBnRPJ3EbFB0onAKWQPAM4sNy0zM6uKPIWk64L3acDMiLgd2KO8lMzMrEryFJLnJH0fOBu4S9KAnO3MzGwXkKcgnA3cA4yLiFeAQcDXSs3KzMwqo9dCEhFvkD19fmIKbQKeLDMpMzOrjjx3bX0L+DowNYV2B24oMykzM6uOPKe2PgV8EngdICJWA/uUmZSZmVVHnkLy+zR/VQBI2qvclMzMrEryFJI56a6t/SX9JXAf8INy0zIzs6roda6tiPhnSR8HXgXeBXwzIuaVnpmZmVVCrkkbU+Fw8TAzs610W0gkbaDB2wbJ3koYEbFvaVmZmVlldFtIIsJ3ZpmZWa9yndpKs/2eSDZC+UVEPFpqVmZmVhl5Hkj8JtmMvwcCg4FrJX2j7MTMzKwa8oxIzgGOTm8jRNJ04BHgH8pMzMzMqiHPcySrgD1rtgcAT5WSjZmZVU6eEclGYLmkeWTXSD4O/ELSlQARcWGJ+ZmZWR+Xp5DclpYuD5aTipmZVVGeJ9tnNyMRMzOrpjx3bZ0u6VFJL0l6VdIGSa82IzkzM+v78pzaugL4L8DSNAuwmZnZH+S5a+tZYJmLiJmZNZJnRHIxcJekfye7gwuAiPhOaVmZmVll5Ckk04DXyJ4l2aPcdMzMrGryFJJBEXFy6ZmYmVkl5blGcp8kFxIzM2soTyG5APi5pN/59l8zM6uX54FEv5fEzMy6lfd9JAcAo6mZvDEiHiorKTMzq448T7Z/AXgIuAe4LH1emqPdnpIWSfq1pOWSLkvxQZLmSXoyfR5Q02aqpA5JKySdUhM/VtLS9N2VkpTiAyTdkuILJbVtW/fNzKyoPNdILgKOA34bER8FjgbW5Wi3EfhYRLwPOAoYJ+kEYAowPyJGA/PTNpIOByYARwDjgKsk9UvHmglMJhsVjU7fA0wCXo6Iw4DLgRk58jIzsx0oTyF5s+alVgMi4gngXb01isxraXP3tAQwnuyNi6TPM9L6eODmiNgYESuBDuB4ScOBfSNiQXq6/rq6Nl3HuhUY2zVaMTOz5shTSDol7Q/8DJgn6XZgdZ6DS+onaQmwFpgXEQuBYRGxBiB9Dk27jyCbjuUPv5tiI9J6fXyLNhGxCVhP9krg+jwmS2qX1L5uXZ7BlJmZ5ZXnrq1PpdVLJT0A7Af8PM/BI2IzcFQqRLdJOrKH3RuNJKKHeE9t6vOYBcwCGDNmjOcMMzPbgfJcbP9PkgZ0bQJtwDu25Uci4hWyF2KNA55Pp6tIn2vTbp3AwTXNRpKNfDrTen18izaS+pMVuZe2JTczMysmz6mtnwCbJR0GXAOMAn7cWyNJQ9JIBEkDgT8DngDmAhPTbhOB29P6XGBCuhNrFNlF9UXp9NcGSSek6x/n1bXpOtaZwP2epdjMrLnyPEfydkRskvQp4IqI+K6kR3O0Gw7MTnde7QbMiYg7JC0A5kiaBDwDnAUQEcslzQEeAzYBF6RTYwDnA9cCA4G70wJZYbteUgfZSGRCjrzMzGwHylNI3pJ0Dtn/+f95iu3eW6OI+A3ZrcL18ReBsd20mUY223B9vB3Y6vpKupvsrN5yMTOz8uQ5tfU54APAtIhYmU473VBuWmZmVhV57tp6DLiwZnslML3MpMzMrDryjEjMzMy65UJiZmaFdFtIJF2fPi9qXjpmZlY1PY1IjpV0CPB5SQekWXv/sDQrQTMz69t6uth+NdlUKIcCi9lyOpJIcTMz28V1OyKJiCsj4t3AjyLi0IgYVbO4iJiZGZDv9t/zJb0P+FAKPZQeNjQzM8s1aeOFwI1k070PBW6U9MWyEzMzs2rIM0XKF4D3R8TrAJJmAAuA75aZmJmZVUOe50gEbK7Z3kzj94CYmdkuKM+I5N+AhZJuS9tnkM26a2Zmluti+3ckPQicSDYS+VxE5JlG3szMdgF5RiRExCPAIyXnYmZmFeS5tszMrBAXEjMzK6THQiKpn6T7mpWMmZlVT4+FJL0z/Q1J+zUpHzMzq5g8F9vfBJZKmge83hWMiAu7b7JraptyZ4/fr5p+WpMyMTNrnjyF5M60mJmZbSXPcySzJQ0E3hkRK5qQk5mZVUieSRv/HFhC9m4SJB0laW7ZiZmZWTXkuf33UuB44BWAiFgCjCoxJzMzq5A8hWRTRKyvi0UZyZiZWfXkudi+TNJ/A/pJGg1cCPyy3LTMzKwq8oxIvggcAWwEbgJeBb5UZlJmZlYdee7aegO4JL3QKiJiQ/lpmZlZVeS5a+s4SUuB35A9mPhrSceWn5qZmVVBnmsk1wB/FRH/ASDpRLKXXb23zMTMzKwa8lwj2dBVRAAi4heAT2+ZmRnQQyGRdIykY4BFkr4v6SRJH5F0FfBgbweWdLCkByQ9Lmm5pItSfJCkeZKeTJ8H1LSZKqlD0gpJp9TEj5W0NH13pSSl+ABJt6T4Qklt2/1PwszMtktPp7b+V932t2rW8zxHsgn4SkQ8ImkfYHGa+PGzwPyImC5pCjAF+Lqkw4EJZHeIHQTcJ+lP0gzEM4HJwK+Au4BxwN3AJODliDhM0gRgBvDpHLmZmdkO0m0hiYiPFjlwRKwB1qT1DZIeB0YA44GT0m6zyUY3X0/xmyNiI7BSUgdwvKRVwL4RsQBA0nXAGWSFZDzZk/cAtwLfk6SI8AOTZmZN0uvFdkn7A+cBbbX7b8s08umU09HAQmBYKjJExBpJQ9NuI8hGHF06U+yttF4f72rzbDrWJknrgQOBF+p+fzLZiIZ3vvOdedM2M7Mc8ty1dRfZX/BLgbe39Qck7Q38BPhSRLyaLm803LVBLHqI99Rmy0DELGAWwJgxYzxaMTPbgfIUkj0j4svbc3BJu5MVkRsj4qcp/Lyk4Wk0MhxYm+KdwME1zUcCq1N8ZIN4bZtOSf2B/YCXtidXMzPbPnlu/71e0l9KGp7uuBokaVBvjdKdVdcAj0fEd2q+mgtMTOsTgdtr4hPSnVijgNHAonQabIOkE9Ixz6tr03WsM4H7fX3EzKy58oxIfg98G7iEP542CuDQXtp9EPgM2dPwS1Lsb4HpwBxJk4BngLMAImK5pDnAY2R3fF2Q7tgCOB+4FhhIdpH97hS/hqzQdZCNRCbk6I+Zme1AeQrJl4HDIuKFXveskR5c7O6CyNhu2kwDpjWItwNHNoi/SSpEZmbWGnlObS0H3ig7ETMzq6Y8I5LNwBJJD5BNJQ9s2+2/Zma288pTSH6WFjMzs63keR/J7GYkYmZm1ZTnyfaVNH7Ir7e7tszMbBeQ59TWmJr1Pcnukur1ORIzM9s19HrXVkS8WLM8FxFXAB9rQm5mZlYBeU5tHVOzuRvZCGWf0jIyM7NKyXNqq/a9JJuAVcDZpWRjZmaVk+eurULvJTEzs51bnlNbA4D/ytbvI/n78tIyM7OqyHNq63ZgPbCYmifbzczMIF8hGRkR40rPxMzMKinPpI2/lPSe0jMxM7NKyjMiORH4bHrCfSPZ1PAREe8tNTMzM6uEPIXk1NKzMDOzyspz++9vm5GImZlVU55rJGZmZt1yITEzs0JcSMzMrBAXEjMzK8SFxMzMCnEhMTOzQlxIzMysEBcSMzMrxIXEzMwKcSExM7NCXEjMzKwQFxIzMyvEhcTMzApxITEzs0JKKySSfiRpraRlNbFBkuZJejJ9HlDz3VRJHZJWSDqlJn6spKXpuyslKcUHSLolxRdKaiurL2Zm1r0yRyTXAvXvep8CzI+I0cD8tI2kw4EJwBGpzVWS+qU2M4HJwOi0dB1zEvByRBwGXA7MKK0nZmbWrdIKSUQ8BLxUFx4PzE7rs4EzauI3R8TGiFgJdADHSxoO7BsRCyIigOvq2nQd61ZgbNdoxczMmqfZ10iGRcQagPQ5NMVHAM/W7NeZYiPSen18izYRsQlYDxzY6EclTZbULql93bp1O6grZmYGfedie6ORRPQQ76nN1sGIWRExJiLGDBkyZDtTNDOzRppdSJ5Pp6tIn2tTvBM4uGa/kcDqFB/ZIL5FG0n9gf3Y+lSamZmVrNmFZC4wMa1PBG6viU9Id2KNIruoviid/tog6YR0/eO8ujZdxzoTuD9dRzEzsybqX9aBJd0EnAQMltQJfAuYDsyRNAl4BjgLICKWS5oDPAZsAi6IiM3pUOeT3QE2ELg7LQDXANdL6iAbiUwoqy9mZta90gpJRJzTzVdju9l/GjCtQbwdOLJB/E1SITIzs9bpKxfbzcysolxIzMysEBcSMzMrxIXEzMwKKe1iu22tbcqd3X63avppTczEzGzH8YjEzMwKcSExM7NCXEjMzKwQFxIzMyvEhcTMzApxITEzs0JcSMzMrBAXEjMzK8SFxMzMCnEhMTOzQlxIzMysEBcSMzMrxIXEzMwKcSExM7NCXEjMzKwQFxIzMyvEhcTMzApxITEzs0L8qt0+oqfX8IJfxWtmfZdHJGZmVogLiZmZFeJCYmZmhbiQmJlZIS4kZmZWiAuJmZkV4tt/K6Kn24N9a7CZtZJHJGZmVkjlRySSxgH/AvQDfhgR01ucUtP5YUYza6VKFxJJ/YB/BT4OdAIPS5obEY+1NrO+xYXGzMpU6UICHA90RMTTAJJuBsYDLiTboLdC0xMXITOreiEZATxbs90JvL9+J0mTgclp8zVJK7bz9wYDL2xn275ih/ZBM3bUkbaZ/yz6hp2hD7Bz9KPsPhzS3RdVLyRqEIutAhGzgFmFf0xqj4gxRY/TSjtDH2Dn6If70HfsDP1oZR+qftdWJ3BwzfZIYHWLcjEz2yVVvZA8DIyWNErSHsAEYG6LczIz26VU+tRWRGyS9NfAPWS3//4oIpaX+JOFT4/1ATtDH2Dn6If70HfsDP1oWR8UsdUlBTMzs9yqfmrLzMxazIXEzMwKcSHJQdI4SSskdUia0up8uiPpYEkPSHpc0nJJF6X4IEnzJD2ZPg+oaTM19WuFpFNal/2WJPWT9KikO9J2Ffuwv6RbJT2R/kw+ULV+SPqb9O/SMkk3SdqzCn2Q9CNJayUtq4ltc96SjpW0NH13paRGjxw0sw/fTv8+/UbSbZL27xN9iAgvPSxkF/GfAg4F9gB+DRze6ry6yXU4cExa3wf4v8DhwP8EpqT4FGBGWj889WcAMCr1s1+r+5Fy+zLwY+COtF3FPswGvpDW9wD2r1I/yB74XQkMTNtzgM9WoQ/Ah4FjgGU1sW3OG1gEfIDsmbW7gVNb3IeTgf5pfUZf6YNHJL37wzQsEfF7oGsalj4nItZExCNpfQPwONlfBuPJ/lIjfZ6R1scDN0fExohYCXSQ9belJI0ETgN+WBOuWh/2JfuL4BqAiPh9RLxCxfpBdmfnQEn9gXeQPafV5/sQEQ8BL9WFtylvScOBfSNiQWR/I19X06Z0jfoQEfdGxKa0+SuyZ+egxX1wIeldo2lYRrQol9wktQFHAwuBYRGxBrJiAwxNu/XVvl0BXAy8XROrWh8OBdYB/5ZO0f1Q0l5UqB8R8Rzwz8AzwBpgfUTcS4X6UGdb8x6R1uvjfcXnyUYY0OI+uJD0Ltc0LH2JpL2BnwBfiohXe9q1QaylfZN0OrA2IhbnbdIg1hf+fPqTnZaYGRFHA6+TnU7pTp/rR7qGMJ7sVMlBwF6Szu2pSYNYX/iz6E13effZ/ki6BNgE3NgVarBb0/rgQtK7Sk3DIml3siJyY0T8NIWfT0Nc0ufaFO+Lffsg8ElJq8hOI35M0g1Uqw+Q5dUZEQvT9q1khaVK/fgzYGVErIuIt4CfAn9KtfpQa1vz7uSPp45q4y0laSJwOvAX6XQVtLgPLiS9q8w0LOlujGuAxyPiOzVfzQUmpvWJwO018QmSBkgaBYwmuzDXMhExNSJGRkQb2T/r+yPiXCrUB4CI+H/As5LelUJjyV5vUKV+PAOcIOkd6d+tsWTX3arUh1rblHc6/bVB0gmp/+fVtGkJZS/y+zrwyYh4o+ar1vahWXcgVHkBPkF2B9RTwCWtzqeHPE8kG7b+BliSlk8ABwLzgSfT56CaNpekfq2giXek5OzPSfzxrq3K9QE4CmhPfx4/Aw6oWj+Ay4AngGXA9WR3BfX5PgA3kV3XeYvs/8onbU/ewJjU96eA75FmA2lhHzrIroV0/fd9dV/og6dIMTOzQnxqy8zMCnEhMTOzQlxIzMysEBcSMzMrxIXEzMwKcSGxnZqk10o45lGSPlGzfamkrxY43llpduAHdkyG253HKkmDW5mDVZMLidm2O4rs+ZwdZRLwVxHx0R14TLOmcSGxXYakr0l6OL3L4bIUa0ujgR+k927cK2lg+u64tO+C9B6IZWl2g78HPi1piaRPp8MfLulBSU9LurCb3z8nvRdimaQZKfZNsgdJr5b07br9h0t6KP3OMkkfSvGZktpTvpfV7L9K0j+mfNslHSPpHklPSfofaZ+T0jFvk/SYpKslbfX3gKRzJS1Kv/19Ze+H6Sfp2pTLUkl/U/CPxHYWrX5y1ouXMhfgtfR5MjCLbBK73YA7yKZ5byOb/O6otN8c4Ny0vgz407Q+nfReCLJ3cnyv5jcuBX5J9tT3YOBFYPe6PA4im3JkCNmEjvcDZ6TvHgTGNMj9K6SZFMjei7NPWh9UE3sQeG/aXgWcn9YvJ3uifp/0m2tT/CTgTbLZifsB84Aza9oPBt4N/O+uPgBXkU2tcSwwrya//Vv95+ulbywekdiu4uS0PAo8AvxnsvmIIJuYcElaXwy0KXvz3D4R8csU/3Evx78zsndBvEA2GeCwuu+PAx6MbALErllbP9zLMR8GPifpUuA9kb1jBuBsSY+kvhxB9lKjLl3zwC0FFkbEhohYB7ypP75Nb1Fk79fZTDYNx4l1vzuWrGg8LGlJ2j4UeBo4VNJ305xPPc0sbbuQ/q1OwKxJBPxTRHx/i2D23paNNaHNwEAaT7/dk/pj1P+3tc2vN42IhyR9mOwlX9enU1//AXwVOC4iXpZ0LbBngzzersvp7Zqc6udFqt8WMDsiptbnJOl9wCnABcDZZO/EsF2cRyS2q7gH+Lyyd7UgaYSkod3tHBEvk2ZNTaEJNV9vIDtltC0WAh+RNFhSP+Ac4N97aiDpELJTUj8gm9X5GGBfsnebrJc0DDh1G/OA7M15o9K1kU8Dv6j7fj5wZtc/H2XvOj8k3dG1W0T8BPi7lI+ZRyS2a4iIeyW9G1iQzabNa8C5ZKOH7kwCfiDpdbJrEetT/AFgSjrt8085f3+NpKmprYC7IqK36bxPAr4m6a2U73kRsVLSo8ByslNN/yfP79dZQHbN5z3AQ8Btdbk+JukbwL2p2LxFNgL5HdkbH7v+B3SrEYvtmjz7r1k3JO0dEa+l9SnA8Ii4qMVpFSLpJOCrEXF6q3OxnYdHJGbdOy2NIvoDvyW7W8vM6nhEYmZmhfhiu5mZFeJCYmZmhbiQmJlZIS4kZmZWiAuJmZkV8v8Bf8ovhCSyxK4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 샘플의 최소, 최대, 평균을 구하고 길이 분포 시각화하기\n",
    "\n",
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 적절한 최대 길이 정하기\n",
    "\n",
    "text_max_len = 50\n",
    "summary_max_len = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이에 속한 데이터를 전체 데이터의 몇%에 해당할까?\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "    cnt = 0\n",
    "    for s in nested_list:\n",
    "        if(len(s.split()) <= max_len):\n",
    "            cnt = cnt + 1\n",
    "    print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 50 이하인 샘플의 비율: 0.7745119121724859\n",
      "전체 샘플 중 길이가 8 이하인 샘플의 비율: 0.9424593967517402\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['Text'])\n",
    "below_threshold_len(summary_max_len,  data['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 65818\n"
     ]
    }
   ],
   "source": [
    "# 최대 길이보다 긴 데이터는 자르지 않고 제외시키는 방법으로 전처리 하기\n",
    "\n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 디코더의 입력과 레이블에 시작토큰과 종료토큰 추가하기\n",
    "# 디코더 입력에 해당하면서 시작토큰이 있으면 decoder_input\n",
    "# 디코더 출력에 해당하면서 종료토큰이 있으면 decoder_target\n",
    "\n",
    "# summary 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더의 입력, 디코더의 입력과 레이블을 numpy 타입으로 변경 저장\n",
    "\n",
    "encoder_input = np.array(data['Text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65047 54193 36829 ... 16006 38865 14736]\n"
     ]
    }
   ],
   "source": [
    "# 데이터 섞기\n",
    "\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 13163\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터와 테스트 데이터 분리하기 8:2\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :',n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 52655\n",
      "훈련 레이블의 개수 : 52655\n",
      "테스트 데이터의 개수 : 13163\n",
      "테스트 레이블의 개수 : 13163\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단어 집합(vocaburary) 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 연산이 가능하도록 정수로 바꾸기\n",
    "# 각 단어에 고유한 정수를 부여하기(맵핑하기), 단어 집합 만들기\n",
    "\n",
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 31988\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 23746\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8242\n",
      "단어 집합에서 희귀 단어의 비율: 74.23408778291859\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.381203202872192\n"
     ]
    }
   ],
   "source": [
    "# 단어 집합은 src_tokenizer.word_index에 저장된다.\n",
    "# 등장 빈도수가 7회 미만인 단어는 제외하기\n",
    "# src_tokenizer.word_counts.items()에 단어와 빈도 수가 저장되어 있다.\n",
    "\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 빈도수가 6회 이하인 단어는 제외하고 단어 집합 크기를 8000으로 제한\n",
    "# 토크나이저 정의 시 크기를 지정하면 된다.\n",
    "\n",
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1452, 155, 90, 2, 543, 7672, 2459, 2968, 44, 190, 7673, 1132, 3402, 1197, 2184, 946, 7213, 279, 245, 44, 322, 381, 1, 42, 35, 361, 6476, 1205, 420, 7, 540, 54, 517, 4081, 318, 1274, 137, 1117, 4654, 344, 3989, 311, 2208, 10, 22], [1211, 9, 3358, 3254, 5651, 156, 587, 137, 3599, 111, 4399, 502, 486, 9, 486, 7, 743, 335], [654, 296, 7674, 246, 2626, 348, 2093, 1278, 2626, 155, 157, 3671, 463, 202, 1259, 18, 3600, 13, 824, 2480, 2626, 124, 287, 337, 568, 7, 246, 1613, 348, 5, 1, 165, 129, 755, 881, 713, 476, 730]]\n"
     ]
    }
   ],
   "source": [
    "# texts_to_sequences(): 생성된 단어 집합에 기반하여 입력된 텍스트의 단어들을 모두 정수로 변환시킨다.\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary 데이터도 동일하게 진행\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 10475\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 8105\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2370\n",
      "단어 집합에서 희귀 단어의 비율: 77.3747016706444\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.89089561436396\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 3, 16, 388, 131], [1, 157, 27, 19, 384], [1, 69, 402], [1, 75, 23, 5, 8, 528], [1, 385, 215, 497, 9, 85]]\n",
      "target\n",
      "decoder  [[3, 16, 388, 131, 2], [157, 27, 19, 384, 2], [69, 402, 2], [75, 23, 5, 8, 528, 2], [385, 215, 497, 9, 85, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1294\n",
      "삭제할 테스트 데이터의 개수 : 325\n",
      "훈련 데이터의 개수 : 51361\n",
      "훈련 레이블의 개수 : 51361\n",
      "테스트 데이터의 개수 : 12838\n",
      "테스트 레이블의 개수 : 12838\n"
     ]
    }
   ],
   "source": [
    "# 패딩을 추가하기 전에 단어 집합을 각각 8000개, 2000개로 제한하면서 빈 데이터가 나올 수 있다.\n",
    "# text 데이터 보다는 summary 데이터에서 많이 나올 것이다.\n",
    "# decoder는 이전에 토큰을 추가했으므로 빈 데이터는 길이가 1이 나올 것이다.\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서로 다른 길이를 가진 샘플들의 길이는 맞추기 위해 패딩 처리를 한다.\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# hidden_size는 LSTM의 뉴론 갯수\n",
    "# 3개의 LSTM층은 모델의 복잡도를 높여서 모델의 용량을 높인 것이다.\n",
    "# 인코더에서 나온 출력 벡터를 디코더로 보낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 설계\n",
    "\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# initial_state는 인코더의 hidden state와 cell state 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 디코더의 출력은 tar_vocab에서 하나를 선택하는 분류의 문제이므로 소프트맥스를 사용한다.\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 매커니즘 적용하기\n",
    "# 이미 구현된 어텐션 함수를 가져와서 디코더 출력층에 겹할하기\n",
    "# 깃허브에서 어텐션 함수 다운로드 하기\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 50, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 50, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 50, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,276,432\n",
      "Trainable params: 4,276,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층 수정하기\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "201/201 [==============================] - 201s 998ms/step - loss: 2.7071 - val_loss: 2.4194\n",
      "Epoch 2/50\n",
      "201/201 [==============================] - 203s 1s/step - loss: 2.3707 - val_loss: 2.2756\n",
      "Epoch 3/50\n",
      "201/201 [==============================] - 202s 1s/step - loss: 2.2276 - val_loss: 2.1509\n",
      "Epoch 4/50\n",
      "201/201 [==============================] - 203s 1s/step - loss: 2.1136 - val_loss: 2.0760\n",
      "Epoch 5/50\n",
      "201/201 [==============================] - 207s 1s/step - loss: 2.0322 - val_loss: 2.0239\n",
      "Epoch 6/50\n",
      "201/201 [==============================] - 196s 977ms/step - loss: 1.9691 - val_loss: 1.9876\n",
      "Epoch 7/50\n",
      "201/201 [==============================] - 195s 968ms/step - loss: 1.9190 - val_loss: 1.9555\n",
      "Epoch 8/50\n",
      "201/201 [==============================] - 201s 1000ms/step - loss: 1.8741 - val_loss: 1.9296\n",
      "Epoch 9/50\n",
      "201/201 [==============================] - 197s 982ms/step - loss: 1.8316 - val_loss: 1.9113\n",
      "Epoch 10/50\n",
      "201/201 [==============================] - 196s 976ms/step - loss: 1.7948 - val_loss: 1.8930\n",
      "Epoch 11/50\n",
      "201/201 [==============================] - 195s 969ms/step - loss: 1.7603 - val_loss: 1.8839\n",
      "Epoch 12/50\n",
      "201/201 [==============================] - 194s 964ms/step - loss: 1.7285 - val_loss: 1.8768\n",
      "Epoch 13/50\n",
      "201/201 [==============================] - 194s 963ms/step - loss: 1.6988 - val_loss: 1.8661\n",
      "Epoch 14/50\n",
      "201/201 [==============================] - 198s 984ms/step - loss: 1.6723 - val_loss: 1.8621\n",
      "Epoch 15/50\n",
      "201/201 [==============================] - 193s 960ms/step - loss: 1.6457 - val_loss: 1.8595\n",
      "Epoch 16/50\n",
      "201/201 [==============================] - 193s 958ms/step - loss: 1.6212 - val_loss: 1.8564\n",
      "Epoch 17/50\n",
      "201/201 [==============================] - 193s 959ms/step - loss: 1.5975 - val_loss: 1.8558\n",
      "Epoch 18/50\n",
      "201/201 [==============================] - 193s 959ms/step - loss: 1.5753 - val_loss: 1.8549\n",
      "Epoch 19/50\n",
      "201/201 [==============================] - 193s 959ms/step - loss: 1.5533 - val_loss: 1.8560\n",
      "Epoch 20/50\n",
      "201/201 [==============================] - 194s 963ms/step - loss: 1.5326 - val_loss: 1.8545\n",
      "Epoch 21/50\n",
      "201/201 [==============================] - 194s 964ms/step - loss: 1.5121 - val_loss: 1.8612\n",
      "Epoch 22/50\n",
      "201/201 [==============================] - 191s 951ms/step - loss: 1.4928 - val_loss: 1.8597\n",
      "Epoch 00022: early stopping\n"
     ]
    }
   ],
   "source": [
    "# 모델 훈련하기\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size = 256, callbacks=[es], epochs = 50)\n",
    "\n",
    "# EarlyStopping: 특정 조건이 충족되면 모델의 훈련을 멈추는 역할\n",
    "# val_loss를 모니터링하다가 val_loss가 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습이 종료된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 손실 과정을 시각화하기\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인퍼런스 모델 구현하기\n",
    "# 정수 데이터를 실제 데이터로 복원하기 위해\n",
    "\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 단계:\n",
    "# 정답 문장을 디코더에 입력하면 디코더에서 출력하는 문장과 한꺼번에 비교 가능, 인코더와 디코더 통합 설계\n",
    "# 인퍼런스 단계(생성 단계):\n",
    "# 생성될 문장 길이만큼 디코더가 반복 수행, 인코더와 디코더 분리 설계\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 매커니즘을 사용한 출력층 설계\n",
    "\n",
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 시퀀스를 생성하는 함수\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : let us say five us really enjoy swedish fish usually gone matter days however bought pack christmas still half pack left \n",
      "실제 요약 : these actually last in this house \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : chill switch kiwi berry pour pretty wine glass relax enjoy repeat switch kiwi berry pleasing color fruity taste enough carbonation experience \n",
      "실제 요약 : my throat \n",
      "예측 요약 :  good\n",
      "\n",
      "\n",
      "원문 : gotten flavor larabar grocery store loved fact reason purchased amazon cost per unit much lower peanut butter cookie bar grocery store moist delicious bars received amazon taste stale dry crumbly expiration date understand would way reordering larabars amazon \n",
      "실제 요약 : amazon larabars taste stale and dry \n",
      "예측 요약 :  good but\n",
      "\n",
      "\n",
      "원문 : really loved baking put cookies lot replace chopped nuts also rolled cookies almond flour baking use place flour called quick breads good plan using pie crusts bear filling \n",
      "실제 요약 : loved it \n",
      "예측 요약 :  great cookies\n",
      "\n",
      "\n",
      "원문 : picky eater loves eat gerber organic mac cheese gerber organic green beans yes bit runny makes perfect month olds gives thicken whatever want older babies mommy loves great taste \n",
      "실제 요약 : excellent \n",
      "예측 요약 :  love it\n",
      "\n",
      "\n",
      "원문 : used choice avoderm many years excellent results coat digestion problems ect natural low protein large breeds like mountain dog \n",
      "실제 요약 : adult canned \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : got tea supposed help supposedly helps prepare figured cannot hurt think tea light flavored usually put honey goes great rest using past days gone full cycle yet know really work yet \n",
      "실제 요약 : light flavored tea \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : looking value unopened box cereal cannot find information send info thanks email net \n",
      "실제 요약 : cereal box \n",
      "예측 요약 :  misleading\n",
      "\n",
      "\n",
      "원문 : buy husband cannot find stores live find like enjoys greatly \n",
      "실제 요약 : great product \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : love nut bars would consider granola bars really nuts granola great travel get smashed \n",
      "실제 요약 : better than candy bar \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : best dark chocolate covered orange peel ever tasted keep ordering run cannot find good anywhere else \n",
      "실제 요약 : amazing \n",
      "예측 요약 :  best chocolate ever\n",
      "\n",
      "\n",
      "원문 : nice coffee exceptional body flavor bitter tastes great continue purchase long available \n",
      "실제 요약 : great coffee \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : california grew best wheat cereal holds day moved texas could find anywhere say time always find looking amazon searched buying unit pack ever since try disappointed \n",
      "실제 요약 : good stuff \n",
      "예측 요약 :  love this stuff\n",
      "\n",
      "\n",
      "원문 : like licorice menthol cannot go wrong semi soft sugar free candies vaguely reminiscent \n",
      "실제 요약 : love these \n",
      "예측 요약 :  licorice\n",
      "\n",
      "\n",
      "원문 : trying mean anything cookies dry tasted unpleasant \n",
      "실제 요약 : really did not like these cookies \n",
      "예측 요약 :  not as good as the original\n",
      "\n",
      "\n",
      "원문 : like tea wish could find store bad price either \n",
      "실제 요약 : good stuff \n",
      "예측 요약 :  tea\n",
      "\n",
      "\n",
      "원문 : leash gives poop bag needed success fits common refill bags find major stores \n",
      "실제 요약 : it does two things \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : love product different flavors fantastic family likes grain best corn tortilla chips house \n",
      "실제 요약 : best kept secret \n",
      "예측 요약 :  great chips\n",
      "\n",
      "\n",
      "원문 : favorite dressing stays mixed dijon spicy enough spicy flavor delicous try \n",
      "실제 요약 : best dressing ever \n",
      "예측 요약 :  great stuff\n",
      "\n",
      "\n",
      "원문 : health issues taking gluten diet good way start may source problem case using pamela products helped get right track feeling better \n",
      "실제 요약 : gluten free and feel good \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : problem bar try cannot seem without tastes good dr oz mentioned bars show thought would try one wow love particular one read ingredients find one thing bad finally treat harm unless eat six day checked quite places handle product amazon far best price \n",
      "실제 요약 : kind bars \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : purchased coffee high anticipation heard raved morning disappointed received tried really taste like chocolate doughnut anything tastes like hardened glaze covers doughnut also somewhat chemically aftertaste \n",
      "실제 요약 : chemical aftertaste \n",
      "예측 요약 :  not so good\n",
      "\n",
      "\n",
      "원문 : tell tasting salad dressing uk addicted delicious well sandwich spread tuna egg salad hint mustard sugar vinegar gives great tangy taste try want amazon buy half dozen better uk highly recommended product wish made usa \n",
      "실제 요약 : simply delicious \n",
      "예측 요약 :  love it\n",
      "\n",
      "\n",
      "원문 : revolution teas superb smooth delicate one pleasant comforting pure delight tried one pomegranate well ginger peach eye oolong white pear \n",
      "실제 요약 : teas are smooth and delicate \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : sure needed buy specific butter flavored popcorn salt could use regular salt thrilled bought makes huge difference oil important salt critical well great tasting popcorn \n",
      "실제 요약 : great addition \n",
      "예측 요약 :  great popcorn\n",
      "\n",
      "\n",
      "원문 : solved pups dog food allergy problems started purchasing several months ago itching started color size kibble even noticeably changed wrote letter newman batch numbers bags received answer since purchased solid gold wolf king royal canine german shepherd dogs okay \n",
      "실제 요약 : not as good as it used to be \n",
      "예측 요약 :  great food\n",
      "\n",
      "\n",
      "원문 : really tasty make great high protein snack order regularly keep desk drawer really filling taste great \n",
      "실제 요약 : really tasty \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : ounce pro treat beef liver treats great value dog loves need reach tub sit put paw even cut tiny pieces sometimes sprinkle onto food gobbles food size last \n",
      "실제 요약 : my dog loves these \n",
      "예측 요약 :  great for small dogs\n",
      "\n",
      "\n",
      "원문 : find amazon offer high priced get local health food store vs living harvest hemp milk great tasting even unsweetened sugar low carbs type diabetic fits nutrition plan \n",
      "실제 요약 : great stuff but overpriced in amazon \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : purely chance dr oz show guest tried different holistic weight loss products particularly intrigued product quickly ordered couple bags would forget hooked since great anything would normally use sugar avid coffee drinker particularly enjoy aroma hint nutty flavor adds beverage bye bye regular sugar \n",
      "실제 요약 : life is just bit \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : review quality product understand anyone pays much gingerbread house unless sized candy buy halloween craft store even grocery store things family eat house buy post holiday house sale save next year lasts buy halloween house holiday decorate christmas cost bucks saying \n",
      "실제 요약 : how do you buy gingerbread house \n",
      "예측 요약 :  misleading\n",
      "\n",
      "\n",
      "원문 : bought chocolates mother birthday little scared quality since significantly cheaper godiva etc mom said best chocolates ever considering chocolates go save great value \n",
      "실제 요약 : great \n",
      "예측 요약 :  love these\n",
      "\n",
      "\n",
      "원문 : tastes like pine earl never thought drinking pine needle tea bought wife cannot caffeinated varieties say big fan english breakfast decaf excellent prefer tea black hot cold earl grey tolerable unless drank splash milk sugar undrinkable iced tea would return could avoid costs young \n",
      "실제 요약 : yuck buy another variety \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : great adults kids healthy taste great buy kids eat \n",
      "실제 요약 : wholesome goodness \n",
      "예측 요약 :  great snack\n",
      "\n",
      "\n",
      "원문 : used product quite time easy use drink cup bed results morning beneficial times life gets \n",
      "실제 요약 : it works \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : like find lot earl grey teas bit weak delicious enticing bergamot aroma definitely one powerful right tea strong like strong tea means add bag regular black tea brew along stash absolutely delicious bring exotic land pure \n",
      "실제 요약 : must for lovers \n",
      "예측 요약 :  great tea\n",
      "\n",
      "\n",
      "원문 : dogs less finicky would eat two prefer chunks instead ground smelled really good best part wet food produced perfectly formed stools \n",
      "실제 요약 : best wet food \n",
      "예측 요약 :  my dog loves these\n",
      "\n",
      "\n",
      "원문 : pit bull loves chews rawhide digest properly also help keep teeth clean great product \n",
      "실제 요약 : dog chews \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : loved item wish could find stores walmart carried item louisiana time travel louisiana sometime find item fred found item houston area easy prepare great conversation piece one seen purchased item amazon \n",
      "실제 요약 : ms mac review \n",
      "예측 요약 :  great product\n",
      "\n",
      "\n",
      "원문 : one best gf bread mixes available use bake sorts breads use baking since girlfriend gluten intolerant also dairy intolerant made great banana blueberry muffins last week got rave reviews \n",
      "실제 요약 : great gf mix \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 요약 :  amazing\n",
      "\n",
      "\n",
      "원문 : best cup coffee ever use dunkin donuts fan since tried blend brew take road instead paying cup dd like strong bold coffee flavor without bitter taste one \n",
      "실제 요약 : green mountain dark magic extra bold \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n",
      "원문 : title says butter biscuits divine everyone loves parents students course love \n",
      "실제 요약 : the aroma the taste \n",
      "예측 요약 :  great for kids\n",
      "\n",
      "\n",
      "원문 : great price amount got cheaper discount stores continue get amazon \n",
      "실제 요약 : great price \n",
      "예측 요약 :  great deal\n",
      "\n",
      "\n",
      "원문 : would recommend coffee anyone like smooth medium roast find flavor rich bitter satisfying \n",
      "실제 요약 : green mountain nantucket is the best \n",
      "예측 요약 :  good coffee\n",
      "\n",
      "\n",
      "원문 : looking dutch process cocoa want ice cream considering one saw lightly problem regular cocoa assume well oils cocoa remain powder try make ice cream oils cause cocoa pill leaving chocolate ice cream tastes ok present well search continues \n",
      "실제 요약 : not for ice cream \n",
      "예측 요약 :  not as good as the\n",
      "\n",
      "\n",
      "원문 : still looking natural soda like curb occasional craving sorry gross tasting nothing like dr pepper maybe flavors bad cola one \n",
      "실제 요약 : good thought but gross \n",
      "예측 요약 :  not bad\n",
      "\n",
      "\n",
      "원문 : like ahead much ginger taste product making drink smell overwhelming horrible taste pleasant ginger lemon taste could detect lemon making aroma none taste imagine using sick open sinuses help clear nose head everyday drink way \n",
      "실제 요약 : very \n",
      "예측 요약 :  not the best\n",
      "\n",
      "\n",
      "원문 : found sugar taste blended drink well tasted like someone put table sugar terrible tasting cold coffee good expensive \n",
      "실제 요약 : cold coffee with sugar \n",
      "예측 요약 :  not good\n",
      "\n",
      "\n",
      "원문 : excited get whole wheat pizza dough ordering got two days later directions easy follow taste crust phenomenal toppings added pizza shrimp chicken cherry tomatoes mexican cheese blend turkey canadian bacon pizza turned great weight watcher point plus value per slice better alternative leading pizzas \n",
      "실제 요약 : the best pizza have ever had \n",
      "예측 요약 :  best gf pasta ever\n",
      "\n",
      "\n",
      "원문 : love machine makes perfectly delicious espresso pretty bulky beware counter space requires complaint sturdy looks move around big deal feels looks works great though \n",
      "실제 요약 : love it \n",
      "예측 요약 :  great coffee\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터 50개 샘플에 대해 실제 데이터와 예측된 데이터를 비교하기\n",
    "\n",
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 추출적 요약 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summa 패키지에 추출적 요약을 위한 모듈인 summarize를 제공해준다.\n",
    "# pip install summa\n",
    "\n",
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매트릭스 시놉시스 다운로드 하기\n",
    "\n",
    "text = requests.get('http://rare-technologies.com/the_matrix_synopsis.txt').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The screen is filled with green, cascading code which gives way to the title, The Matrix.\r\n",
      "\r\n",
      "A phone rings and text appears on the screen: \"Call trans opt: received. 2-19-98 13:24:18 REC: Log>\" As a conversation takes place between Trinity (Carrie-Anne Moss) and Cypher (Joe Pantoliano), two free humans, a table of random green numbers are being scanned and individual numbers selected, creating a series of digits not unlike an ordinary phone number, as if a code is being deciphered or a call is being traced.\r\n",
      "\r\n",
      "Trinity discusses some unknown person. Cypher taunts Trinity, suggesting she enjoys watching him. Trinity counters that \"Morpheus (Laurence Fishburne) says he may be 'the One',\" just as the sound of a number being selected alerts Trinity that someone may be tracing their call. She ends the call.\r\n",
      "\r\n",
      "Armed policemen move down a darkened, decrepit hallway in the Heart O' the City Hotel, their flashlight beam bouncing just ahead of them. They come to room 303, kick down the door and find a woman dressed in black, facing away from them. It's Trinity. She brings her hands up from the laptop she's working on at their command.\r\n",
      "\r\n",
      "Outside the hotel a car drives up and three agents appear in neatly pressed black suits. They are Agent Smith (Hugo Weaving), Agent Brown (Paul Goddard), and Agent Jones (Robert Taylor). Agent Smith and the presiding police lieutenant argue. Agent Smith admonishes the policeman that they were given specific orders to contact the agents first, for their\n"
     ]
    }
   ],
   "source": [
    "print(text[:1500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "# summarize()는 문장 토큰화를 별도 하지 않아도 내부적으로 수행한다. 그래서 원문을 바로 입력이 가능하다.\n",
    "\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))  # 0.005: 원문에서 요약문으로 선택하는 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "['Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.', 'Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.']\n"
     ]
    }
   ],
   "source": [
    "# 리스트로 요약문 출력하기\n",
    "\n",
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))  # split 옵션 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Trinity takes Neo to Morpheus.\n",
      "Morpheus, Trinity, Neo, Apoc, Switch, Mouse and Cypher are jacked into the Matrix.\n",
      "Trinity brings the helicopter down to the floor that Morpheus is on and Neo opens fire on the three Agents.\n"
     ]
    }
   ],
   "source": [
    "# 단어 갯수로 조절하기\n",
    "\n",
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"IN THE LONG and complicated history of the interpretation of the theology of John Calvin, one recurring question is that of the continuity and discontinuity between Calvin’s views and those of later Calvinism. In a formal sense, this question necessarily belongs to the interpretation of any influential theologian that takes seriously the historical development of his particular theological tradition. Historical interpretation of a particular theological figure or tradition demands that careful attention be given to continuities and discontinuities in the course of its development. The theology of Calvin can hardly be understood without paying careful attention to his sixteenth-century context. Furthermore, the theology of later Calvinism can scarcely be understood without regard to the influence of Calvin, who is undoubtedly a leading theologian of the Reformed tradition. However, the question of continuity and discontinuity between Calvin’s views and later Calvinism takes on special significance, when viewed within the framework of the history of interpretation of Calvin’s thought. Though it is not possible in an article such as this to review the history of the interpretation of Calvin’s theology, it is instructive to note that the initial occasion for vigorous debate regarding Calvin and the Calvinists was the emergence of a neo-orthodox approach in the early twentieth century. Contrary to older, nineteenth-century approaches to Calvin’s thought, which either identified the doctrine of predestination as the “central dogma” of Calvin’s theology or found the key to interpretation in its peculiar dialectical form, the trajectory of neo-orthodox interpretation emphasized that Calvin’s theology was characterized by a Christocentric doctrine of the revelation of God’s grace in Christ.1 In the.\"\n",
    "\n",
    "print(summarize(text, words=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
