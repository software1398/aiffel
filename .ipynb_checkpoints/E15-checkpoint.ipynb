{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E15 - 단어 수준의 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 178009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40260</th>\n",
       "      <td>At last, my turn came.</td>\n",
       "      <td>Enfin mon tour est venu.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73590</th>\n",
       "      <td>We'll know in the morning.</td>\n",
       "      <td>Nous le saurons dans la matinée.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21164</th>\n",
       "      <td>The joke's on you.</td>\n",
       "      <td>C'est de vous qu'on se moque.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115550</th>\n",
       "      <td>He raised his hat when he saw me.</td>\n",
       "      <td>Il leva son chapeau quand il me vit.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160337</th>\n",
       "      <td>That twenty-kilometer run really wiped me out.</td>\n",
       "      <td>Cette course de vingt kilomètres m'a vraiment ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   eng  \\\n",
       "40260                           At last, my turn came.   \n",
       "73590                       We'll know in the morning.   \n",
       "21164                               The joke's on you.   \n",
       "115550               He raised his hat when he saw me.   \n",
       "160337  That twenty-kilometer run really wiped me out.   \n",
       "\n",
       "                                                      fra  \\\n",
       "40260                            Enfin mon tour est venu.   \n",
       "73590                    Nous le saurons dans la matinée.   \n",
       "21164                       C'est de vous qu'on se moque.   \n",
       "115550               Il leva son chapeau quand il me vit.   \n",
       "160337  Cette course de vingt kilomètres m'a vraiment ...   \n",
       "\n",
       "                                                       cc  \n",
       "40260   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "73590   CC-BY 2.0 (France) Attribution: tatoeba.org #5...  \n",
       "21164   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "115550  CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "160337  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37666</th>\n",
       "      <td>She told him to stop.</td>\n",
       "      <td>Elle lui a dit de cesser.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49825</th>\n",
       "      <td>It is not his business.</td>\n",
       "      <td>Ce n'est pas son affaire.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34704</th>\n",
       "      <td>He has no girlfriend.</td>\n",
       "      <td>Il n'a pas de petite amie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47103</th>\n",
       "      <td>Do you like my T-shirt?</td>\n",
       "      <td>Mon maillot te plaît-il ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24397</th>\n",
       "      <td>I know his address.</td>\n",
       "      <td>Je connais son adresse.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng                         fra\n",
       "37666    She told him to stop.   Elle lui a dit de cesser.\n",
       "49825  It is not his business.   Ce n'est pas son affaire.\n",
       "34704    He has no girlfriend.  Il n'a pas de petite amie.\n",
       "47103  Do you like my T-shirt?   Mon maillot te plaît-il ?\n",
       "24397      I know his address.     Je connais son adresse."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][20000:53000] # 3만3천개의 샘플 사용, 세 번째 열은 제외\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수 구현\n",
    "import re\n",
    "\n",
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess(cols, sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    \n",
    "    sentence = re.sub(r\"([?.!,¿,'-])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r\"\\s+\", r\" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    if cols == 'fra':\n",
    "        sentence = sos_token + sentence + eos_token\n",
    "            \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39389</th>\n",
       "      <td>which book is better ?</td>\n",
       "      <td>&lt;start&gt; quel livre est le meilleur ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34587</th>\n",
       "      <td>have you seen my pen ?</td>\n",
       "      <td>&lt;start&gt; avez - vous vu mon stylo ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27821</th>\n",
       "      <td>you may use my car .</td>\n",
       "      <td>&lt;start&gt; tu peux prendre ma voiture . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30668</th>\n",
       "      <td>i ' m very busy today .</td>\n",
       "      <td>&lt;start&gt; je suis très occupé aujourd ' hui . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40224</th>\n",
       "      <td>are you seeing anyone ?</td>\n",
       "      <td>&lt;start&gt; vois - tu qui que ce soit ? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31220</th>\n",
       "      <td>my whole body hurts .</td>\n",
       "      <td>&lt;start&gt; tout mon corps me fait mal . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36879</th>\n",
       "      <td>is that your bicycle ?</td>\n",
       "      <td>&lt;start&gt; est - ce que c ' est ta bicyclette ? &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35147</th>\n",
       "      <td>i always feel sleepy .</td>\n",
       "      <td>&lt;start&gt; j ' ai toujours sommeil . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33884</th>\n",
       "      <td>ask them to help you .</td>\n",
       "      <td>&lt;start&gt; demande - leur de t ' aider . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>it ' s a no - brainer .</td>\n",
       "      <td>&lt;start&gt; c ' est simple comme bonjour . &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           eng  \\\n",
       "39389   which book is better ?   \n",
       "34587   have you seen my pen ?   \n",
       "27821     you may use my car .   \n",
       "30668  i ' m very busy today .   \n",
       "40224  are you seeing anyone ?   \n",
       "31220    my whole body hurts .   \n",
       "36879   is that your bicycle ?   \n",
       "35147   i always feel sleepy .   \n",
       "33884   ask them to help you .   \n",
       "20307  it ' s a no - brainer .   \n",
       "\n",
       "                                                     fra  \n",
       "39389         <start> quel livre est le meilleur ? <end>  \n",
       "34587           <start> avez - vous vu mon stylo ? <end>  \n",
       "27821         <start> tu peux prendre ma voiture . <end>  \n",
       "30668  <start> je suis très occupé aujourd ' hui . <end>  \n",
       "40224          <start> vois - tu qui que ce soit ? <end>  \n",
       "31220         <start> tout mon corps me fait mal . <end>  \n",
       "36879  <start> est - ce que c ' est ta bicyclette ? <...  \n",
       "35147            <start> j ' ai toujours sommeil . <end>  \n",
       "33884        <start> demande - leur de t ' aider . <end>  \n",
       "20307       <start> c ' est simple comme bonjour . <end>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.eng = lines.eng.apply(lambda x: preprocess('eng', x))\n",
    "lines.fra = lines.fra.apply(lambda x: preprocess('fra', x))\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 단어장을 만들기, 영어와 프랑스어별로\n",
    "\n",
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(filters=' ')            # 단어 단위로 Tokenizer를 생성합니다.\n",
    "    tokenizer.fit_on_texts(corpus)                # 33000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "    tensor = tokenizer.texts_to_sequences(corpus) # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 22, 70, 30, 174, 1],\n",
       " [3, 2, 22, 70, 30, 174, 1],\n",
       " [3, 2, 22, 70, 509, 1]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text, eng_tokenizer = tokenize(lines.eng)\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 6, 20, 4, 29, 31, 202, 10, 318, 3, 2],\n",
       " [1, 6, 20, 4, 29, 31, 202, 10, 634, 3, 2],\n",
       " [1, 6, 13, 130, 21, 436, 3, 2]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_text, fra_tokenizer = tokenize(lines.fra)\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 5211\n",
      "프랑스어 단어장의 크기 : 9021\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 11\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)\n",
    "# 패딩처리하기 위해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5211\n",
      "프랑스어 단어장의 크기 : 9021\n",
      "영어 시퀀스의 최대 길이 11\n",
      "프랑스어 시퀀스의 최대 길이 20\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [x[:-1] for x in target_text]\n",
    "# 시작 토큰 제거\n",
    "decoder_target = [x[1:] for x in target_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 6, 20, 4, 29, 31, 202, 10, 318, 3], [1, 6, 20, 4, 29, 31, 202, 10, 634, 3], [1, 6, 13, 130, 21, 436, 3]]\n",
      "[[6, 20, 4, 29, 31, 202, 10, 318, 3, 2], [6, 20, 4, 29, 31, 202, 10, 634, 3, 2], [6, 13, 130, 21, 436, 3, 2]]\n"
     ]
    }
   ],
   "source": [
    "print(decoder_input[:3])\n",
    "print(decoder_target[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sent in decoder_target:\n",
    "#     print(' '.join(list(map(lambda x: fra_tokenizer.index_word[x], sent))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 11)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 20)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 20)\n"
     ]
    }
   ],
   "source": [
    "# 패딩 처리하기\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (30000, 11)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (30000, 20)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (30000, 20)\n"
     ]
    }
   ],
   "source": [
    "# 학습데이터와 검증데이터 분리하기\n",
    "\n",
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input_train))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input_train))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Embedding, Masking, Dense, LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "embedding_size = 1024\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더 설계\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state=encoder_states)\n",
    "\n",
    "# 출력층\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 1024)   5336064     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 1024)   9237504     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 1024)   0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 1024)   0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 1024), (None 8392704     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 1024), 8392704     masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9021)   9246525     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 40,605,501\n",
      "Trainable params: 40,605,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "118/118 [==============================] - 30s 255ms/step - loss: 1.8975 - val_loss: 1.5823\n",
      "Epoch 2/20\n",
      "118/118 [==============================] - 29s 250ms/step - loss: 1.1953 - val_loss: 1.3052\n",
      "Epoch 3/20\n",
      "118/118 [==============================] - 29s 246ms/step - loss: 0.9857 - val_loss: 1.1860\n",
      "Epoch 4/20\n",
      "118/118 [==============================] - 29s 246ms/step - loss: 0.8414 - val_loss: 1.0876\n",
      "Epoch 5/20\n",
      "118/118 [==============================] - 29s 249ms/step - loss: 0.7232 - val_loss: 1.0375\n",
      "Epoch 6/20\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.6237 - val_loss: 1.0176\n",
      "Epoch 7/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.5374 - val_loss: 0.9717\n",
      "Epoch 8/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.4615 - val_loss: 0.9694\n",
      "Epoch 9/20\n",
      "118/118 [==============================] - 29s 246ms/step - loss: 0.3952 - val_loss: 0.9294\n",
      "Epoch 10/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.3372 - val_loss: 0.9195\n",
      "Epoch 11/20\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.2889 - val_loss: 0.9094\n",
      "Epoch 12/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.2474 - val_loss: 0.9139\n",
      "Epoch 13/20\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.2129 - val_loss: 0.9158\n",
      "Epoch 14/20\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.1859 - val_loss: 0.9114\n",
      "Epoch 15/20\n",
      "118/118 [==============================] - 29s 243ms/step - loss: 0.1638 - val_loss: 0.9258\n",
      "Epoch 16/20\n",
      "118/118 [==============================] - 29s 247ms/step - loss: 0.1466 - val_loss: 0.9310\n",
      "Epoch 17/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.1332 - val_loss: 0.9336\n",
      "Epoch 18/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.1221 - val_loss: 0.9325\n",
      "Epoch 19/20\n",
      "118/118 [==============================] - 29s 244ms/step - loss: 0.1134 - val_loss: 0.9493\n",
      "Epoch 20/20\n",
      "118/118 [==============================] - 29s 245ms/step - loss: 0.1067 - val_loss: 0.9403\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train,\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='traingin loss', color='red')\n",
    "plt.plot(epochs, val_loss, 'b', label='validation loss', color='blue')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 1024)        5336064   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 1024)        0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 1024), (None, 102 8392704   \n",
      "=================================================================\n",
      "Total params: 13,728,768\n",
      "Trainable params: 13,728,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 테스트하기\n",
    "\n",
    "# 인코더 정의\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 1024)   9237504     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1024)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 1024), 8392704     embedding_2[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9021)   9246525     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 26,876,733\n",
      "Trainable params: 26,876,733\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더 정의\n",
    "\n",
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 훈련 때 사용했던 임베딩 층을 재사용\n",
    "dec_emb2 =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "# 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수->단어, 단어->정수\n",
    "\n",
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode_sequence(): 입력 인자는 번역하고자 하는 문장의 정수 시퀀스\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 단어로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 단어를 예측 문장에 추가\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: do you have nightmares ?\n",
      "정답 문장: fais - tu des cauchemars ?\n",
      "번역기가 번역한 문장: faites - des - ? ? \n",
      "-----------------------------------\n",
      "입력 문장: can you do that for me ?\n",
      "정답 문장: est - ce que tu peux faire ça pour moi ?\n",
      "번역기가 번역한 문장: est - tu le le fair\n",
      "-----------------------------------\n",
      "입력 문장: i ' m not a murderer .\n",
      "정답 문장: je ne suis pas un meurtrier .\n",
      "번역기가 번역한 문장: je ne ne ne je . . \n",
      "-----------------------------------\n",
      "입력 문장: may i do that now ?\n",
      "정답 문장: puis - je faire cela maintenant ?\n",
      "번역기가 번역한 문장: puis - je je je maintenan\n",
      "-----------------------------------\n",
      "입력 문장: they are very kind .\n",
      "정답 문장: ils sont très gentils .\n",
      "번역기가 번역한 문장: ils très très très \n"
     ]
    }
   ],
   "source": [
    "import random as rd\n",
    "sel_lst = [rd.randint(1, 30000) for _ in range(5)]\n",
    "\n",
    "for seq_index in sel_lst:\n",
    "    input_seq = encoder_input_train[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index + 20000])\n",
    "    print('정답 문장:', lines.fra[seq_index + 20000][8:-6])\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
