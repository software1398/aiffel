{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E09 - RNN(영화리뷰 텍스트 감정분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "# 단어를 키로 바꾸기\n",
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-23485464c763>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_non_tensor\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;31m# `SparseTensors` can't be converted to `Tensor`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_non_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1281\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1341\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    260\u001b[0m   \"\"\"\n\u001b[1;32m    261\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 262\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0mctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aiffel/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "# list 형태의 sentences는 numpy array로 변환되어야 딥러닝 레이어의 입력이 될 수 있습니다.\n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "# Embedding레이어의 인풋이 되는 문장 벡터는 길이 일정해야 한다.\n",
    "# Tensorflow의 keras.preprocessing.sequence.pad_sequences()\n",
    "# 문장 벡터 뒤에 패딩(<PAD>)을 추가하여 길이을 일정하게 맞춰준다.\n",
    "\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.02228893 -0.0193723  -0.01558398 -0.03680793]\n",
      "  [-0.04055433 -0.00357191 -0.03995835  0.04183863]\n",
      "  [ 0.03310945 -0.00197109 -0.02934868 -0.01329656]\n",
      "  [ 0.0063182   0.0133387   0.00435569 -0.02557609]\n",
      "  [ 0.03873781  0.02745881 -0.00762119  0.00320307]]\n",
      "\n",
      " [[-0.02228893 -0.0193723  -0.01558398 -0.03680793]\n",
      "  [-0.04055433 -0.00357191 -0.03995835  0.04183863]\n",
      "  [-0.02084392  0.04458013  0.04208721 -0.02466316]\n",
      "  [-0.02162687  0.03414777 -0.04379114 -0.03538904]\n",
      "  [ 0.03873781  0.02745881 -0.00762119  0.00320307]]\n",
      "\n",
      " [[-0.02228893 -0.0193723  -0.01558398 -0.03680793]\n",
      "  [-0.0061186  -0.04618734  0.02933622  0.01939566]\n",
      "  [-0.04055433 -0.00357191 -0.03995835  0.04183863]\n",
      "  [ 0.03310945 -0.00197109 -0.02934868 -0.01329656]\n",
      "  [ 0.04355204  0.02964051 -0.00682864 -0.0357269 ]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index))\n",
    "raw_inputs = keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# RNN모델을 사용하여 이전 스텝의 텍스트 데이터 처리하는 코드\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# CNN모델을 사용하여 텍스트 데이터 처리하는 코드\n",
    "\n",
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-D CNN과 RNN 혼합사용\n",
    "# FFN(FeedForward Network)\n",
    "# Tensorflow레이어 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "# IMDB 영화리뷰 데이터\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "imdb = keras.datasets.imdb\n",
    "\n",
    "# IMDB 데이터셋 다운로드\n",
    "# load_data시 num_words를 지정하면 그 갯수만큼 word_to_index 딕셔너리가 생성된 형태로 데이터셋이 생성\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# encode된 딕셔너리로 제공되었음을 확인\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word[0] = \"<PAD>\"\n",
    "index_to_word[1] = \"<BOS>\"\n",
    "index_to_word[2] = \"<UNK>\"\n",
    "index_to_word[3] = \"<UNUSED>\"\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "# decode 확인\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "# 데이터셋의 문장 길이 맞추기 잊지 않기\n",
    "# 문장 최대 길이 확인하기(maxlen)\n",
    "\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "# padding(길이 맞추기 위해 넣는 값)방법에 따라 성능이 달라진다. post, pre\n",
    "\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경가능)\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 1s 43ms/step - loss: 0.6931 - accuracy: 0.5024 - val_loss: 0.6934 - val_accuracy: 0.5016\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.6929 - accuracy: 0.5116 - val_loss: 0.6931 - val_accuracy: 0.5022\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.6922 - accuracy: 0.5148 - val_loss: 0.6927 - val_accuracy: 0.5020\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.6898 - accuracy: 0.5183 - val_loss: 0.6916 - val_accuracy: 0.5076\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6826 - accuracy: 0.5288 - val_loss: 0.6889 - val_accuracy: 0.5130\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.7232 - accuracy: 0.5389 - val_loss: 0.8333 - val_accuracy: 0.5177\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6930 - accuracy: 0.5232 - val_loss: 0.6919 - val_accuracy: 0.5061\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6826 - accuracy: 0.5313 - val_loss: 0.6882 - val_accuracy: 0.5096\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6781 - accuracy: 0.5311 - val_loss: 0.6887 - val_accuracy: 0.5073\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.6763 - accuracy: 0.5321 - val_loss: 0.6882 - val_accuracy: 0.5091\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.6745 - accuracy: 0.5349 - val_loss: 0.6880 - val_accuracy: 0.5094\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6725 - accuracy: 0.5361 - val_loss: 0.6878 - val_accuracy: 0.5096\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 0.6703 - accuracy: 0.5368 - val_loss: 0.6871 - val_accuracy: 0.5101\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6680 - accuracy: 0.5375 - val_loss: 0.6874 - val_accuracy: 0.5109\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.6654 - accuracy: 0.5380 - val_loss: 0.6863 - val_accuracy: 0.5118\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6626 - accuracy: 0.5384 - val_loss: 0.6851 - val_accuracy: 0.5129\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.6595 - accuracy: 0.5386 - val_loss: 0.6841 - val_accuracy: 0.5147\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 0.6571 - accuracy: 0.5396 - val_loss: 0.6851 - val_accuracy: 0.5156\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 32ms/step - loss: 0.6563 - accuracy: 0.5396 - val_loss: 0.6852 - val_accuracy: 0.5152\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 0.6547 - accuracy: 0.5407 - val_loss: 0.6864 - val_accuracy: 0.5154\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습하기\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "# epoch과정에서 history가 저장된다. 그래프로 확인하면 인사이트 도출\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# model의 첫 번째 레이어인 Embedding, 학습된 워드 벡터가 존재할 것\n",
    "\n",
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.8220395e-02, -4.9640957e-02,  2.8604461e-02,  6.6778123e-02,\n",
       "        4.5720622e-02,  3.4866337e-02, -7.8080319e-02,  6.0631547e-02,\n",
       "       -4.6682246e-02, -4.3688823e-02,  8.7795509e-03, -5.7287626e-03,\n",
       "       -4.2023506e-02,  6.9370370e-05,  7.1478277e-02, -4.8286370e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('big', 0.9368116855621338),\n",
       " ('without', 0.9230618476867676),\n",
       " ('lanza', 0.9224776029586792),\n",
       " ('injury', 0.9222043752670288),\n",
       " ('reaching', 0.9214663505554199),\n",
       " ('moving', 0.9196081757545471),\n",
       " ('shootout', 0.9193623065948486),\n",
       " ('seasons', 0.9175968170166016),\n",
       " ('fresh', 0.913799524307251),\n",
       " ('boiled', 0.913078248500824)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습된 워드벡터로 임의의 단어와 가장 유사한 단어와 그 유사도를 확인해보는 방법\n",
    "\n",
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word2vec(구글 제공): 사전학습된 워드 임베딩 모델, 1억개의 단어로 학습되었다.\n",
    "# 300만개의 단어를 300차원의 벡터로 표현\n",
    "# https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907792091369629),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100709438323975),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('Ilove', 0.5702950954437256),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547305345535278),\n",
       " ('absolutely_adore', 0.5536840558052063)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec 모델이용하기\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수 (변경가능한 하이퍼파라미터)\n",
    "\n",
    "# 모델 구성\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(5))\n",
    "model.add(keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(keras.layers.GlobalMaxPooling1D())\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 28s 936ms/step - loss: 0.6895 - accuracy: 0.5405 - val_loss: 0.6723 - val_accuracy: 0.5942\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.6374 - accuracy: 0.6654 - val_loss: 0.5944 - val_accuracy: 0.7180\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.4885 - accuracy: 0.7884 - val_loss: 0.4052 - val_accuracy: 0.8273\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.3103 - accuracy: 0.8752 - val_loss: 0.3124 - val_accuracy: 0.8668\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.2211 - accuracy: 0.9193 - val_loss: 0.3004 - val_accuracy: 0.8727\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.1660 - accuracy: 0.9423 - val_loss: 0.2950 - val_accuracy: 0.8776\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.1207 - accuracy: 0.9621 - val_loss: 0.3055 - val_accuracy: 0.8751\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0869 - accuracy: 0.9787 - val_loss: 0.3247 - val_accuracy: 0.8737\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0608 - accuracy: 0.9889 - val_loss: 0.3349 - val_accuracy: 0.8742\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0408 - accuracy: 0.9949 - val_loss: 0.3543 - val_accuracy: 0.8741\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0280 - accuracy: 0.9977 - val_loss: 0.3699 - val_accuracy: 0.8745\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0205 - accuracy: 0.9988 - val_loss: 0.3994 - val_accuracy: 0.8717\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0151 - accuracy: 0.9992 - val_loss: 0.4068 - val_accuracy: 0.8723\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0103 - accuracy: 0.9995 - val_loss: 0.4226 - val_accuracy: 0.8712\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.4388 - val_accuracy: 0.8732\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0058 - accuracy: 0.9997 - val_loss: 0.4511 - val_accuracy: 0.8717\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.4646 - val_accuracy: 0.8708\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 6s 201ms/step - loss: 0.0036 - accuracy: 0.9999 - val_loss: 0.4773 - val_accuracy: 0.8711\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0030 - accuracy: 0.9999 - val_loss: 0.4879 - val_accuracy: 0.8704\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 6s 202ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.8701\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 10s - loss: 0.5369 - accuracy: 0.8638\n",
      "[0.5368979573249817, 0.8637599945068359]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
